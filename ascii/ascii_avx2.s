//go:build !noasm && amd64
// Code generated by gocc v0.16.1-rev-1fdd680 -- DO NOT EDIT.
//
// Source file         : ascii_avx2.c
// Clang version       : Apple clang version 17.0.0 (clang-1700.6.3.2)
// Target architecture : amd64
// Compiler options    : -mavx2 -mfma

#include "textflag.h"

TEXT Â·isAsciiAvx(SB), NOSPLIT, $0-17
	MOVQ src+0(FP), DI
	MOVQ src_len+8(FP), SI
	LEAQ 0x60(DI), R8      // <--                                  // lea	r8, [rdi + 96]
	XORL DX, DX            // <--                                  // xor	edx, edx
	MOVQ SI, CX            // <--                                  // mov	rcx, rsi

LBB0_1:
	LEAQ 0x20(DX), AX            // <--                                  // lea	rax, [rdx + 32]
	CMPQ AX, SI                  // <--                                  // cmp	rax, rsi
	JA   LBB0_2                  // <--                                  // ja	.LBB0_2
	LONG $0x046ffec5; BYTE $0x17 // VMOVDQU 0(DI)(DX*1), Y0              // vmovdqu	ymm0, ymmword ptr [rdi + rdx]
	LONG $0xc8d77dc5             // VPMOVMSKB Y0, R9                     // vpmovmskb	r9d, ymm0
	ADDQ $-0x20, CX              // <--                                  // add	rcx, -32
	MOVQ AX, DX                  // <--                                  // mov	rdx, rax
	WORD $0x8545; BYTE $0xc9     // TESTL R9, R9                         // test	r9d, r9d
	JE   LBB0_1                  // <--                                  // je	.LBB0_1
	XORL AX, AX                  // <--                                  // xor	eax, eax
	JMP  LBB0_19                 // <--                                  // jmp	.LBB0_19

LBB0_2:
	MOVQ SI, R9   // <--                                  // mov	r9, rsi
	WORD $0x01b0  // MOVL $0x1, AL                        // mov	al, 1
	SUBQ DX, R9   // <--                                  // sub	r9, rdx
	JBE  LBB0_19  // <--                                  // jbe	.LBB0_19
	CMPQ R9, $0x8 // <--                                  // cmp	r9, 8
	JAE  LBB0_5   // <--                                  // jae	.LBB0_5
	XORL R8, R8   // <--                                  // xor	r8d, r8d
	MOVQ DX, CX   // <--                                  // mov	rcx, rdx
	JMP  LBB0_10  // <--                                  // jmp	.LBB0_10

LBB0_19:
	VZEROUPPER          // <--                                  // vzeroupper
	MOVB AX, ret+16(FP) // <--
	RET                 // <--                                  // ret

LBB0_5:
	CMPQ R9, $0x80 // <--                                  // cmp	r9, 128
	JAE  LBB0_12   // <--                                  // jae	.LBB0_12
	XORL R8, R8    // <--                                  // xor	r8d, r8d
	XORL AX, AX    // <--                                  // xor	eax, eax
	JMP  LBB0_7    // <--                                  // jmp	.LBB0_7

LBB0_12:
	NOP              // (skipped)                            // push	rbp
	NOP              // (skipped)                            // mov	rbp, rsp
	NOP              // (skipped)                            // and	rsp, -8
	ADDQ DX, R8      // <--                                  // add	r8, rdx
	MOVQ R9, AX      // <--                                  // mov	rax, r9
	ANDQ $-0x80, AX  // <--                                  // and	rax, -128
	MOVQ R9, R10     // <--                                  // mov	r10, r9
	ANDQ $-0x80, R10 // <--                                  // and	r10, -128
	LONG $0xc0eff9c5 // VPXOR X0, X0, X0                     // vpxor	xmm0, xmm0, xmm0
	LONG $0xc9eff1c5 // VPXOR X1, X1, X1                     // vpxor	xmm1, xmm1, xmm1
	LONG $0xd2efe9c5 // VPXOR X2, X2, X2                     // vpxor	xmm2, xmm2, xmm2
	LONG $0xdbefe1c5 // VPXOR X3, X3, X3                     // vpxor	xmm3, xmm3, xmm3

LBB0_13:
	LONG $0xeb7dc1c4; WORD $0xa040 // VPOR -0x60(R8), Y0, Y0               // vpor	ymm0, ymm0, ymmword ptr [r8 - 96]
	LONG $0xeb75c1c4; WORD $0xc048 // VPOR -0x40(R8), Y1, Y1               // vpor	ymm1, ymm1, ymmword ptr [r8 - 64]
	LONG $0xeb6dc1c4; WORD $0xe050 // VPOR -0x20(R8), Y2, Y2               // vpor	ymm2, ymm2, ymmword ptr [r8 - 32]
	LONG $0xeb65c1c4; BYTE $0x18   // VPOR 0(R8), Y3, Y3                   // vpor	ymm3, ymm3, ymmword ptr [r8]
	SUBQ $-0x80, R8                // <--                                  // sub	r8, -128
	ADDQ $-0x80, R10               // <--                                  // add	r10, -128
	JNE  LBB0_13                   // <--                                  // jne	.LBB0_13
	LONG $0xc0ebf5c5               // VPOR Y0, Y1, Y0                      // vpor	ymm0, ymm1, ymm0
	LONG $0xcaebe5c5               // VPOR Y2, Y3, Y1                      // vpor	ymm1, ymm3, ymm2
	LONG $0xc0ebf5c5               // VPOR Y0, Y1, Y0                      // vpor	ymm0, ymm1, ymm0
	LONG $0x397de3c4; WORD $0x01c1 // VEXTRACTI128 $0x1, Y0, X1            // vextracti128	xmm1, ymm0, 1
	LONG $0xc1ebf9c5               // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0xc870f9c5; BYTE $0xee   // VPSHUFD $-0x12, X0, X1               // vpshufd	xmm1, xmm0, 238
	LONG $0xc1ebf9c5               // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0xc870f9c5; BYTE $0x55   // VPSHUFD $0x55, X0, X1                // vpshufd	xmm1, xmm0, 85
	LONG $0xc1ebf9c5               // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0xd072f1c5; BYTE $0x10   // VPSRLD $0x10, X0, X1                 // vpsrld	xmm1, xmm0, 16
	LONG $0xc1ebf9c5               // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0xd071f1c5; BYTE $0x08   // VPSRLW $0x8, X0, X1                  // vpsrlw	xmm1, xmm0, 8
	LONG $0xc1ebf9c5               // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0x7e79c1c4; BYTE $0xc0   // VMOVD X0, R8                         // vmovd	r8d, xmm0
	CMPQ R9, AX                    // <--                                  // cmp	r9, rax
	NOP                            // (skipped)                            // mov	rsp, rbp
	NOP                            // (skipped)                            // pop	rbp
	JE   LBB0_11                   // <--                                  // je	.LBB0_11
	LONG $0x78c1f641               // TESTL $0x78, R9                      // test	r9b, 120
	JE   LBB0_16                   // <--                                  // je	.LBB0_16

LBB0_7:
	MOVQ SI, CX                  // <--                                  // mov	rcx, rsi
	ANDQ $-0x8, CX               // <--                                  // and	rcx, -8
	LONG $0xc0b60f45             // MOVZX R8, R8                         // movzx	r8d, r8b
	LONG $0x6e79c1c4; BYTE $0xc0 // VMOVD R8, X0                         // vmovd	xmm0, r8d
	ADDQ DX, AX                  // <--                                  // add	rax, rdx

LBB0_8:
	LONG $0x0c7efac5; BYTE $0x07 // VMOVQ 0(DI)(AX*1), X1                // vmovq	xmm1, qword ptr [rdi + rax]
	LONG $0xc0ebf1c5             // VPOR X0, X1, X0                      // vpor	xmm0, xmm1, xmm0
	ADDQ $0x8, AX                // <--                                  // add	rax, 8
	CMPQ CX, AX                  // <--                                  // cmp	rcx, rax
	JNE  LBB0_8                  // <--                                  // jne	.LBB0_8
	LONG $0xc870f9c5; BYTE $0x55 // VPSHUFD $0x55, X0, X1                // vpshufd	xmm1, xmm0, 85
	LONG $0xc1ebf9c5             // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0xd072f1c5; BYTE $0x10 // VPSRLD $0x10, X0, X1                 // vpsrld	xmm1, xmm0, 16
	LONG $0xc1ebf9c5             // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0xd071f1c5; BYTE $0x08 // VPSRLW $0x8, X0, X1                  // vpsrlw	xmm1, xmm0, 8
	LONG $0xc1ebf9c5             // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0x7e79c1c4; BYTE $0xc0 // VMOVD X0, R8                         // vmovd	r8d, xmm0
	LONG $0x07c6f640             // TESTL $0x7, SI                       // test	sil, 7
	JE   LBB0_11                 // <--                                  // je	.LBB0_11

LBB0_10:
	ORB  0(DI)(CX*1), R8 // <--                                  // or	r8b, byte ptr [rdi + rcx]
	INCQ CX              // <--                                  // inc	rcx
	CMPQ CX, SI          // <--                                  // cmp	rcx, rsi
	JB   LBB0_10         // <--                                  // jb	.LBB0_10

LBB0_11:
	WORD $0x8445; BYTE $0xc0 // TESTL R8, R8                         // test	r8b, r8b
	WORD $0x990f; BYTE $0xc0 // SETNS AL                             // setns	al
	VZEROUPPER               // <--                                  // vzeroupper
	MOVB AX, ret+16(FP)      // <--
	RET                      // <--                                  // ret

LBB0_16:
	ANDQ $-0x80, CX // <--                                  // and	rcx, -128
	ADDQ DX, CX     // <--                                  // add	rcx, rdx
	JMP  LBB0_10    // <--                                  // jmp	.LBB0_10
