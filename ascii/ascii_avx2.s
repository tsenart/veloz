//go:build !noasm && amd64
// Code generated by gocc v0.16.5-rev-57c4d32 -- DO NOT EDIT.
//
// Source file         : ascii_avx2.c
// Clang version       : Apple clang version 17.0.0 (clang-1700.6.3.2)
// Target architecture : amd64
// Compiler options    : -mavx2 -mfma

#include "textflag.h"

DATA LCPI0_0<>+0x00(SB)/8, $0x8080808080808080
GLOBL LCPI0_0<>(SB), (RODATA|NOPTR), $8

DATA LCPI0_1<>+0x00(SB)/8, $0x8080808080808080
DATA LCPI0_1<>+0x08(SB)/8, $0x8080808080808080
GLOBL LCPI0_1<>(SB), (RODATA|NOPTR), $16

DATA LCPI0_2<>+0x00(SB)/1, $0x80
GLOBL LCPI0_2<>(SB), (RODATA|NOPTR), $1

TEXT ·isAsciiAvx(SB), NOSPLIT, $0-17
	MOVQ         src+0(FP), DI
	MOVQ         src_len+8(FP), SI
	NOP                              // (skipped)                            // push	rbp
	NOP                              // (skipped)                            // mov	rbp, rsp
	NOP                              // (skipped)                            // and	rsp, -8
	CMPQ         SI, $0x10           // <--                                  // cmp	rsi, 16
	JB           LBB0_13             // <--                                  // jb	.LBB0_13
	LEAQ         0(DI)(SI*1), CX     // <--                                  // lea	rcx, [rdi + rsi]
	WORD         $0xf089             // MOVL SI, AX                          // mov	eax, esi
	WORD         $0xe083; BYTE $0x7f // ANDL $0x7f, AX                       // and	eax, 127
	SUBQ         AX, CX              // <--                                  // sub	rcx, rax
	CMPQ         CX, DI              // <--                                  // cmp	rcx, rdi
	JBE          LBB0_5              // <--                                  // jbe	.LBB0_5
	VPBROADCASTQ LCPI0_0<>(SB), Y0   // <--                                  // vpbroadcastq	ymm0, qword ptr [rip + .LCPI0_0]

LBB0_3:
	LONG $0x4f6ffec5; BYTE $0x20 // VMOVDQU 0x20(DI), Y1                 // vmovdqu	ymm1, ymmword ptr [rdi + 32]
	LONG $0x0febf5c5             // VPOR 0(DI), Y1, Y1                   // vpor	ymm1, ymm1, ymmword ptr [rdi]
	LONG $0x4febf5c5; BYTE $0x40 // VPOR 0x40(DI), Y1, Y1                // vpor	ymm1, ymm1, ymmword ptr [rdi + 64]
	LONG $0x4febf5c5; BYTE $0x60 // VPOR 0x60(DI), Y1, Y1                // vpor	ymm1, ymm1, ymmword ptr [rdi + 96]
	LONG $0x177de2c4; BYTE $0xc8 // VPTEST Y0, Y1                        // vptest	ymm1, ymm0
	JNE  LBB0_19                 // <--                                  // jne	.LBB0_19
	SUBQ $-0x80, DI              // <--                                  // sub	rdi, -128
	CMPQ DI, CX                  // <--                                  // cmp	rdi, rcx
	JB   LBB0_3                  // <--                                  // jb	.LBB0_3

LBB0_5:
	ADDQ         DI, AX              // <--                                  // add	rax, rdi
	WORD         $0xf189             // MOVL SI, CX                          // mov	ecx, esi
	WORD         $0xe183; BYTE $0x1f // ANDL $0x1f, CX                       // and	ecx, 31
	SUBQ         CX, AX              // <--                                  // sub	rax, rcx
	CMPQ         DI, AX              // <--                                  // cmp	rdi, rax
	JAE          LBB0_9              // <--                                  // jae	.LBB0_9
	VPBROADCASTQ LCPI0_0<>(SB), Y0   // <--                                  // vpbroadcastq	ymm0, qword ptr [rip + .LCPI0_0]

LBB0_7:
	LONG $0x177de2c4; BYTE $0x07 // VPTEST 0(DI), Y0                     // vptest	ymm0, ymmword ptr [rdi]
	JNE  LBB0_19                 // <--                                  // jne	.LBB0_19
	ADDQ $0x20, DI               // <--                                  // add	rdi, 32
	CMPQ DI, AX                  // <--                                  // cmp	rdi, rax
	JB   LBB0_7                  // <--                                  // jb	.LBB0_7

LBB0_9:
	CMPL         CX, $0x10               // <--                                  // cmp	ecx, 16
	JB           LBB0_12                 // <--                                  // jb	.LBB0_12
	VPBROADCASTB LCPI0_2<>(SB), X0       // <--                                  // vpbroadcastb	xmm0, byte ptr [rip + .LCPI0_2]
	LONG         $0x1779e2c4; BYTE $0x07 // VPTEST 0(DI), X0                     // vptest	xmm0, xmmword ptr [rdi]
	JNE          LBB0_19                 // <--                                  // jne	.LBB0_19
	ADDQ         $0x10, DI               // <--                                  // add	rdi, 16

LBB0_12:
	WORD $0xe683; BYTE $0x0f // ANDL $0xf, SI                        // and	esi, 15

LBB0_13:
	WORD $0x8548; BYTE $0xf6 // TESTQ SI, SI                         // test	rsi, rsi
	JE   LBB0_17             // <--                                  // je	.LBB0_17
	CMPQ SI, $0x8            // <--                                  // cmp	rsi, 8
	JAE  LBB0_18             // <--                                  // jae	.LBB0_18
	CMPQ SI, $0x4            // <--                                  // cmp	rsi, 4
	JAE  LBB0_20             // <--                                  // jae	.LBB0_20
	MOVQ SI, AX              // <--                                  // mov	rax, rsi
	SHRQ $0x1, AX            // <--                                  // shr	rax
	LONG $0x0704b60f         // MOVZX 0(DI)(AX*1), AX                // movzx	eax, byte ptr [rdi + rax]
	ORB  0(DI), AL           // <--                                  // or	al, byte ptr [rdi]
	ORB  -0x1(DI)(SI*1), AL  // <--                                  // or	al, byte ptr [rdi + rsi - 1]
	WORD $0x990f; BYTE $0xc0 // SETNS AL                             // setns	al
	NOP                      // (skipped)                            // mov	rsp, rbp
	NOP                      // (skipped)                            // pop	rbp
	VZEROUPPER               // <--                                  // vzeroupper
	MOVB AX, ret+16(FP)      // <--
	RET                      // <--                                  // ret

LBB0_19:
	XORL AX, AX         // <--                                  // xor	eax, eax
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVB AX, ret+16(FP) // <--
	RET                 // <--                                  // ret

LBB0_17:
	WORD $0x01b0        // MOVL $0x1, AL                        // mov	al, 1
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVB AX, ret+16(FP) // <--
	RET                 // <--                                  // ret

LBB0_18:
	MOVQ -0x8(DI)(SI*1), AX                // <--                                  // mov	rax, qword ptr [rdi + rsi - 8]
	ORQ  0(DI), AX                         // <--                                  // or	rax, qword ptr [rdi]
	QUAD $0x808080808080b948; WORD $0x8080 // MOVQ $0x8080808080808080, CX         // movabs	rcx, -9187201950435737472
	WORD $0x8548; BYTE $0xc8               // TESTQ CX, AX                         // test	rax, rcx
	WORD $0x940f; BYTE $0xc0               // SETE AL                              // sete	al
	NOP                                    // (skipped)                            // mov	rsp, rbp
	NOP                                    // (skipped)                            // pop	rbp
	VZEROUPPER                             // <--                                  // vzeroupper
	MOVB AX, ret+16(FP)                    // <--
	RET                                    // <--                                  // ret

LBB0_20:
	LONG $0xfc37448b             // MOVL -0x4(DI)(SI*1), AX              // mov	eax, dword ptr [rdi + rsi - 4]
	WORD $0x070b                 // ORL 0(DI), AX                        // or	eax, dword ptr [rdi]
	LONG $0x808080a9; BYTE $0x80 // TESTL $-0x7f7f7f80, AX               // test	eax, -2139062144
	WORD $0x940f; BYTE $0xc0     // SETE AL                              // sete	al
	NOP                          // (skipped)                            // mov	rsp, rbp
	NOP                          // (skipped)                            // pop	rbp
	VZEROUPPER                   // <--                                  // vzeroupper
	MOVB AX, ret+16(FP)          // <--
	RET                          // <--                                  // ret

DATA LCPI1_0<>+0x00(SB)/8, $0x2020202020202020
DATA LCPI1_0<>+0x08(SB)/8, $0x2020202020202020
DATA LCPI1_0<>+0x10(SB)/8, $0x2020202020202020
DATA LCPI1_0<>+0x18(SB)/8, $0x2020202020202020
GLOBL LCPI1_0<>(SB), (RODATA|NOPTR), $32

DATA LCPI1_1<>+0x00(SB)/8, $0x1f1f1f1f1f1f1f1f
DATA LCPI1_1<>+0x08(SB)/8, $0x1f1f1f1f1f1f1f1f
DATA LCPI1_1<>+0x10(SB)/8, $0x1f1f1f1f1f1f1f1f
DATA LCPI1_1<>+0x18(SB)/8, $0x1f1f1f1f1f1f1f1f
GLOBL LCPI1_1<>(SB), (RODATA|NOPTR), $32

DATA LCPI1_2<>+0x00(SB)/8, $0x9a9a9a9a9a9a9a9a
DATA LCPI1_2<>+0x08(SB)/8, $0x9a9a9a9a9a9a9a9a
DATA LCPI1_2<>+0x10(SB)/8, $0x9a9a9a9a9a9a9a9a
DATA LCPI1_2<>+0x18(SB)/8, $0x9a9a9a9a9a9a9a9a
GLOBL LCPI1_2<>(SB), (RODATA|NOPTR), $32

DATA LCPI1_3<>+0x00(SB)/8, $0x9999999999999999
DATA LCPI1_3<>+0x08(SB)/8, $0x9999999999999999
DATA LCPI1_3<>+0x10(SB)/8, $0x9999999999999999
DATA LCPI1_3<>+0x18(SB)/8, $0x9999999999999999
GLOBL LCPI1_3<>(SB), (RODATA|NOPTR), $32

DATA LCPI1_4<>+0x00(SB)/8, $0x7f7f7f7f7f7f7f7f
DATA LCPI1_4<>+0x08(SB)/8, $0x7f7f7f7f7f7f7f7f
GLOBL LCPI1_4<>(SB), (RODATA|NOPTR), $16

DATA LCPI1_5<>+0x00(SB)/8, $0xfafafafafafafafa
DATA LCPI1_5<>+0x08(SB)/8, $0xfafafafafafafafa
GLOBL LCPI1_5<>(SB), (RODATA|NOPTR), $16

DATA LCPI1_6<>+0x00(SB)/8, $0x1f1f1f1f1f1f1f1f
DATA LCPI1_6<>+0x08(SB)/8, $0x1f1f1f1f1f1f1f1f
GLOBL LCPI1_6<>(SB), (RODATA|NOPTR), $16

DATA LCPI1_7<>+0x00(SB)/8, $0x2020202020202020
DATA LCPI1_7<>+0x08(SB)/8, $0x2020202020202020
GLOBL LCPI1_7<>(SB), (RODATA|NOPTR), $16

DATA LCPI1_8<>+0x00(SB)/1, $0x20
GLOBL LCPI1_8<>(SB), (RODATA|NOPTR), $1

DATA LCPI1_9<>+0x00(SB)/1, $0x1f
GLOBL LCPI1_9<>(SB), (RODATA|NOPTR), $1

DATA LCPI1_10<>+0x00(SB)/1, $0x9a
GLOBL LCPI1_10<>(SB), (RODATA|NOPTR), $1

DATA LCPI1_11<>+0x00(SB)/1, $0x99
GLOBL LCPI1_11<>(SB), (RODATA|NOPTR), $1

DATA LCPI1_12<>+0x00(SB)/1, $0x7f
GLOBL LCPI1_12<>(SB), (RODATA|NOPTR), $1

DATA LCPI1_13<>+0x00(SB)/1, $0xfa
GLOBL LCPI1_13<>(SB), (RODATA|NOPTR), $1

TEXT ·equalFoldAvx(SB), NOSPLIT, $0-33
	MOVQ a+0(FP), DI
	MOVQ a_len+8(FP), SI
	MOVQ b+16(FP), DX
	MOVQ b_len+24(FP), CX
	CMPQ SI, CX           // <--                                  // cmp	rsi, rcx
	JNE  LBB1_9           // <--                                  // jne	.LBB1_9
	NOP                   // (skipped)                            // push	rbp
	NOP                   // (skipped)                            // mov	rbp, rsp
	NOP                   // (skipped)                            // and	rsp, -8
	CMPQ SI, $0x1f        // <--                                  // cmp	rsi, 31
	JA   LBB1_10          // <--                                  // ja	.LBB1_10
	CMPQ SI, $0x8         // <--                                  // cmp	rsi, 8
	JAE  LBB1_20          // <--                                  // jae	.LBB1_20
	XORL CX, CX           // <--                                  // xor	ecx, ecx

LBB1_4:
	WORD $0x01b0 // MOVL $0x1, AL                        // mov	al, 1
	CMPQ CX, SI  // <--                                  // cmp	rcx, rsi
	JAE  LBB1_8  // <--                                  // jae	.LBB1_8
	DECQ SI      // <--                                  // dec	rsi

LBB1_6:
	LONG $0x0f04b60f             // MOVZX 0(DI)(CX*1), AX                // movzx	eax, byte ptr [rdi + rcx]
	LONG $0x14b60f44; BYTE $0x0a // MOVZX 0(DX)(CX*1), R10               // movzx	r10d, byte ptr [rdx + rcx]
	LONG $0x9f408d44             // LEAL -0x61(AX), R8                   // lea	r8d, [rax - 97]
	LONG $0xe0488d44             // LEAL -0x20(AX), R9                   // lea	r9d, [rax - 32]
	CMPB R8, $0x1a               // <--                                  // cmp	r8b, 26
	LONG $0xc1b60f45             // MOVZX R9, R8                         // movzx	r8d, r9b
	LONG $0xc0430f44             // CMOVAE AX, R8                        // cmovae	r8d, eax
	LONG $0x9f428d41             // LEAL -0x61(R10), AX                  // lea	eax, [r10 - 97]
	LONG $0xe04a8d45             // LEAL -0x20(R10), R9                  // lea	r9d, [r10 - 32]
	WORD $0x1a3c                 // CMPL AL, $0x1a                       // cmp	al, 26
	LONG $0xc9b60f45             // MOVZX R9, R9                         // movzx	r9d, r9b
	LONG $0xca430f45             // CMOVAE R10, R9                       // cmovae	r9d, r10d
	CMPB R8, R9                  // <--                                  // cmp	r8b, r9b
	WORD $0x940f; BYTE $0xc0     // SETE AL                              // sete	al
	CMPQ SI, CX                  // <--                                  // cmp	rsi, rcx
	JE   LBB1_8                  // <--                                  // je	.LBB1_8
	INCQ CX                      // <--                                  // inc	rcx
	CMPB R8, R9                  // <--                                  // cmp	r8b, r9b
	JE   LBB1_6                  // <--                                  // je	.LBB1_6

LBB1_8:
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	MOVB AX, ret+32(FP) // <--
	RET                 // <--                                  // ret

LBB1_9:
	XORL AX, AX         // <--                                  // xor	eax, eax
	MOVB AX, ret+32(FP) // <--
	RET                 // <--                                  // ret

LBB1_10:
	LEAQ         0(DI)(SI*1), CX     // <--                                  // lea	rcx, [rdi + rsi]
	WORD         $0xf089             // MOVL SI, AX                          // mov	eax, esi
	WORD         $0xe083; BYTE $0x3f // ANDL $0x3f, AX                       // and	eax, 63
	SUBQ         AX, CX              // <--                                  // sub	rcx, rax
	CMPQ         CX, DI              // <--                                  // cmp	rcx, rdi
	JBE          LBB1_14             // <--                                  // jbe	.LBB1_14
	VPBROADCASTB LCPI1_8<>(SB), Y0   // <--                                  // vpbroadcastb	ymm0, byte ptr [rip + .LCPI1_8]
	VPBROADCASTB LCPI1_9<>(SB), Y1   // <--                                  // vpbroadcastb	ymm1, byte ptr [rip + .LCPI1_9]
	VPBROADCASTB LCPI1_10<>(SB), Y2  // <--                                  // vpbroadcastb	ymm2, byte ptr [rip + .LCPI1_10]
	LONG         $0xdb76e5c5         // VPCMPEQD Y3, Y3, Y3                  // vpcmpeqd	ymm3, ymm3, ymm3

LBB1_12:
	LONG $0x276ffec5             // VMOVDQU 0(DI), Y4                    // vmovdqu	ymm4, ymmword ptr [rdi]
	LONG $0x6f6ffec5; BYTE $0x20 // VMOVDQU 0x20(DI), Y5                 // vmovdqu	ymm5, ymmword ptr [rdi + 32]
	LONG $0x32efddc5             // VPXOR 0(DX), Y4, Y6                  // vpxor	ymm6, ymm4, ymmword ptr [rdx]
	LONG $0xf874cdc5             // VPCMPEQB Y0, Y6, Y7                  // vpcmpeqb	ymm7, ymm6, ymm0
	LONG $0xe0ebddc5             // VPOR Y0, Y4, Y4                      // vpor	ymm4, ymm4, ymm0
	LONG $0xe1fcddc5             // VPADDB Y1, Y4, Y4                    // vpaddb	ymm4, ymm4, ymm1
	LONG $0xe464edc5             // VPCMPGTB Y4, Y2, Y4                  // vpcmpgtb	ymm4, ymm2, ymm4
	LONG $0xe4dbc5c5             // VPAND Y4, Y7, Y4                     // vpand	ymm4, ymm7, ymm4
	LONG $0xf471ddc5; BYTE $0x05 // VPSLLW $0x5, Y4, Y4                  // vpsllw	ymm4, ymm4, 5
	LONG $0xe0dbddc5             // VPAND Y0, Y4, Y4                     // vpand	ymm4, ymm4, ymm0
	LONG $0x7aefd5c5; BYTE $0x20 // VPXOR 0x20(DX), Y5, Y7               // vpxor	ymm7, ymm5, ymmword ptr [rdx + 32]
	LONG $0xe674ddc5             // VPCMPEQB Y6, Y4, Y4                  // vpcmpeqb	ymm4, ymm4, ymm6
	LONG $0xf074c5c5             // VPCMPEQB Y0, Y7, Y6                  // vpcmpeqb	ymm6, ymm7, ymm0
	LONG $0xe8ebd5c5             // VPOR Y0, Y5, Y5                      // vpor	ymm5, ymm5, ymm0
	LONG $0xe9fcd5c5             // VPADDB Y1, Y5, Y5                    // vpaddb	ymm5, ymm5, ymm1
	LONG $0xed64edc5             // VPCMPGTB Y5, Y2, Y5                  // vpcmpgtb	ymm5, ymm2, ymm5
	LONG $0xeddbcdc5             // VPAND Y5, Y6, Y5                     // vpand	ymm5, ymm6, ymm5
	LONG $0xf571d5c5; BYTE $0x05 // VPSLLW $0x5, Y5, Y5                  // vpsllw	ymm5, ymm5, 5
	LONG $0xe8dbd5c5             // VPAND Y0, Y5, Y5                     // vpand	ymm5, ymm5, ymm0
	LONG $0xef74d5c5             // VPCMPEQB Y7, Y5, Y5                  // vpcmpeqb	ymm5, ymm5, ymm7
	LONG $0xe4dbd5c5             // VPAND Y4, Y5, Y4                     // vpand	ymm4, ymm5, ymm4
	LONG $0x177de2c4; BYTE $0xe3 // VPTEST Y3, Y4                        // vptest	ymm4, ymm3
	JAE  LBB1_24                 // <--                                  // jae	.LBB1_24
	ADDQ $0x40, DI               // <--                                  // add	rdi, 64
	ADDQ $0x40, DX               // <--                                  // add	rdx, 64
	CMPQ DI, CX                  // <--                                  // cmp	rdi, rcx
	JB   LBB1_12                 // <--                                  // jb	.LBB1_12

LBB1_14:
	ADDQ         DI, AX              // <--                                  // add	rax, rdi
	WORD         $0xe683; BYTE $0x1f // ANDL $0x1f, SI                       // and	esi, 31
	SUBQ         SI, AX              // <--                                  // sub	rax, rsi
	CMPQ         DI, AX              // <--                                  // cmp	rdi, rax
	JAE          LBB1_18             // <--                                  // jae	.LBB1_18
	VPBROADCASTB LCPI1_8<>(SB), Y0   // <--                                  // vpbroadcastb	ymm0, byte ptr [rip + .LCPI1_8]
	VPBROADCASTB LCPI1_9<>(SB), Y1   // <--                                  // vpbroadcastb	ymm1, byte ptr [rip + .LCPI1_9]
	VPBROADCASTB LCPI1_11<>(SB), Y2  // <--                                  // vpbroadcastb	ymm2, byte ptr [rip + .LCPI1_11]
	LONG         $0xdb76e5c5         // VPCMPEQD Y3, Y3, Y3                  // vpcmpeqd	ymm3, ymm3, ymm3

LBB1_16:
	LONG $0x276ffec5             // VMOVDQU 0(DI), Y4                    // vmovdqu	ymm4, ymmword ptr [rdi]
	LONG $0x2aefddc5             // VPXOR 0(DX), Y4, Y5                  // vpxor	ymm5, ymm4, ymmword ptr [rdx]
	LONG $0xf074d5c5             // VPCMPEQB Y0, Y5, Y6                  // vpcmpeqb	ymm6, ymm5, ymm0
	LONG $0xe0ebddc5             // VPOR Y0, Y4, Y4                      // vpor	ymm4, ymm4, ymm0
	LONG $0xe1fcddc5             // VPADDB Y1, Y4, Y4                    // vpaddb	ymm4, ymm4, ymm1
	LONG $0xe264ddc5             // VPCMPGTB Y2, Y4, Y4                  // vpcmpgtb	ymm4, ymm4, ymm2
	LONG $0xe6dfddc5             // VPANDN Y6, Y4, Y4                    // vpandn	ymm4, ymm4, ymm6
	LONG $0xf471ddc5; BYTE $0x05 // VPSLLW $0x5, Y4, Y4                  // vpsllw	ymm4, ymm4, 5
	LONG $0xe0dbddc5             // VPAND Y0, Y4, Y4                     // vpand	ymm4, ymm4, ymm0
	LONG $0xe574ddc5             // VPCMPEQB Y5, Y4, Y4                  // vpcmpeqb	ymm4, ymm4, ymm5
	LONG $0x177de2c4; BYTE $0xe3 // VPTEST Y3, Y4                        // vptest	ymm4, ymm3
	JAE  LBB1_24                 // <--                                  // jae	.LBB1_24
	ADDQ $0x20, DI               // <--                                  // add	rdi, 32
	ADDQ $0x20, DX               // <--                                  // add	rdx, 32
	CMPQ DI, AX                  // <--                                  // cmp	rdi, rax
	JB   LBB1_16                 // <--                                  // jb	.LBB1_16

LBB1_18:
	WORD         $0x8548; BYTE $0xf6       // TESTQ SI, SI                         // test	rsi, rsi
	JE           LBB1_26                   // <--                                  // je	.LBB1_26
	LONG         $0x446ffec5; WORD $0xe037 // VMOVDQU -0x20(DI)(SI*1), Y0          // vmovdqu	ymm0, ymmword ptr [rdi + rsi - 32]
	LONG         $0x4ceffdc5; WORD $0xe032 // VPXOR -0x20(DX)(SI*1), Y0, Y1        // vpxor	ymm1, ymm0, ymmword ptr [rdx + rsi - 32]
	VPBROADCASTB LCPI1_8<>(SB), Y2         // <--                                  // vpbroadcastb	ymm2, byte ptr [rip + .LCPI1_8]
	LONG         $0xda74f5c5               // VPCMPEQB Y2, Y1, Y3                  // vpcmpeqb	ymm3, ymm1, ymm2
	LONG         $0xc2ebfdc5               // VPOR Y2, Y0, Y0                      // vpor	ymm0, ymm0, ymm2
	VPADDB       LCPI1_1<>(SB), Y0, Y0     // <--                                  // vpaddb	ymm0, ymm0, ymmword ptr [rip + .LCPI1_1]
	VPCMPGTB     LCPI1_3<>(SB), Y0, Y0     // <--                                  // vpcmpgtb	ymm0, ymm0, ymmword ptr [rip + .LCPI1_3]
	LONG         $0xc3dffdc5               // VPANDN Y3, Y0, Y0                    // vpandn	ymm0, ymm0, ymm3
	LONG         $0xf071fdc5; BYTE $0x05   // VPSLLW $0x5, Y0, Y0                  // vpsllw	ymm0, ymm0, 5
	LONG         $0xc2dbfdc5               // VPAND Y2, Y0, Y0                     // vpand	ymm0, ymm0, ymm2
	LONG         $0xc174fdc5               // VPCMPEQB Y1, Y0, Y0                  // vpcmpeqb	ymm0, ymm0, ymm1
	LONG         $0xc976f5c5               // VPCMPEQD Y1, Y1, Y1                  // vpcmpeqd	ymm1, ymm1, ymm1
	LONG         $0x177de2c4; BYTE $0xc1   // VPTEST Y1, Y0                        // vptest	ymm0, ymm1
	WORD         $0x920f; BYTE $0xc0       // SETB AL                              // setb	al
	NOP                                    // (skipped)                            // mov	rsp, rbp
	NOP                                    // (skipped)                            // pop	rbp
	VZEROUPPER                             // <--                                  // vzeroupper
	MOVB         AX, ret+32(FP)            // <--
	RET                                    // <--                                  // ret

LBB1_20:
	XORL         AX, AX             // <--                                  // xor	eax, eax
	VPBROADCASTB LCPI1_12<>(SB), X0 // <--                                  // vpbroadcastb	xmm0, byte ptr [rip + .LCPI1_12]
	VPBROADCASTB LCPI1_13<>(SB), X1 // <--                                  // vpbroadcastb	xmm1, byte ptr [rip + .LCPI1_13]
	VPBROADCASTB LCPI1_9<>(SB), X2  // <--                                  // vpbroadcastb	xmm2, byte ptr [rip + .LCPI1_9]
	VPBROADCASTB LCPI1_8<>(SB), X3  // <--                                  // vpbroadcastb	xmm3, byte ptr [rip + .LCPI1_8]
	JMP          LBB1_22            // <--                                  // jmp	.LBB1_22

LBB1_21:
	LEAQ 0x8(AX), CX // <--                                  // lea	rcx, [rax + 8]
	ADDQ $0x10, AX   // <--                                  // add	rax, 16
	CMPQ AX, SI      // <--                                  // cmp	rax, rsi
	MOVQ CX, AX      // <--                                  // mov	rax, rcx
	JA   LBB1_4      // <--                                  // ja	.LBB1_4

LBB1_22:
	MOVQ 0(DI)(AX*1), CX         // <--                                  // mov	rcx, qword ptr [rdi + rax]
	MOVQ 0(DX)(AX*1), R8         // <--                                  // mov	r8, qword ptr [rdx + rax]
	CMPQ CX, R8                  // <--                                  // cmp	rcx, r8
	JE   LBB1_21                 // <--                                  // je	.LBB1_21
	LONG $0x6ef9c1c4; BYTE $0xe0 // VMOVQ R8, X4                         // vmovq	xmm4, r8
	LONG $0x6ef9e1c4; BYTE $0xe9 // VMOVQ CX, X5                         // vmovq	xmm5, rcx
	LONG $0xe46cd1c5             // VPUNPCKLQDQ X4, X5, X4               // vpunpcklqdq	xmm4, xmm5, xmm4
	LONG $0xe8dbd9c5             // VPAND X0, X4, X5                     // vpand	xmm5, xmm4, xmm0
	LONG $0xf5fbf1c5             // VPSUBQ X5, X1, X6                    // vpsubq	xmm6, xmm1, xmm5
	LONG $0xf6dfd9c5             // VPANDN X6, X4, X6                    // vpandn	xmm6, xmm4, xmm6
	LONG $0xead4d1c5             // VPADDQ X2, X5, X5                    // vpaddq	xmm5, xmm5, xmm2
	LONG $0xeddbc9c5             // VPAND X5, X6, X5                     // vpand	xmm5, xmm6, xmm5
	LONG $0xd573d1c5; BYTE $0x02 // VPSRLQ $0x2, X5, X5                  // vpsrlq	xmm5, xmm5, 2
	LONG $0xebdbd1c5             // VPAND X3, X5, X5                     // vpand	xmm5, xmm5, xmm3
	LONG $0xe5fbd9c5             // VPSUBQ X5, X4, X4                    // vpsubq	xmm4, xmm4, xmm5
	LONG $0xec70f9c5; BYTE $0xee // VPSHUFD $-0x12, X4, X5               // vpshufd	xmm5, xmm4, 238
	LONG $0x2959e2c4; BYTE $0xe5 // VPCMPEQQ X5, X4, X4                  // vpcmpeqq	xmm4, xmm4, xmm5
	LONG $0xe17ef9c5             // VMOVD X4, CX                         // vmovd	ecx, xmm4
	WORD $0xc1f6; BYTE $0x01     // TESTL $0x1, CL                       // test	cl, 1
	JNE  LBB1_21                 // <--                                  // jne	.LBB1_21

LBB1_24:
	XORL AX, AX         // <--                                  // xor	eax, eax
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVB AX, ret+32(FP) // <--
	RET                 // <--                                  // ret

LBB1_26:
	WORD $0x01b0        // MOVL $0x1, AL                        // mov	al, 1
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVB AX, ret+32(FP) // <--
	RET                 // <--                                  // ret
