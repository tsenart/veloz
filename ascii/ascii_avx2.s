//go:build !noasm && amd64
// Code generated by gocc v0.16.5-rev-57c4d32 -- DO NOT EDIT.
//
// Source file         : ascii_avx2.c
// Clang version       : Apple clang version 17.0.0 (clang-1700.6.3.2)
// Target architecture : amd64
// Compiler options    : -mavx2 -mfma

#include "textflag.h"

DATA LCPI0_0<>+0x00(SB)/8, $0x8080808080808080
GLOBL LCPI0_0<>(SB), (RODATA|NOPTR), $8

DATA LCPI0_1<>+0x00(SB)/8, $0x8080808080808080
DATA LCPI0_1<>+0x08(SB)/8, $0x8080808080808080
GLOBL LCPI0_1<>(SB), (RODATA|NOPTR), $16

DATA LCPI0_2<>+0x00(SB)/1, $0x80
GLOBL LCPI0_2<>(SB), (RODATA|NOPTR), $1

TEXT 路isAsciiAvx(SB), NOSPLIT, $0-17
	MOVQ         src+0(FP), DI
	MOVQ         src_len+8(FP), SI
	NOP                              // (skipped)                            // push	rbp
	NOP                              // (skipped)                            // mov	rbp, rsp
	NOP                              // (skipped)                            // and	rsp, -8
	CMPQ         SI, $0x10           // <--                                  // cmp	rsi, 16
	JB           LBB0_13             // <--                                  // jb	.LBB0_13
	LEAQ         0(DI)(SI*1), CX     // <--                                  // lea	rcx, [rdi + rsi]
	WORD         $0xf089             // MOVL SI, AX                          // mov	eax, esi
	WORD         $0xe083; BYTE $0x7f // ANDL $0x7f, AX                       // and	eax, 127
	SUBQ         AX, CX              // <--                                  // sub	rcx, rax
	CMPQ         CX, DI              // <--                                  // cmp	rcx, rdi
	JBE          LBB0_5              // <--                                  // jbe	.LBB0_5
	VPBROADCASTQ LCPI0_0<>(SB), Y0   // <--                                  // vpbroadcastq	ymm0, qword ptr [rip + .LCPI0_0]

LBB0_3:
	LONG $0x4f6ffec5; BYTE $0x20 // VMOVDQU 0x20(DI), Y1                 // vmovdqu	ymm1, ymmword ptr [rdi + 32]
	LONG $0x0febf5c5             // VPOR 0(DI), Y1, Y1                   // vpor	ymm1, ymm1, ymmword ptr [rdi]
	LONG $0x4febf5c5; BYTE $0x40 // VPOR 0x40(DI), Y1, Y1                // vpor	ymm1, ymm1, ymmword ptr [rdi + 64]
	LONG $0x4febf5c5; BYTE $0x60 // VPOR 0x60(DI), Y1, Y1                // vpor	ymm1, ymm1, ymmword ptr [rdi + 96]
	LONG $0x177de2c4; BYTE $0xc8 // VPTEST Y0, Y1                        // vptest	ymm1, ymm0
	JNE  LBB0_19                 // <--                                  // jne	.LBB0_19
	SUBQ $-0x80, DI              // <--                                  // sub	rdi, -128
	CMPQ DI, CX                  // <--                                  // cmp	rdi, rcx
	JB   LBB0_3                  // <--                                  // jb	.LBB0_3

LBB0_5:
	ADDQ         DI, AX              // <--                                  // add	rax, rdi
	WORD         $0xf189             // MOVL SI, CX                          // mov	ecx, esi
	WORD         $0xe183; BYTE $0x1f // ANDL $0x1f, CX                       // and	ecx, 31
	SUBQ         CX, AX              // <--                                  // sub	rax, rcx
	CMPQ         DI, AX              // <--                                  // cmp	rdi, rax
	JAE          LBB0_9              // <--                                  // jae	.LBB0_9
	VPBROADCASTQ LCPI0_0<>(SB), Y0   // <--                                  // vpbroadcastq	ymm0, qword ptr [rip + .LCPI0_0]

LBB0_7:
	LONG $0x177de2c4; BYTE $0x07 // VPTEST 0(DI), Y0                     // vptest	ymm0, ymmword ptr [rdi]
	JNE  LBB0_19                 // <--                                  // jne	.LBB0_19
	ADDQ $0x20, DI               // <--                                  // add	rdi, 32
	CMPQ DI, AX                  // <--                                  // cmp	rdi, rax
	JB   LBB0_7                  // <--                                  // jb	.LBB0_7

LBB0_9:
	CMPL         CX, $0x10               // <--                                  // cmp	ecx, 16
	JB           LBB0_12                 // <--                                  // jb	.LBB0_12
	VPBROADCASTB LCPI0_2<>(SB), X0       // <--                                  // vpbroadcastb	xmm0, byte ptr [rip + .LCPI0_2]
	LONG         $0x1779e2c4; BYTE $0x07 // VPTEST 0(DI), X0                     // vptest	xmm0, xmmword ptr [rdi]
	JNE          LBB0_19                 // <--                                  // jne	.LBB0_19
	ADDQ         $0x10, DI               // <--                                  // add	rdi, 16

LBB0_12:
	WORD $0xe683; BYTE $0x0f // ANDL $0xf, SI                        // and	esi, 15

LBB0_13:
	WORD $0x8548; BYTE $0xf6 // TESTQ SI, SI                         // test	rsi, rsi
	JE   LBB0_17             // <--                                  // je	.LBB0_17
	CMPQ SI, $0x8            // <--                                  // cmp	rsi, 8
	JAE  LBB0_18             // <--                                  // jae	.LBB0_18
	CMPQ SI, $0x4            // <--                                  // cmp	rsi, 4
	JAE  LBB0_20             // <--                                  // jae	.LBB0_20
	MOVQ SI, AX              // <--                                  // mov	rax, rsi
	SHRQ $0x1, AX            // <--                                  // shr	rax
	LONG $0x0704b60f         // MOVZX 0(DI)(AX*1), AX                // movzx	eax, byte ptr [rdi + rax]
	ORB  0(DI), AL           // <--                                  // or	al, byte ptr [rdi]
	ORB  -0x1(DI)(SI*1), AL  // <--                                  // or	al, byte ptr [rdi + rsi - 1]
	WORD $0x990f; BYTE $0xc0 // SETNS AL                             // setns	al
	NOP                      // (skipped)                            // mov	rsp, rbp
	NOP                      // (skipped)                            // pop	rbp
	VZEROUPPER               // <--                                  // vzeroupper
	MOVB AX, ret+16(FP)      // <--
	RET                      // <--                                  // ret

LBB0_19:
	XORL AX, AX         // <--                                  // xor	eax, eax
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVB AX, ret+16(FP) // <--
	RET                 // <--                                  // ret

LBB0_17:
	WORD $0x01b0        // MOVL $0x1, AL                        // mov	al, 1
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVB AX, ret+16(FP) // <--
	RET                 // <--                                  // ret

LBB0_18:
	MOVQ -0x8(DI)(SI*1), AX                // <--                                  // mov	rax, qword ptr [rdi + rsi - 8]
	ORQ  0(DI), AX                         // <--                                  // or	rax, qword ptr [rdi]
	QUAD $0x808080808080b948; WORD $0x8080 // MOVQ $0x8080808080808080, CX         // movabs	rcx, -9187201950435737472
	WORD $0x8548; BYTE $0xc8               // TESTQ CX, AX                         // test	rax, rcx
	WORD $0x940f; BYTE $0xc0               // SETE AL                              // sete	al
	NOP                                    // (skipped)                            // mov	rsp, rbp
	NOP                                    // (skipped)                            // pop	rbp
	VZEROUPPER                             // <--                                  // vzeroupper
	MOVB AX, ret+16(FP)                    // <--
	RET                                    // <--                                  // ret

LBB0_20:
	LONG $0xfc37448b             // MOVL -0x4(DI)(SI*1), AX              // mov	eax, dword ptr [rdi + rsi - 4]
	WORD $0x070b                 // ORL 0(DI), AX                        // or	eax, dword ptr [rdi]
	LONG $0x808080a9; BYTE $0x80 // TESTL $-0x7f7f7f80, AX               // test	eax, -2139062144
	WORD $0x940f; BYTE $0xc0     // SETE AL                              // sete	al
	NOP                          // (skipped)                            // mov	rsp, rbp
	NOP                          // (skipped)                            // pop	rbp
	VZEROUPPER                   // <--                                  // vzeroupper
	MOVB AX, ret+16(FP)          // <--
	RET                          // <--                                  // ret

DATA LCPI1_0<>+0x00(SB)/8, $0x2020202020202020
DATA LCPI1_0<>+0x08(SB)/8, $0x2020202020202020
DATA LCPI1_0<>+0x10(SB)/8, $0x2020202020202020
DATA LCPI1_0<>+0x18(SB)/8, $0x2020202020202020
GLOBL LCPI1_0<>(SB), (RODATA|NOPTR), $32

DATA LCPI1_1<>+0x00(SB)/8, $0x1f1f1f1f1f1f1f1f
DATA LCPI1_1<>+0x08(SB)/8, $0x1f1f1f1f1f1f1f1f
DATA LCPI1_1<>+0x10(SB)/8, $0x1f1f1f1f1f1f1f1f
DATA LCPI1_1<>+0x18(SB)/8, $0x1f1f1f1f1f1f1f1f
GLOBL LCPI1_1<>(SB), (RODATA|NOPTR), $32

DATA LCPI1_2<>+0x00(SB)/8, $0x9a9a9a9a9a9a9a9a
DATA LCPI1_2<>+0x08(SB)/8, $0x9a9a9a9a9a9a9a9a
DATA LCPI1_2<>+0x10(SB)/8, $0x9a9a9a9a9a9a9a9a
DATA LCPI1_2<>+0x18(SB)/8, $0x9a9a9a9a9a9a9a9a
GLOBL LCPI1_2<>(SB), (RODATA|NOPTR), $32

DATA LCPI1_3<>+0x00(SB)/8, $0x9999999999999999
DATA LCPI1_3<>+0x08(SB)/8, $0x9999999999999999
DATA LCPI1_3<>+0x10(SB)/8, $0x9999999999999999
DATA LCPI1_3<>+0x18(SB)/8, $0x9999999999999999
GLOBL LCPI1_3<>(SB), (RODATA|NOPTR), $32

DATA LCPI1_4<>+0x00(SB)/8, $0x7f7f7f7f7f7f7f7f
DATA LCPI1_4<>+0x08(SB)/8, $0x7f7f7f7f7f7f7f7f
GLOBL LCPI1_4<>(SB), (RODATA|NOPTR), $16

DATA LCPI1_5<>+0x00(SB)/8, $0xfafafafafafafafa
DATA LCPI1_5<>+0x08(SB)/8, $0xfafafafafafafafa
GLOBL LCPI1_5<>(SB), (RODATA|NOPTR), $16

DATA LCPI1_6<>+0x00(SB)/8, $0x1f1f1f1f1f1f1f1f
DATA LCPI1_6<>+0x08(SB)/8, $0x1f1f1f1f1f1f1f1f
GLOBL LCPI1_6<>(SB), (RODATA|NOPTR), $16

DATA LCPI1_7<>+0x00(SB)/8, $0x2020202020202020
DATA LCPI1_7<>+0x08(SB)/8, $0x2020202020202020
GLOBL LCPI1_7<>(SB), (RODATA|NOPTR), $16

DATA LCPI1_8<>+0x00(SB)/1, $0x20
GLOBL LCPI1_8<>(SB), (RODATA|NOPTR), $1

DATA LCPI1_9<>+0x00(SB)/1, $0x1f
GLOBL LCPI1_9<>(SB), (RODATA|NOPTR), $1

DATA LCPI1_10<>+0x00(SB)/1, $0x9a
GLOBL LCPI1_10<>(SB), (RODATA|NOPTR), $1

DATA LCPI1_11<>+0x00(SB)/1, $0x99
GLOBL LCPI1_11<>(SB), (RODATA|NOPTR), $1

DATA LCPI1_12<>+0x00(SB)/1, $0x7f
GLOBL LCPI1_12<>(SB), (RODATA|NOPTR), $1

DATA LCPI1_13<>+0x00(SB)/1, $0xfa
GLOBL LCPI1_13<>(SB), (RODATA|NOPTR), $1

TEXT 路equalFoldAvx(SB), NOSPLIT, $0-33
	MOVQ a+0(FP), DI
	MOVQ a_len+8(FP), SI
	MOVQ b+16(FP), DX
	MOVQ b_len+24(FP), CX
	CMPQ SI, CX           // <--                                  // cmp	rsi, rcx
	JNE  LBB1_9           // <--                                  // jne	.LBB1_9
	NOP                   // (skipped)                            // push	rbp
	NOP                   // (skipped)                            // mov	rbp, rsp
	NOP                   // (skipped)                            // and	rsp, -8
	CMPQ SI, $0x1f        // <--                                  // cmp	rsi, 31
	JA   LBB1_10          // <--                                  // ja	.LBB1_10
	CMPQ SI, $0x8         // <--                                  // cmp	rsi, 8
	JAE  LBB1_20          // <--                                  // jae	.LBB1_20
	XORL CX, CX           // <--                                  // xor	ecx, ecx

LBB1_4:
	WORD $0x01b0 // MOVL $0x1, AL                        // mov	al, 1
	CMPQ CX, SI  // <--                                  // cmp	rcx, rsi
	JAE  LBB1_8  // <--                                  // jae	.LBB1_8
	DECQ SI      // <--                                  // dec	rsi

LBB1_6:
	LONG $0x0f04b60f             // MOVZX 0(DI)(CX*1), AX                // movzx	eax, byte ptr [rdi + rcx]
	LONG $0x14b60f44; BYTE $0x0a // MOVZX 0(DX)(CX*1), R10               // movzx	r10d, byte ptr [rdx + rcx]
	LONG $0x9f408d44             // LEAL -0x61(AX), R8                   // lea	r8d, [rax - 97]
	LONG $0xe0488d44             // LEAL -0x20(AX), R9                   // lea	r9d, [rax - 32]
	CMPB R8, $0x1a               // <--                                  // cmp	r8b, 26
	LONG $0xc1b60f45             // MOVZX R9, R8                         // movzx	r8d, r9b
	LONG $0xc0430f44             // CMOVAE AX, R8                        // cmovae	r8d, eax
	LONG $0x9f428d41             // LEAL -0x61(R10), AX                  // lea	eax, [r10 - 97]
	LONG $0xe04a8d45             // LEAL -0x20(R10), R9                  // lea	r9d, [r10 - 32]
	WORD $0x1a3c                 // CMPL AL, $0x1a                       // cmp	al, 26
	LONG $0xc9b60f45             // MOVZX R9, R9                         // movzx	r9d, r9b
	LONG $0xca430f45             // CMOVAE R10, R9                       // cmovae	r9d, r10d
	CMPB R8, R9                  // <--                                  // cmp	r8b, r9b
	WORD $0x940f; BYTE $0xc0     // SETE AL                              // sete	al
	CMPQ SI, CX                  // <--                                  // cmp	rsi, rcx
	JE   LBB1_8                  // <--                                  // je	.LBB1_8
	INCQ CX                      // <--                                  // inc	rcx
	CMPB R8, R9                  // <--                                  // cmp	r8b, r9b
	JE   LBB1_6                  // <--                                  // je	.LBB1_6

LBB1_8:
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	MOVB AX, ret+32(FP) // <--
	RET                 // <--                                  // ret

LBB1_9:
	XORL AX, AX         // <--                                  // xor	eax, eax
	MOVB AX, ret+32(FP) // <--
	RET                 // <--                                  // ret

LBB1_10:
	LEAQ         0(DI)(SI*1), CX     // <--                                  // lea	rcx, [rdi + rsi]
	WORD         $0xf089             // MOVL SI, AX                          // mov	eax, esi
	WORD         $0xe083; BYTE $0x3f // ANDL $0x3f, AX                       // and	eax, 63
	SUBQ         AX, CX              // <--                                  // sub	rcx, rax
	CMPQ         CX, DI              // <--                                  // cmp	rcx, rdi
	JBE          LBB1_14             // <--                                  // jbe	.LBB1_14
	VPBROADCASTB LCPI1_8<>(SB), Y0   // <--                                  // vpbroadcastb	ymm0, byte ptr [rip + .LCPI1_8]
	VPBROADCASTB LCPI1_9<>(SB), Y1   // <--                                  // vpbroadcastb	ymm1, byte ptr [rip + .LCPI1_9]
	VPBROADCASTB LCPI1_10<>(SB), Y2  // <--                                  // vpbroadcastb	ymm2, byte ptr [rip + .LCPI1_10]
	LONG         $0xdb76e5c5         // VPCMPEQD Y3, Y3, Y3                  // vpcmpeqd	ymm3, ymm3, ymm3

LBB1_12:
	LONG $0x276ffec5             // VMOVDQU 0(DI), Y4                    // vmovdqu	ymm4, ymmword ptr [rdi]
	LONG $0x6f6ffec5; BYTE $0x20 // VMOVDQU 0x20(DI), Y5                 // vmovdqu	ymm5, ymmword ptr [rdi + 32]
	LONG $0x32efddc5             // VPXOR 0(DX), Y4, Y6                  // vpxor	ymm6, ymm4, ymmword ptr [rdx]
	LONG $0xf874cdc5             // VPCMPEQB Y0, Y6, Y7                  // vpcmpeqb	ymm7, ymm6, ymm0
	LONG $0xe0ebddc5             // VPOR Y0, Y4, Y4                      // vpor	ymm4, ymm4, ymm0
	LONG $0xe1fcddc5             // VPADDB Y1, Y4, Y4                    // vpaddb	ymm4, ymm4, ymm1
	LONG $0xe464edc5             // VPCMPGTB Y4, Y2, Y4                  // vpcmpgtb	ymm4, ymm2, ymm4
	LONG $0xe4dbc5c5             // VPAND Y4, Y7, Y4                     // vpand	ymm4, ymm7, ymm4
	LONG $0xf471ddc5; BYTE $0x05 // VPSLLW $0x5, Y4, Y4                  // vpsllw	ymm4, ymm4, 5
	LONG $0xe0dbddc5             // VPAND Y0, Y4, Y4                     // vpand	ymm4, ymm4, ymm0
	LONG $0x7aefd5c5; BYTE $0x20 // VPXOR 0x20(DX), Y5, Y7               // vpxor	ymm7, ymm5, ymmword ptr [rdx + 32]
	LONG $0xe674ddc5             // VPCMPEQB Y6, Y4, Y4                  // vpcmpeqb	ymm4, ymm4, ymm6
	LONG $0xf074c5c5             // VPCMPEQB Y0, Y7, Y6                  // vpcmpeqb	ymm6, ymm7, ymm0
	LONG $0xe8ebd5c5             // VPOR Y0, Y5, Y5                      // vpor	ymm5, ymm5, ymm0
	LONG $0xe9fcd5c5             // VPADDB Y1, Y5, Y5                    // vpaddb	ymm5, ymm5, ymm1
	LONG $0xed64edc5             // VPCMPGTB Y5, Y2, Y5                  // vpcmpgtb	ymm5, ymm2, ymm5
	LONG $0xeddbcdc5             // VPAND Y5, Y6, Y5                     // vpand	ymm5, ymm6, ymm5
	LONG $0xf571d5c5; BYTE $0x05 // VPSLLW $0x5, Y5, Y5                  // vpsllw	ymm5, ymm5, 5
	LONG $0xe8dbd5c5             // VPAND Y0, Y5, Y5                     // vpand	ymm5, ymm5, ymm0
	LONG $0xef74d5c5             // VPCMPEQB Y7, Y5, Y5                  // vpcmpeqb	ymm5, ymm5, ymm7
	LONG $0xe4dbd5c5             // VPAND Y4, Y5, Y4                     // vpand	ymm4, ymm5, ymm4
	LONG $0x177de2c4; BYTE $0xe3 // VPTEST Y3, Y4                        // vptest	ymm4, ymm3
	JAE  LBB1_24                 // <--                                  // jae	.LBB1_24
	ADDQ $0x40, DI               // <--                                  // add	rdi, 64
	ADDQ $0x40, DX               // <--                                  // add	rdx, 64
	CMPQ DI, CX                  // <--                                  // cmp	rdi, rcx
	JB   LBB1_12                 // <--                                  // jb	.LBB1_12

LBB1_14:
	ADDQ         DI, AX              // <--                                  // add	rax, rdi
	WORD         $0xe683; BYTE $0x1f // ANDL $0x1f, SI                       // and	esi, 31
	SUBQ         SI, AX              // <--                                  // sub	rax, rsi
	CMPQ         DI, AX              // <--                                  // cmp	rdi, rax
	JAE          LBB1_18             // <--                                  // jae	.LBB1_18
	VPBROADCASTB LCPI1_8<>(SB), Y0   // <--                                  // vpbroadcastb	ymm0, byte ptr [rip + .LCPI1_8]
	VPBROADCASTB LCPI1_9<>(SB), Y1   // <--                                  // vpbroadcastb	ymm1, byte ptr [rip + .LCPI1_9]
	VPBROADCASTB LCPI1_11<>(SB), Y2  // <--                                  // vpbroadcastb	ymm2, byte ptr [rip + .LCPI1_11]
	LONG         $0xdb76e5c5         // VPCMPEQD Y3, Y3, Y3                  // vpcmpeqd	ymm3, ymm3, ymm3

LBB1_16:
	LONG $0x276ffec5             // VMOVDQU 0(DI), Y4                    // vmovdqu	ymm4, ymmword ptr [rdi]
	LONG $0x2aefddc5             // VPXOR 0(DX), Y4, Y5                  // vpxor	ymm5, ymm4, ymmword ptr [rdx]
	LONG $0xf074d5c5             // VPCMPEQB Y0, Y5, Y6                  // vpcmpeqb	ymm6, ymm5, ymm0
	LONG $0xe0ebddc5             // VPOR Y0, Y4, Y4                      // vpor	ymm4, ymm4, ymm0
	LONG $0xe1fcddc5             // VPADDB Y1, Y4, Y4                    // vpaddb	ymm4, ymm4, ymm1
	LONG $0xe264ddc5             // VPCMPGTB Y2, Y4, Y4                  // vpcmpgtb	ymm4, ymm4, ymm2
	LONG $0xe6dfddc5             // VPANDN Y6, Y4, Y4                    // vpandn	ymm4, ymm4, ymm6
	LONG $0xf471ddc5; BYTE $0x05 // VPSLLW $0x5, Y4, Y4                  // vpsllw	ymm4, ymm4, 5
	LONG $0xe0dbddc5             // VPAND Y0, Y4, Y4                     // vpand	ymm4, ymm4, ymm0
	LONG $0xe574ddc5             // VPCMPEQB Y5, Y4, Y4                  // vpcmpeqb	ymm4, ymm4, ymm5
	LONG $0x177de2c4; BYTE $0xe3 // VPTEST Y3, Y4                        // vptest	ymm4, ymm3
	JAE  LBB1_24                 // <--                                  // jae	.LBB1_24
	ADDQ $0x20, DI               // <--                                  // add	rdi, 32
	ADDQ $0x20, DX               // <--                                  // add	rdx, 32
	CMPQ DI, AX                  // <--                                  // cmp	rdi, rax
	JB   LBB1_16                 // <--                                  // jb	.LBB1_16

LBB1_18:
	WORD         $0x8548; BYTE $0xf6       // TESTQ SI, SI                         // test	rsi, rsi
	JE           LBB1_26                   // <--                                  // je	.LBB1_26
	LONG         $0x446ffec5; WORD $0xe037 // VMOVDQU -0x20(DI)(SI*1), Y0          // vmovdqu	ymm0, ymmword ptr [rdi + rsi - 32]
	LONG         $0x4ceffdc5; WORD $0xe032 // VPXOR -0x20(DX)(SI*1), Y0, Y1        // vpxor	ymm1, ymm0, ymmword ptr [rdx + rsi - 32]
	VPBROADCASTB LCPI1_8<>(SB), Y2         // <--                                  // vpbroadcastb	ymm2, byte ptr [rip + .LCPI1_8]
	LONG         $0xda74f5c5               // VPCMPEQB Y2, Y1, Y3                  // vpcmpeqb	ymm3, ymm1, ymm2
	LONG         $0xc2ebfdc5               // VPOR Y2, Y0, Y0                      // vpor	ymm0, ymm0, ymm2
	VPADDB       LCPI1_1<>(SB), Y0, Y0     // <--                                  // vpaddb	ymm0, ymm0, ymmword ptr [rip + .LCPI1_1]
	VPCMPGTB     LCPI1_3<>(SB), Y0, Y0     // <--                                  // vpcmpgtb	ymm0, ymm0, ymmword ptr [rip + .LCPI1_3]
	LONG         $0xc3dffdc5               // VPANDN Y3, Y0, Y0                    // vpandn	ymm0, ymm0, ymm3
	LONG         $0xf071fdc5; BYTE $0x05   // VPSLLW $0x5, Y0, Y0                  // vpsllw	ymm0, ymm0, 5
	LONG         $0xc2dbfdc5               // VPAND Y2, Y0, Y0                     // vpand	ymm0, ymm0, ymm2
	LONG         $0xc174fdc5               // VPCMPEQB Y1, Y0, Y0                  // vpcmpeqb	ymm0, ymm0, ymm1
	LONG         $0xc976f5c5               // VPCMPEQD Y1, Y1, Y1                  // vpcmpeqd	ymm1, ymm1, ymm1
	LONG         $0x177de2c4; BYTE $0xc1   // VPTEST Y1, Y0                        // vptest	ymm0, ymm1
	WORD         $0x920f; BYTE $0xc0       // SETB AL                              // setb	al
	NOP                                    // (skipped)                            // mov	rsp, rbp
	NOP                                    // (skipped)                            // pop	rbp
	VZEROUPPER                             // <--                                  // vzeroupper
	MOVB         AX, ret+32(FP)            // <--
	RET                                    // <--                                  // ret

LBB1_20:
	XORL         AX, AX             // <--                                  // xor	eax, eax
	VPBROADCASTB LCPI1_12<>(SB), X0 // <--                                  // vpbroadcastb	xmm0, byte ptr [rip + .LCPI1_12]
	VPBROADCASTB LCPI1_13<>(SB), X1 // <--                                  // vpbroadcastb	xmm1, byte ptr [rip + .LCPI1_13]
	VPBROADCASTB LCPI1_9<>(SB), X2  // <--                                  // vpbroadcastb	xmm2, byte ptr [rip + .LCPI1_9]
	VPBROADCASTB LCPI1_8<>(SB), X3  // <--                                  // vpbroadcastb	xmm3, byte ptr [rip + .LCPI1_8]
	JMP          LBB1_22            // <--                                  // jmp	.LBB1_22

LBB1_21:
	LEAQ 0x8(AX), CX // <--                                  // lea	rcx, [rax + 8]
	ADDQ $0x10, AX   // <--                                  // add	rax, 16
	CMPQ AX, SI      // <--                                  // cmp	rax, rsi
	MOVQ CX, AX      // <--                                  // mov	rax, rcx
	JA   LBB1_4      // <--                                  // ja	.LBB1_4

LBB1_22:
	MOVQ 0(DI)(AX*1), CX         // <--                                  // mov	rcx, qword ptr [rdi + rax]
	MOVQ 0(DX)(AX*1), R8         // <--                                  // mov	r8, qword ptr [rdx + rax]
	CMPQ CX, R8                  // <--                                  // cmp	rcx, r8
	JE   LBB1_21                 // <--                                  // je	.LBB1_21
	LONG $0x6ef9c1c4; BYTE $0xe0 // VMOVQ R8, X4                         // vmovq	xmm4, r8
	LONG $0x6ef9e1c4; BYTE $0xe9 // VMOVQ CX, X5                         // vmovq	xmm5, rcx
	LONG $0xe46cd1c5             // VPUNPCKLQDQ X4, X5, X4               // vpunpcklqdq	xmm4, xmm5, xmm4
	LONG $0xe8dbd9c5             // VPAND X0, X4, X5                     // vpand	xmm5, xmm4, xmm0
	LONG $0xf5fbf1c5             // VPSUBQ X5, X1, X6                    // vpsubq	xmm6, xmm1, xmm5
	LONG $0xf6dfd9c5             // VPANDN X6, X4, X6                    // vpandn	xmm6, xmm4, xmm6
	LONG $0xead4d1c5             // VPADDQ X2, X5, X5                    // vpaddq	xmm5, xmm5, xmm2
	LONG $0xeddbc9c5             // VPAND X5, X6, X5                     // vpand	xmm5, xmm6, xmm5
	LONG $0xd573d1c5; BYTE $0x02 // VPSRLQ $0x2, X5, X5                  // vpsrlq	xmm5, xmm5, 2
	LONG $0xebdbd1c5             // VPAND X3, X5, X5                     // vpand	xmm5, xmm5, xmm3
	LONG $0xe5fbd9c5             // VPSUBQ X5, X4, X4                    // vpsubq	xmm4, xmm4, xmm5
	LONG $0xec70f9c5; BYTE $0xee // VPSHUFD $-0x12, X4, X5               // vpshufd	xmm5, xmm4, 238
	LONG $0x2959e2c4; BYTE $0xe5 // VPCMPEQQ X5, X4, X4                  // vpcmpeqq	xmm4, xmm4, xmm5
	LONG $0xe17ef9c5             // VMOVD X4, CX                         // vmovd	ecx, xmm4
	WORD $0xc1f6; BYTE $0x01     // TESTL $0x1, CL                       // test	cl, 1
	JNE  LBB1_21                 // <--                                  // jne	.LBB1_21

LBB1_24:
	XORL AX, AX         // <--                                  // xor	eax, eax
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVB AX, ret+32(FP) // <--
	RET                 // <--                                  // ret

LBB1_26:
	WORD $0x01b0        // MOVL $0x1, AL                        // mov	al, 1
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVB AX, ret+32(FP) // <--
	RET                 // <--                                  // ret

TEXT 路indexMaskAvx(SB), NOSPLIT, $0-32
	MOVQ    data+0(FP), DI
	MOVQ    length+8(FP), SI
	MOVBQZX mask+16(FP), DX
	NOP                             // (skipped)                            // push	rbp
	NOP                             // (skipped)                            // mov	rbp, rsp
	NOP                             // (skipped)                            // and	rsp, -8
	CMPQ    SI, $0x10               // <--                                  // cmp	rsi, 16
	JB      LBB2_19                 // <--                                  // jb	.LBB2_19
	LONG    $0xc26ef9c5             // VMOVD DX, X0                         // vmovd	xmm0, edx
	LONG    $0x787de2c4; BYTE $0xc0 // VPBROADCASTB X0, Y0                  // vpbroadcastb	ymm0, xmm0
	LEAQ    0(DI)(SI*1), R8         // <--                                  // lea	r8, [rdi + rsi]
	WORD    $0xf089                 // MOVL SI, AX                          // mov	eax, esi
	WORD    $0xe083; BYTE $0x7f     // ANDL $0x7f, AX                       // and	eax, 127
	SUBQ    AX, R8                  // <--                                  // sub	r8, rax
	MOVQ    DI, CX                  // <--                                  // mov	rcx, rdi
	CMPQ    R8, DI                  // <--                                  // cmp	r8, rdi
	JBE     LBB2_6                  // <--                                  // jbe	.LBB2_6
	XORL    CX, CX                  // <--                                  // xor	ecx, ecx

LBB2_3:
	LONG $0x246ffec5; BYTE $0x0f   // VMOVDQU 0(DI)(CX*1), Y4              // vmovdqu	ymm4, ymmword ptr [rdi + rcx]
	LONG $0x5c6ffec5; WORD $0x200f // VMOVDQU 0x20(DI)(CX*1), Y3           // vmovdqu	ymm3, ymmword ptr [rdi + rcx + 32]
	LONG $0x546ffec5; WORD $0x400f // VMOVDQU 0x40(DI)(CX*1), Y2           // vmovdqu	ymm2, ymmword ptr [rdi + rcx + 64]
	LONG $0x4c6ffec5; WORD $0x600f // VMOVDQU 0x60(DI)(CX*1), Y1           // vmovdqu	ymm1, ymmword ptr [rdi + rcx + 96]
	LONG $0xecebe5c5               // VPOR Y4, Y3, Y5                      // vpor	ymm5, ymm3, ymm4
	LONG $0xf1ebedc5               // VPOR Y1, Y2, Y6                      // vpor	ymm6, ymm2, ymm1
	LONG $0xeeebd5c5               // VPOR Y6, Y5, Y5                      // vpor	ymm5, ymm5, ymm6
	LONG $0x177de2c4; BYTE $0xe8   // VPTEST Y0, Y5                        // vptest	ymm5, ymm0
	JNE  LBB2_29                   // <--                                  // jne	.LBB2_29
	LEAQ 0(DI)(CX*1), R9           // <--                                  // lea	r9, [rdi + rcx]
	SUBQ $-0x80, CX                // <--                                  // sub	rcx, -128
	SUBQ $-0x80, R9                // <--                                  // sub	r9, -128
	CMPQ R9, R8                    // <--                                  // cmp	r9, r8
	JB   LBB2_3                    // <--                                  // jb	.LBB2_3
	ADDQ DI, CX                    // <--                                  // add	rcx, rdi

LBB2_6:
	ADDQ CX, AX              // <--                                  // add	rax, rcx
	WORD $0xe683; BYTE $0x1f // ANDL $0x1f, SI                       // and	esi, 31
	SUBQ SI, AX              // <--                                  // sub	rax, rsi
	CMPQ CX, AX              // <--                                  // cmp	rcx, rax
	JAE  LBB2_10             // <--                                  // jae	.LBB2_10
	MOVQ CX, R8              // <--                                  // mov	r8, rcx
	SUBQ DI, R8              // <--                                  // sub	r8, rdi

LBB2_8:
	LONG $0x096ffec5             // VMOVDQU 0(CX), Y1                    // vmovdqu	ymm1, ymmword ptr [rcx]
	LONG $0x177de2c4; BYTE $0xc8 // VPTEST Y0, Y1                        // vptest	ymm1, ymm0
	JNE  LBB2_32                 // <--                                  // jne	.LBB2_32
	ADDQ $0x20, CX               // <--                                  // add	rcx, 32
	ADDQ $0x20, R8               // <--                                  // add	r8, 32
	CMPQ CX, AX                  // <--                                  // cmp	rcx, rax
	JB   LBB2_8                  // <--                                  // jb	.LBB2_8

LBB2_10:
	CMPL SI, $0x10               // <--                                  // cmp	esi, 16
	JB   LBB2_13                 // <--                                  // jb	.LBB2_13
	LONG $0x096ffac5             // VMOVDQU 0(CX), X1                    // vmovdqu	xmm1, xmmword ptr [rcx]
	LONG $0x1779e2c4; BYTE $0xc8 // VPTEST X0, X1                        // vptest	xmm1, xmm0
	JNE  LBB2_35                 // <--                                  // jne	.LBB2_35
	ADDQ $0x10, CX               // <--                                  // add	rcx, 16
	ADDQ $-0x10, SI              // <--                                  // add	rsi, -16

LBB2_13:
	WORD $0xb60f; BYTE $0xc2       // MOVZX DL, AX                         // movzx	eax, dl
	LONG $0x0101c069; WORD $0x0101 // IMULL $0x1010101, AX, AX             // imul	eax, eax, 16843009
	CMPQ SI, $0x8                  // <--                                  // cmp	rsi, 8
	JB   LBB2_14                   // <--                                  // jb	.LBB2_14

LBB2_20:
	WORD $0x8941; BYTE $0xc0     // MOVL AX, R8                          // mov	r8d, eax
	MOVQ R8, DX                  // <--                                  // mov	rdx, r8
	SHLQ $0x20, DX               // <--                                  // shl	rdx, 32
	ORQ  R8, DX                  // <--                                  // or	rdx, r8
	ANDQ 0(CX), DX               // <--                                  // and	rdx, qword ptr [rcx]
	JE   LBB2_22                 // <--                                  // je	.LBB2_22
	SUBQ DI, CX                  // <--                                  // sub	rcx, rdi
	LONG $0xbc0f48f3; BYTE $0xc2 // TZCNT DX, AX                         // rep		bsf	rax, rdx
	JMP  LBB2_28                 // <--                                  // jmp	.LBB2_28

LBB2_19:
	MOVQ DI, CX                    // <--                                  // mov	rcx, rdi
	WORD $0xb60f; BYTE $0xc2       // MOVZX DL, AX                         // movzx	eax, dl
	LONG $0x0101c069; WORD $0x0101 // IMULL $0x1010101, AX, AX             // imul	eax, eax, 16843009
	CMPQ SI, $0x8                  // <--                                  // cmp	rsi, 8
	JAE  LBB2_20                   // <--                                  // jae	.LBB2_20

LBB2_14:
	CMPQ SI, $0x4 // <--                                  // cmp	rsi, 4
	JB   LBB2_15  // <--                                  // jb	.LBB2_15

LBB2_23:
	WORD $0x118b   // MOVL 0(CX), DX                       // mov	edx, dword ptr [rcx]
	WORD $0xc221   // ANDL AX, DX                          // and	edx, eax
	JNE  LBB2_27   // <--                                  // jne	.LBB2_27
	ADDQ $0x4, CX  // <--                                  // add	rcx, 4
	ADDQ $-0x4, SI // <--                                  // add	rsi, -4
	CMPQ SI, $0x1  // <--                                  // cmp	rsi, 1
	JNE  LBB2_16   // <--                                  // jne	.LBB2_16

LBB2_25:
	WORD $0xb60f; BYTE $0x11 // MOVZX 0(CX), DX                      // movzx	edx, byte ptr [rcx]
	JMP  LBB2_26             // <--                                  // jmp	.LBB2_26

LBB2_22:
	ADDQ $0x8, CX  // <--                                  // add	rcx, 8
	ADDQ $-0x8, SI // <--                                  // add	rsi, -8
	CMPQ SI, $0x4  // <--                                  // cmp	rsi, 4
	JAE  LBB2_23   // <--                                  // jae	.LBB2_23

LBB2_15:
	CMPQ SI, $0x1 // <--                                  // cmp	rsi, 1
	JE   LBB2_25  // <--                                  // je	.LBB2_25

LBB2_16:
	CMPQ SI, $0x2            // <--                                  // cmp	rsi, 2
	JE   LBB2_33             // <--                                  // je	.LBB2_33
	XORL DX, DX              // <--                                  // xor	edx, edx
	CMPQ SI, $0x3            // <--                                  // cmp	rsi, 3
	JNE  LBB2_26             // <--                                  // jne	.LBB2_26
	WORD $0xb70f; BYTE $0x31 // MOVZX 0(CX), SI                      // movzx	esi, word ptr [rcx]
	LONG $0x0251b60f         // MOVZX 0x2(CX), DX                    // movzx	edx, byte ptr [rcx + 2]
	WORD $0xe2c1; BYTE $0x10 // SHLL $0x10, DX                       // shl	edx, 16
	WORD $0xf209             // ORL SI, DX                           // or	edx, esi
	WORD $0xc221             // ANDL AX, DX                          // and	edx, eax
	JNE  LBB2_27             // <--                                  // jne	.LBB2_27
	JMP  LBB2_34             // <--                                  // jmp	.LBB2_34

LBB2_26:
	WORD $0xc221 // ANDL AX, DX                          // and	edx, eax
	JE   LBB2_34 // <--                                  // je	.LBB2_34

LBB2_27:
	SUBQ DI, CX      // <--                                  // sub	rcx, rdi
	LONG $0xc2bc0ff3 // TZCNT DX, AX                         // rep		bsf	eax, edx

LBB2_28:
	WORD $0xe8c1; BYTE $0x03 // SHRL $0x3, AX                        // shr	eax, 3
	ADDQ CX, AX              // <--                                  // add	rax, rcx
	NOP                      // (skipped)                            // mov	rsp, rbp
	NOP                      // (skipped)                            // pop	rbp
	VZEROUPPER               // <--                                  // vzeroupper
	MOVQ AX, ret+24(FP)      // <--
	RET                      // <--                                  // ret

LBB2_29:
	LONG $0xe8dbddc5 // VPAND Y0, Y4, Y5                     // vpand	ymm5, ymm4, ymm0
	LONG $0xe4efd9c5 // VPXOR X4, X4, X4                     // vpxor	xmm4, xmm4, xmm4
	LONG $0xec74d5c5 // VPCMPEQB Y4, Y5, Y5                  // vpcmpeqb	ymm5, ymm5, ymm4
	LONG $0xc5d7fdc5 // VPMOVMSKB Y5, AX                     // vpmovmskb	eax, ymm5
	CMPL AX, $-0x1   // <--                                  // cmp	eax, -1
	JE   LBB2_36     // <--                                  // je	.LBB2_36
	WORD $0xd0f7     // NOTL AX                              // not	eax
	JMP  LBB2_31     // <--                                  // jmp	.LBB2_31

LBB2_32:
	LONG $0xc0dbf5c5    // VPAND Y0, Y1, Y0                     // vpand	ymm0, ymm1, ymm0
	LONG $0xc9eff1c5    // VPXOR X1, X1, X1                     // vpxor	xmm1, xmm1, xmm1
	LONG $0xc174fdc5    // VPCMPEQB Y1, Y0, Y0                  // vpcmpeqb	ymm0, ymm0, ymm1
	LONG $0xc0d7fdc5    // VPMOVMSKB Y0, AX                     // vpmovmskb	eax, ymm0
	WORD $0xd0f7        // NOTL AX                              // not	eax
	LONG $0xc0bc0ff3    // TZCNT AX, AX                         // rep		bsf	eax, eax
	ADDQ R8, AX         // <--                                  // add	rax, r8
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVQ AX, ret+24(FP) // <--
	RET                 // <--                                  // ret

LBB2_33:
	WORD $0xb70f; BYTE $0x11 // MOVZX 0(CX), DX                      // movzx	edx, word ptr [rcx]
	WORD $0xc221             // ANDL AX, DX                          // and	edx, eax
	JNE  LBB2_27             // <--                                  // jne	.LBB2_27

LBB2_34:
	MOVQ $-0x1, AX      // <--                                  // mov	rax, -1
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVQ AX, ret+24(FP) // <--
	RET                 // <--                                  // ret

LBB2_35:
	LONG $0xc0dbf1c5 // VPAND X0, X1, X0                     // vpand	xmm0, xmm1, xmm0
	LONG $0xc9eff1c5 // VPXOR X1, X1, X1                     // vpxor	xmm1, xmm1, xmm1
	LONG $0xc174f9c5 // VPCMPEQB X1, X0, X0                  // vpcmpeqb	xmm0, xmm0, xmm1
	LONG $0xc0d7f9c5 // VPMOVMSKB X0, AX                     // vpmovmskb	eax, xmm0
	WORD $0xd0f7     // NOTL AX                              // not	eax
	SUBQ DI, CX      // <--                                  // sub	rcx, rdi

LBB2_31:
	LONG $0xc0bc0ff3    // TZCNT AX, AX                         // rep		bsf	eax, eax
	ADDQ CX, AX         // <--                                  // add	rax, rcx
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVQ AX, ret+24(FP) // <--
	RET                 // <--                                  // ret

LBB2_36:
	LONG $0xd8dbe5c5    // VPAND Y0, Y3, Y3                     // vpand	ymm3, ymm3, ymm0
	LONG $0xdc74e5c5    // VPCMPEQB Y4, Y3, Y3                  // vpcmpeqb	ymm3, ymm3, ymm4
	LONG $0xc3d7fdc5    // VPMOVMSKB Y3, AX                     // vpmovmskb	eax, ymm3
	CMPL AX, $-0x1      // <--                                  // cmp	eax, -1
	JE   LBB2_38        // <--                                  // je	.LBB2_38
	WORD $0xd0f7        // NOTL AX                              // not	eax
	LONG $0xc0bc0ff3    // TZCNT AX, AX                         // rep		bsf	eax, eax
	ADDQ CX, AX         // <--                                  // add	rax, rcx
	ADDQ $0x20, AX      // <--                                  // add	rax, 32
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVQ AX, ret+24(FP) // <--
	RET                 // <--                                  // ret

LBB2_38:
	LONG $0xd8dbedc5    // VPAND Y0, Y2, Y3                     // vpand	ymm3, ymm2, ymm0
	LONG $0xd2efe9c5    // VPXOR X2, X2, X2                     // vpxor	xmm2, xmm2, xmm2
	LONG $0xda74e5c5    // VPCMPEQB Y2, Y3, Y3                  // vpcmpeqb	ymm3, ymm3, ymm2
	LONG $0xc3d7fdc5    // VPMOVMSKB Y3, AX                     // vpmovmskb	eax, ymm3
	CMPL AX, $-0x1      // <--                                  // cmp	eax, -1
	JE   LBB2_40        // <--                                  // je	.LBB2_40
	WORD $0xd0f7        // NOTL AX                              // not	eax
	LONG $0xc0bc0ff3    // TZCNT AX, AX                         // rep		bsf	eax, eax
	ADDQ CX, AX         // <--                                  // add	rax, rcx
	ADDQ $0x40, AX      // <--                                  // add	rax, 64
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVQ AX, ret+24(FP) // <--
	RET                 // <--                                  // ret

LBB2_40:
	LONG $0xc0dbf5c5    // VPAND Y0, Y1, Y0                     // vpand	ymm0, ymm1, ymm0
	LONG $0xc274fdc5    // VPCMPEQB Y2, Y0, Y0                  // vpcmpeqb	ymm0, ymm0, ymm2
	LONG $0xc0d7fdc5    // VPMOVMSKB Y0, AX                     // vpmovmskb	eax, ymm0
	WORD $0xd0f7        // NOTL AX                              // not	eax
	LONG $0xc0bc0ff3    // TZCNT AX, AX                         // rep		bsf	eax, eax
	ADDQ CX, AX         // <--                                  // add	rax, rcx
	ADDQ $0x60, AX      // <--                                  // add	rax, 96
	NOP                 // (skipped)                            // mov	rsp, rbp
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVQ AX, ret+24(FP) // <--
	RET                 // <--                                  // ret

DATA LCPI3_0<>+0x00(SB)/8, $0x1f1f1f1f1f1f1f1f
DATA LCPI3_0<>+0x08(SB)/8, $0x1f1f1f1f1f1f1f1f
DATA LCPI3_0<>+0x10(SB)/8, $0x1f1f1f1f1f1f1f1f
DATA LCPI3_0<>+0x18(SB)/8, $0x1f1f1f1f1f1f1f1f
GLOBL LCPI3_0<>(SB), (RODATA|NOPTR), $32

DATA LCPI3_1<>+0x00(SB)/8, $0x9999999999999999
DATA LCPI3_1<>+0x08(SB)/8, $0x9999999999999999
DATA LCPI3_1<>+0x10(SB)/8, $0x9999999999999999
DATA LCPI3_1<>+0x18(SB)/8, $0x9999999999999999
GLOBL LCPI3_1<>(SB), (RODATA|NOPTR), $32

DATA LCPI3_2<>+0x00(SB)/8, $0xe0e0e0e0e0e0e0e0
DATA LCPI3_2<>+0x08(SB)/8, $0xe0e0e0e0e0e0e0e0
DATA LCPI3_2<>+0x10(SB)/8, $0xe0e0e0e0e0e0e0e0
DATA LCPI3_2<>+0x18(SB)/8, $0xe0e0e0e0e0e0e0e0
GLOBL LCPI3_2<>(SB), (RODATA|NOPTR), $32

DATA LCPI3_3<>+0x00(SB)/8, $0x1f1f1f1f1f1f1f1f
DATA LCPI3_3<>+0x08(SB)/8, $0x1f1f1f1f1f1f1f1f
GLOBL LCPI3_3<>(SB), (RODATA|NOPTR), $16

DATA LCPI3_4<>+0x00(SB)/8, $0x9999999999999999
DATA LCPI3_4<>+0x08(SB)/8, $0x9999999999999999
GLOBL LCPI3_4<>(SB), (RODATA|NOPTR), $16

DATA LCPI3_5<>+0x00(SB)/8, $0xe0e0e0e0e0e0e0e0
DATA LCPI3_5<>+0x08(SB)/8, $0xe0e0e0e0e0e0e0e0
GLOBL LCPI3_5<>(SB), (RODATA|NOPTR), $16

DATA LCPI3_6<>+0x00(SB)/8, $0x7f7f7f7f7f7f7f7f
DATA LCPI3_6<>+0x08(SB)/8, $0x7f7f7f7f7f7f7f7f
GLOBL LCPI3_6<>(SB), (RODATA|NOPTR), $16

DATA LCPI3_7<>+0x00(SB)/8, $0xfafafafafafafafa
DATA LCPI3_7<>+0x08(SB)/8, $0xfafafafafafafafa
GLOBL LCPI3_7<>(SB), (RODATA|NOPTR), $16

DATA LCPI3_8<>+0x00(SB)/8, $0x2020202020202020
DATA LCPI3_8<>+0x08(SB)/8, $0x2020202020202020
GLOBL LCPI3_8<>(SB), (RODATA|NOPTR), $16

DATA LCPI3_9<>+0x00(SB)/1, $0x1f
GLOBL LCPI3_9<>(SB), (RODATA|NOPTR), $1

DATA LCPI3_10<>+0x00(SB)/1, $0x99
GLOBL LCPI3_10<>(SB), (RODATA|NOPTR), $1

DATA LCPI3_11<>+0x00(SB)/1, $0xe0
GLOBL LCPI3_11<>(SB), (RODATA|NOPTR), $1

DATA LCPI3_12<>+0x00(SB)/1, $0x7f
GLOBL LCPI3_12<>(SB), (RODATA|NOPTR), $1

DATA LCPI3_13<>+0x00(SB)/1, $0xfa
GLOBL LCPI3_13<>(SB), (RODATA|NOPTR), $1

DATA LCPI3_14<>+0x00(SB)/1, $0x20
GLOBL LCPI3_14<>(SB), (RODATA|NOPTR), $1

TEXT 路indexFoldAvx(SB), 0, $24-40
	MOVQ haystack+0(FP), DI
	MOVQ haystack_len+8(FP), SI
	MOVQ needle+16(FP), DX
	MOVQ needle_len+24(FP), CX
	NOP                         // (skipped)                            // push	rbp
	NOP                         // (skipped)                            // mov	rbp, rsp
	NOP                         // (skipped)                            // push	r15
	NOP                         // (skipped)                            // push	r14
	NOP                         // (skipped)                            // push	r13
	NOP                         // (skipped)                            // push	r12
	NOP                         // (skipped)                            // push	rbx
	NOP                         // (skipped)                            // and	rsp, -8
	NOP                         // (skipped)                            // sub	rsp, 24
	MOVQ $-0x1, AX              // <--                                  // mov	rax, -1
	CMPQ SI, CX                 // <--                                  // cmp	rsi, rcx
	JL   LBB3_92                // <--                                  // jl	.LBB3_92
	WORD $0x8548; BYTE $0xc9    // TESTQ CX, CX                         // test	rcx, rcx
	JLE  LBB3_9                 // <--                                  // jle	.LBB3_9
	CMPQ SI, CX                 // <--                                  // cmp	rsi, rcx
	JNE  LBB3_10                // <--                                  // jne	.LBB3_10
	CMPQ SI, $0x8               // <--                                  // cmp	rsi, 8
	JAE  LBB3_20                // <--                                  // jae	.LBB3_20
	XORL CX, CX                 // <--                                  // xor	ecx, ecx

LBB3_5:
	CMPQ CX, SI // <--                                  // cmp	rcx, rsi
	JAE  LBB3_9 // <--                                  // jae	.LBB3_9

LBB3_6:
	LONG $0x04b60f44; BYTE $0x0f // MOVZX 0(DI)(CX*1), R8                // movzx	r8d, byte ptr [rdi + rcx]
	LONG $0x9f488d45             // LEAL -0x61(R8), R9                   // lea	r9d, [r8 - 97]
	LONG $0xe0508d45             // LEAL -0x20(R8), R10                  // lea	r10d, [r8 - 32]
	CMPB R9, $0x1a               // <--                                  // cmp	r9b, 26
	LONG $0xcab60f45             // MOVZX R10, R9                        // movzx	r9d, r10b
	LONG $0xc8430f45             // CMOVAE R8, R9                        // cmovae	r9d, r8d
	LONG $0x04b60f44; BYTE $0x0a // MOVZX 0(DX)(CX*1), R8                // movzx	r8d, byte ptr [rdx + rcx]
	LONG $0x9f508d45             // LEAL -0x61(R8), R10                  // lea	r10d, [r8 - 97]
	LONG $0xe0588d45             // LEAL -0x20(R8), R11                  // lea	r11d, [r8 - 32]
	CMPB R10, $0x1a              // <--                                  // cmp	r10b, 26
	LONG $0xd3b60f45             // MOVZX R11, R10                       // movzx	r10d, r11b
	LONG $0xd0430f45             // CMOVAE R8, R10                       // cmovae	r10d, r8d
	CMPB R9, R10                 // <--                                  // cmp	r9b, r10b
	JNE  LBB3_92                 // <--                                  // jne	.LBB3_92
	INCQ CX                      // <--                                  // inc	rcx
	CMPQ SI, CX                  // <--                                  // cmp	rsi, rcx
	JNE  LBB3_6                  // <--                                  // jne	.LBB3_6

LBB3_9:
	XORL AX, AX // <--                                  // xor	eax, eax

LBB3_92:
	NOP                 // (skipped)                            // lea	rsp, [rbp - 40]
	NOP                 // (skipped)                            // pop	rbx
	NOP                 // (skipped)                            // pop	r12
	NOP                 // (skipped)                            // pop	r13
	NOP                 // (skipped)                            // pop	r14
	NOP                 // (skipped)                            // pop	r15
	NOP                 // (skipped)                            // pop	rbp
	VZEROUPPER          // <--                                  // vzeroupper
	MOVQ AX, ret+32(FP) // <--
	RET                 // <--                                  // ret

LBB3_10:
	CMPQ         CX, $0x2                // <--                                  // cmp	rcx, 2
	JE           LBB3_25                 // <--                                  // je	.LBB3_25
	CMPQ         CX, $0x1                // <--                                  // cmp	rcx, 1
	JNE          LBB3_47                 // <--                                  // jne	.LBB3_47
	WORD         $0xb60f; BYTE $0x12     // MOVZX 0(DX), DX                      // movzx	edx, byte ptr [rdx]
	WORD         $0x4a8d; BYTE $0x9f     // LEAL -0x61(DX), CX                   // lea	ecx, [rdx - 97]
	LONG         $0xe0428d44             // LEAL -0x20(DX), R8                   // lea	r8d, [rdx - 32]
	WORD         $0xf980; BYTE $0x1a     // CMPL CL, $0x1a                       // cmp	cl, 26
	LONG         $0xc8b60f41             // MOVZX R8, CX                         // movzx	ecx, r8b
	WORD         $0x430f; BYTE $0xca     // CMOVAE DX, CX                        // cmovae	ecx, edx
	LEAQ         0(DI)(SI*1), R8         // <--                                  // lea	r8, [rdi + rsi]
	LEAQ         0x1f(SI), DX            // <--                                  // lea	rdx, [rsi + 31]
	WORD         $0x8548; BYTE $0xf6     // TESTQ SI, SI                         // test	rsi, rsi
	LONG         $0xd6490f48             // CMOVNS SI, DX                        // cmovns	rdx, rsi
	ANDQ         $-0x20, DX              // <--                                  // and	rdx, -32
	SUBQ         DX, SI                  // <--                                  // sub	rsi, rdx
	SUBQ         SI, R8                  // <--                                  // sub	r8, rsi
	MOVQ         DI, DX                  // <--                                  // mov	rdx, rdi
	CMPQ         R8, DI                  // <--                                  // cmp	r8, rdi
	JBE          LBB3_17                 // <--                                  // jbe	.LBB3_17
	LONG         $0xc16ef9c5             // VMOVD CX, X0                         // vmovd	xmm0, ecx
	LONG         $0x787de2c4; BYTE $0xc0 // VPBROADCASTB X0, Y0                  // vpbroadcastb	ymm0, xmm0
	XORL         DX, DX                  // <--                                  // xor	edx, edx
	VPBROADCASTB LCPI3_9<>(SB), Y1       // <--                                  // vpbroadcastb	ymm1, byte ptr [rip + .LCPI3_9]
	VPBROADCASTB LCPI3_10<>(SB), Y2      // <--                                  // vpbroadcastb	ymm2, byte ptr [rip + .LCPI3_10]
	VPBROADCASTB LCPI3_11<>(SB), Y3      // <--                                  // vpbroadcastb	ymm3, byte ptr [rip + .LCPI3_11]

LBB3_14:
	LONG $0x246ffec5; BYTE $0x17 // VMOVDQU 0(DI)(DX*1), Y4              // vmovdqu	ymm4, ymmword ptr [rdi + rdx]
	LONG $0xe9fcddc5             // VPADDB Y1, Y4, Y5                    // vpaddb	ymm5, ymm4, ymm1
	LONG $0xea64d5c5             // VPCMPGTB Y2, Y5, Y5                  // vpcmpgtb	ymm5, ymm5, ymm2
	LONG $0xebdfd5c5             // VPANDN Y3, Y5, Y5                    // vpandn	ymm5, ymm5, ymm3
	LONG $0xe4fcd5c5             // VPADDB Y4, Y5, Y4                    // vpaddb	ymm4, ymm5, ymm4
	LONG $0xe074ddc5             // VPCMPEQB Y0, Y4, Y4                  // vpcmpeqb	ymm4, ymm4, ymm0
	LONG $0xccd77dc5             // VPMOVMSKB Y4, R9                     // vpmovmskb	r9d, ymm4
	WORD $0x8545; BYTE $0xc9     // TESTL R9, R9                         // test	r9d, r9d
	JNE  LBB3_80                 // <--                                  // jne	.LBB3_80
	LEAQ 0(DI)(DX*1), R9         // <--                                  // lea	r9, [rdi + rdx]
	ADDQ $0x20, R9               // <--                                  // add	r9, 32
	ADDQ $0x20, DX               // <--                                  // add	rdx, 32
	CMPQ R9, R8                  // <--                                  // cmp	r9, r8
	JB   LBB3_14                 // <--                                  // jb	.LBB3_14
	ADDQ DI, DX                  // <--                                  // add	rdx, rdi

LBB3_17:
	CMPQ     SI, $0x10               // <--                                  // cmp	rsi, 16
	JL       LBB3_82                 // <--                                  // jl	.LBB3_82
	LONG     $0x026ffac5             // VMOVDQU 0(DX), X0                    // vmovdqu	xmm0, xmmword ptr [rdx]
	VPADDB   LCPI3_3<>(SB), X0, X1   // <--                                  // vpaddb	xmm1, xmm0, xmmword ptr [rip + .LCPI3_3]
	VPCMPGTB LCPI3_4<>(SB), X1, X1   // <--                                  // vpcmpgtb	xmm1, xmm1, xmmword ptr [rip + .LCPI3_4]
	LONG     $0xd16ef9c5             // VMOVD CX, X2                         // vmovd	xmm2, ecx
	VPANDN   LCPI3_5<>(SB), X1, X1   // <--                                  // vpandn	xmm1, xmm1, xmmword ptr [rip + .LCPI3_5]
	LONG     $0xc0fcf1c5             // VPADDB X0, X1, X0                    // vpaddb	xmm0, xmm1, xmm0
	LONG     $0x7879e2c4; BYTE $0xca // VPBROADCASTB X2, X1                  // vpbroadcastb	xmm1, xmm2
	LONG     $0xc174f9c5             // VPCMPEQB X1, X0, X0                  // vpcmpeqb	xmm0, xmm0, xmm1
	LONG     $0xc0d779c5             // VPMOVMSKB X0, R8                     // vpmovmskb	r8d, xmm0
	WORD     $0x8545; BYTE $0xc0     // TESTL R8, R8                         // test	r8d, r8d
	JE       LBB3_81                 // <--                                  // je	.LBB3_81
	SUBQ     DI, DX                  // <--                                  // sub	rdx, rdi
	LONG     $0xbc0f41f3; BYTE $0xc0 // TZCNT R8, AX                         // rep		bsf	eax, r8d
	ADDQ     DX, AX                  // <--                                  // add	rax, rdx
	JMP      LBB3_92                 // <--                                  // jmp	.LBB3_92

LBB3_20:
	XORL         R8, R8             // <--                                  // xor	r8d, r8d
	VPBROADCASTB LCPI3_12<>(SB), X0 // <--                                  // vpbroadcastb	xmm0, byte ptr [rip + .LCPI3_12]
	VPBROADCASTB LCPI3_13<>(SB), X1 // <--                                  // vpbroadcastb	xmm1, byte ptr [rip + .LCPI3_13]
	VPBROADCASTB LCPI3_9<>(SB), X2  // <--                                  // vpbroadcastb	xmm2, byte ptr [rip + .LCPI3_9]
	VPBROADCASTB LCPI3_14<>(SB), X3 // <--                                  // vpbroadcastb	xmm3, byte ptr [rip + .LCPI3_14]
	JMP          LBB3_22            // <--                                  // jmp	.LBB3_22

LBB3_21:
	LEAQ 0x8(R8), CX // <--                                  // lea	rcx, [r8 + 8]
	ADDQ $0x10, R8   // <--                                  // add	r8, 16
	CMPQ R8, SI      // <--                                  // cmp	r8, rsi
	MOVQ CX, R8      // <--                                  // mov	r8, rcx
	JA   LBB3_5      // <--                                  // ja	.LBB3_5

LBB3_22:
	MOVQ 0(DI)(R8*1), CX         // <--                                  // mov	rcx, qword ptr [rdi + r8]
	MOVQ 0(DX)(R8*1), R9         // <--                                  // mov	r9, qword ptr [rdx + r8]
	CMPQ CX, R9                  // <--                                  // cmp	rcx, r9
	JE   LBB3_21                 // <--                                  // je	.LBB3_21
	LONG $0x6ef9c1c4; BYTE $0xe1 // VMOVQ R9, X4                         // vmovq	xmm4, r9
	LONG $0x6ef9e1c4; BYTE $0xe9 // VMOVQ CX, X5                         // vmovq	xmm5, rcx
	LONG $0xe46cd1c5             // VPUNPCKLQDQ X4, X5, X4               // vpunpcklqdq	xmm4, xmm5, xmm4
	LONG $0xe8dbd9c5             // VPAND X0, X4, X5                     // vpand	xmm5, xmm4, xmm0
	LONG $0xf5fbf1c5             // VPSUBQ X5, X1, X6                    // vpsubq	xmm6, xmm1, xmm5
	LONG $0xf6dfd9c5             // VPANDN X6, X4, X6                    // vpandn	xmm6, xmm4, xmm6
	LONG $0xead4d1c5             // VPADDQ X2, X5, X5                    // vpaddq	xmm5, xmm5, xmm2
	LONG $0xeddbc9c5             // VPAND X5, X6, X5                     // vpand	xmm5, xmm6, xmm5
	LONG $0xd573d1c5; BYTE $0x02 // VPSRLQ $0x2, X5, X5                  // vpsrlq	xmm5, xmm5, 2
	LONG $0xebdbd1c5             // VPAND X3, X5, X5                     // vpand	xmm5, xmm5, xmm3
	LONG $0xe5fbd9c5             // VPSUBQ X5, X4, X4                    // vpsubq	xmm4, xmm4, xmm5
	LONG $0xec70f9c5; BYTE $0xee // VPSHUFD $-0x12, X4, X5               // vpshufd	xmm5, xmm4, 238
	LONG $0x2959e2c4; BYTE $0xe5 // VPCMPEQQ X5, X4, X4                  // vpcmpeqq	xmm4, xmm4, xmm5
	LONG $0xe17ef9c5             // VMOVD X4, CX                         // vmovd	ecx, xmm4
	WORD $0xc1f6; BYTE $0x01     // TESTL $0x1, CL                       // test	cl, 1
	JNE  LBB3_21                 // <--                                  // jne	.LBB3_21
	JMP  LBB3_92                 // <--                                  // jmp	.LBB3_92

LBB3_25:
	CMPQ         SI, $0x2                // <--                                  // cmp	rsi, 2
	JL           LBB3_92                 // <--                                  // jl	.LBB3_92
	LEAQ         -0x2(SI), CX            // <--                                  // lea	rcx, [rsi - 2]
	WORD         $0xb60f; BYTE $0x02     // MOVZX 0(DX), AX                      // movzx	eax, byte ptr [rdx]
	LONG         $0x42b60f44; BYTE $0x01 // MOVZX 0x1(DX), R8                    // movzx	r8d, byte ptr [rdx + 1]
	LONG         $0x9f508d41             // LEAL -0x61(R8), DX                   // lea	edx, [r8 - 97]
	LONG         $0xe0488d45             // LEAL -0x20(R8), R9                   // lea	r9d, [r8 - 32]
	WORD         $0xfa80; BYTE $0x1a     // CMPL DL, $0x1a                       // cmp	dl, 26
	LONG         $0xd1b60f41             // MOVZX R9, DX                         // movzx	edx, r9b
	LONG         $0xd0430f41             // CMOVAE R8, DX                        // cmovae	edx, r8d
	LONG         $0x9f408d44             // LEAL -0x61(AX), R8                   // lea	r8d, [rax - 97]
	LONG         $0xe0488d44             // LEAL -0x20(AX), R9                   // lea	r9d, [rax - 32]
	CMPB         R8, $0x1a               // <--                                  // cmp	r8b, 26
	LONG         $0xc1b60f45             // MOVZX R9, R8                         // movzx	r8d, r9b
	LONG         $0xc0430f44             // CMOVAE AX, R8                        // cmovae	r8d, eax
	LONG         $0x6e79c1c4; BYTE $0xc0 // VMOVD R8, X0                         // vmovd	xmm0, r8d
	LONG         $0x787de2c4; BYTE $0xc0 // VPBROADCASTB X0, Y0                  // vpbroadcastb	ymm0, xmm0
	LEAQ         0(DI)(SI*1), R9         // <--                                  // lea	r9, [rdi + rsi]
	XORL         R10, R10                // <--                                  // xor	r10d, r10d
	VPBROADCASTB LCPI3_9<>(SB), Y1       // <--                                  // vpbroadcastb	ymm1, byte ptr [rip + .LCPI3_9]
	VPBROADCASTB LCPI3_10<>(SB), Y2      // <--                                  // vpbroadcastb	ymm2, byte ptr [rip + .LCPI3_10]
	VPBROADCASTB LCPI3_11<>(SB), Y3      // <--                                  // vpbroadcastb	ymm3, byte ptr [rip + .LCPI3_11]
	VPBROADCASTB LCPI3_9<>(SB), X4       // <--                                  // vpbroadcastb	xmm4, byte ptr [rip + .LCPI3_9]
	VPBROADCASTB LCPI3_10<>(SB), X5      // <--                                  // vpbroadcastb	xmm5, byte ptr [rip + .LCPI3_10]
	VPBROADCASTB LCPI3_11<>(SB), X6      // <--                                  // vpbroadcastb	xmm6, byte ptr [rip + .LCPI3_11]

LBB3_27:
	CMPQ R10, CX             // <--                                  // cmp	r10, rcx
	JG   LBB3_87             // <--                                  // jg	.LBB3_87
	LEAQ 0(DI)(R10*1), AX    // <--                                  // lea	rax, [rdi + r10]
	MOVQ SI, BX              // <--                                  // mov	rbx, rsi
	SUBQ R10, BX             // <--                                  // sub	rbx, r10
	LEAQ 0x1f(BX), R11       // <--                                  // lea	r11, [rbx + 31]
	WORD $0x8548; BYTE $0xdb // TESTQ BX, BX                         // test	rbx, rbx
	LONG $0xdb490f4c         // CMOVNS BX, R11                       // cmovns	r11, rbx
	ANDQ $-0x20, R11         // <--                                  // and	r11, -32
	SUBQ R11, BX             // <--                                  // sub	rbx, r11
	MOVQ R9, R14             // <--                                  // mov	r14, r9
	SUBQ BX, R14             // <--                                  // sub	r14, rbx
	MOVQ AX, R11             // <--                                  // mov	r11, rax
	CMPQ R14, AX             // <--                                  // cmp	r14, rax
	JBE  LBB3_33             // <--                                  // jbe	.LBB3_33
	XORL R11, R11            // <--                                  // xor	r11d, r11d

LBB3_30:
	LONG $0x6f7ea1c4; WORD $0x183c // VMOVDQU 0(AX)(R11*1), Y7             // vmovdqu	ymm7, ymmword ptr [rax + r11]
	LONG $0xc1fc45c5               // VPADDB Y1, Y7, Y8                    // vpaddb	ymm8, ymm7, ymm1
	LONG $0xc2643dc5               // VPCMPGTB Y2, Y8, Y8                  // vpcmpgtb	ymm8, ymm8, ymm2
	LONG $0xc3df3dc5               // VPANDN Y3, Y8, Y8                    // vpandn	ymm8, ymm8, ymm3
	LONG $0xfffcbdc5               // VPADDB Y7, Y8, Y7                    // vpaddb	ymm7, ymm8, ymm7
	LONG $0xf874c5c5               // VPCMPEQB Y0, Y7, Y7                  // vpcmpeqb	ymm7, ymm7, ymm0
	LONG $0xffd77dc5               // VPMOVMSKB Y7, R15                    // vpmovmskb	r15d, ymm7
	WORD $0x8545; BYTE $0xff       // TESTL R15, R15                       // test	r15d, r15d
	JNE  LBB3_36                   // <--                                  // jne	.LBB3_36
	LEAQ 0(AX)(R11*1), R15         // <--                                  // lea	r15, [rax + r11]
	ADDQ $0x20, R15                // <--                                  // add	r15, 32
	ADDQ $0x20, R11                // <--                                  // add	r11, 32
	CMPQ R15, R14                  // <--                                  // cmp	r15, r14
	JB   LBB3_30                   // <--                                  // jb	.LBB3_30
	ADDQ AX, R11                   // <--                                  // add	r11, rax

LBB3_33:
	CMPQ BX, $0x10               // <--                                  // cmp	rbx, 16
	JL   LBB3_39                 // <--                                  // jl	.LBB3_39
	LONG $0x6f7ac1c4; BYTE $0x3b // VMOVDQU 0(R11), X7                   // vmovdqu	xmm7, xmmword ptr [r11]
	LONG $0xc4fc41c5             // VPADDB X4, X7, X8                    // vpaddb	xmm8, xmm7, xmm4
	LONG $0xc56439c5             // VPCMPGTB X5, X8, X8                  // vpcmpgtb	xmm8, xmm8, xmm5
	LONG $0xc6df39c5             // VPANDN X6, X8, X8                    // vpandn	xmm8, xmm8, xmm6
	LONG $0xfffcb9c5             // VPADDB X7, X8, X7                    // vpaddb	xmm7, xmm8, xmm7
	LONG $0xf874c1c5             // VPCMPEQB X0, X7, X7                  // vpcmpeqb	xmm7, xmm7, xmm0
	LONG $0xf7d779c5             // VPMOVMSKB X7, R14                    // vpmovmskb	r14d, xmm7
	WORD $0x8545; BYTE $0xf6     // TESTL R14, R14                       // test	r14d, r14d
	JE   LBB3_38                 // <--                                  // je	.LBB3_38
	SUBQ AX, R11                 // <--                                  // sub	r11, rax
	LONG $0xbc0f41f3; BYTE $0xc6 // TZCNT R14, AX                        // rep		bsf	eax, r14d
	JMP  LBB3_37                 // <--                                  // jmp	.LBB3_37

LBB3_36:
	LONG $0xbc0f41f3; BYTE $0xc7 // TZCNT R15, AX                        // rep		bsf	eax, r15d

LBB3_37:
	ADDQ R11, AX // <--                                  // add	rax, r11
	JMP  LBB3_44 // <--                                  // jmp	.LBB3_44

LBB3_38:
	ADDQ $0x10, R11 // <--                                  // add	r11, 16
	ADDQ $-0x10, BX // <--                                  // add	rbx, -16

LBB3_39:
	WORD $0x8548; BYTE $0xdb // TESTQ BX, BX                         // test	rbx, rbx
	JLE  LBB3_87             // <--                                  // jle	.LBB3_87
	XORL R14, R14            // <--                                  // xor	r14d, r14d

LBB3_41:
	LONG $0x3cb60f47; BYTE $0x33 // MOVZX 0(R11)(R14*1), R15             // movzx	r15d, byte ptr [r11 + r14]
	LONG $0x9f678d45             // LEAL -0x61(R15), R12                 // lea	r12d, [r15 - 97]
	LONG $0xe06f8d45             // LEAL -0x20(R15), R13                 // lea	r13d, [r15 - 32]
	CMPB R12, $0x1a              // <--                                  // cmp	r12b, 26
	LONG $0xe5b60f45             // MOVZX R13, R12                       // movzx	r12d, r13b
	LONG $0xe7430f45             // CMOVAE R15, R12                      // cmovae	r12d, r15d
	CMPB R12, R8                 // <--                                  // cmp	r12b, r8b
	JE   LBB3_43                 // <--                                  // je	.LBB3_43
	INCQ R14                     // <--                                  // inc	r14
	CMPQ BX, R14                 // <--                                  // cmp	rbx, r14
	JNE  LBB3_41                 // <--                                  // jne	.LBB3_41
	JMP  LBB3_87                 // <--                                  // jmp	.LBB3_87

LBB3_43:
	SUBQ AX, R11  // <--                                  // sub	r11, rax
	ADDQ R14, R11 // <--                                  // add	r11, r14
	MOVQ R11, AX  // <--                                  // mov	rax, r11

LBB3_44:
	WORD $0x8548; BYTE $0xc0       // TESTQ AX, AX                         // test	rax, rax
	JS   LBB3_87                   // <--                                  // js	.LBB3_87
	ADDQ R10, AX                   // <--                                  // add	rax, r10
	CMPQ AX, CX                    // <--                                  // cmp	rax, rcx
	JG   LBB3_87                   // <--                                  // jg	.LBB3_87
	LEAQ 0x1(AX), R10              // <--                                  // lea	r10, [rax + 1]
	LONG $0x5cb60f44; WORD $0x0107 // MOVZX 0x1(DI)(AX*1), R11             // movzx	r11d, byte ptr [rdi + rax + 1]
	LONG $0x9f5b8d41               // LEAL -0x61(R11), BX                  // lea	ebx, [r11 - 97]
	LONG $0xe0738d45               // LEAL -0x20(R11), R14                 // lea	r14d, [r11 - 32]
	WORD $0xfb80; BYTE $0x1a       // CMPL BL, $0x1a                       // cmp	bl, 26
	LONG $0xdeb60f41               // MOVZX R14, BX                        // movzx	ebx, r14b
	LONG $0xdb430f41               // CMOVAE R11, BX                       // cmovae	ebx, r11d
	WORD $0xd338                   // CMPL BL, DL                          // cmp	bl, dl
	JNE  LBB3_27                   // <--                                  // jne	.LBB3_27
	JMP  LBB3_92                   // <--                                  // jmp	.LBB3_92

LBB3_47:
	MOVQ         SI, R13                 // <--                                  // mov	r13, rsi
	SUBQ         CX, R13                 // <--                                  // sub	r13, rcx
	JS           LBB3_92                 // <--                                  // js	.LBB3_92
	LONG         $0x12b60f44             // MOVZX 0(DX), R10                     // movzx	r10d, byte ptr [rdx]
	LONG         $0x9f4a8d45             // LEAL -0x61(R10), R9                  // lea	r9d, [r10 - 97]
	LONG         $0xe05a8d45             // LEAL -0x20(R10), R11                 // lea	r11d, [r10 - 32]
	CMPB         R9, $0x1a               // <--                                  // cmp	r9b, 26
	LONG         $0xcbb60f45             // MOVZX R11, R9                        // movzx	r9d, r11b
	LONG         $0xca430f45             // CMOVAE R10, R9                       // cmovae	r9d, r10d
	LONG         $0x6e79c1c4; BYTE $0xc1 // VMOVD R9, X0                         // vmovd	xmm0, r9d
	LONG         $0x787de2c4; BYTE $0xc0 // VPBROADCASTB X0, Y0                  // vpbroadcastb	ymm0, xmm0
	LEAQ         0(DI)(SI*1), R8         // <--                                  // lea	r8, [rdi + rsi]
	LEAQ         -0x1(CX), R10           // <--                                  // lea	r10, [rcx - 1]
	MOVQ         R10, 0(SP)              // <--                                  // mov	qword ptr [rsp], r10
	XORL         R11, R11                // <--                                  // xor	r11d, r11d
	VPBROADCASTB LCPI3_9<>(SB), Y1       // <--                                  // vpbroadcastb	ymm1, byte ptr [rip + .LCPI3_9]
	VPBROADCASTB LCPI3_10<>(SB), Y2      // <--                                  // vpbroadcastb	ymm2, byte ptr [rip + .LCPI3_10]
	VPBROADCASTB LCPI3_11<>(SB), Y3      // <--                                  // vpbroadcastb	ymm3, byte ptr [rip + .LCPI3_11]
	VPBROADCASTB LCPI3_9<>(SB), X4       // <--                                  // vpbroadcastb	xmm4, byte ptr [rip + .LCPI3_9]
	VPBROADCASTB LCPI3_10<>(SB), X5      // <--                                  // vpbroadcastb	xmm5, byte ptr [rip + .LCPI3_10]
	VPBROADCASTB LCPI3_11<>(SB), X6      // <--                                  // vpbroadcastb	xmm6, byte ptr [rip + .LCPI3_11]
	VPBROADCASTB LCPI3_12<>(SB), X7      // <--                                  // vpbroadcastb	xmm7, byte ptr [rip + .LCPI3_12]
	VPBROADCASTB LCPI3_13<>(SB), X8      // <--                                  // vpbroadcastb	xmm8, byte ptr [rip + .LCPI3_13]
	VPBROADCASTB LCPI3_14<>(SB), X9      // <--                                  // vpbroadcastb	xmm9, byte ptr [rip + .LCPI3_14]
	MOVQ         R13, 0x10(SP)           // <--                                  // mov	qword ptr [rsp + 16], r13
	MOVQ         R8, 0x8(SP)             // <--                                  // mov	qword ptr [rsp + 8], r8

LBB3_49:
	LEAQ 0(DI)(R11*1), R14   // <--                                  // lea	r14, [rdi + r11]
	MOVQ SI, R12             // <--                                  // mov	r12, rsi
	SUBQ R11, R12            // <--                                  // sub	r12, r11
	LEAQ 0x1f(R12), R10      // <--                                  // lea	r10, [r12 + 31]
	WORD $0x854d; BYTE $0xe4 // TESTQ R12, R12                       // test	r12, r12
	LONG $0xd4490f4d         // CMOVNS R12, R10                      // cmovns	r10, r12
	ANDQ $-0x20, R10         // <--                                  // and	r10, -32
	SUBQ R10, R12            // <--                                  // sub	r12, r10
	MOVQ R8, R13             // <--                                  // mov	r13, r8
	SUBQ R12, R13            // <--                                  // sub	r13, r12
	MOVQ R14, R15            // <--                                  // mov	r15, r14
	CMPQ R13, R14            // <--                                  // cmp	r13, r14
	JBE  LBB3_54             // <--                                  // jbe	.LBB3_54
	XORL R15, R15            // <--                                  // xor	r15d, r15d

LBB3_51:
	LONG $0x6f7e01c4; WORD $0x3e14 // VMOVDQU 0(R14)(R15*1), Y10           // vmovdqu	ymm10, ymmword ptr [r14 + r15]
	LONG $0xd9fc2dc5               // VPADDB Y1, Y10, Y11                  // vpaddb	ymm11, ymm10, ymm1
	LONG $0xda6425c5               // VPCMPGTB Y2, Y11, Y11                // vpcmpgtb	ymm11, ymm11, ymm2
	LONG $0xdbdf25c5               // VPANDN Y3, Y11, Y11                  // vpandn	ymm11, ymm11, ymm3
	LONG $0xfc2541c4; BYTE $0xd2   // VPADDB Y10, Y11, Y10                 // vpaddb	ymm10, ymm11, ymm10
	LONG $0xd0742dc5               // VPCMPEQB Y0, Y10, Y10                // vpcmpeqb	ymm10, ymm10, ymm0
	LONG $0xd77d41c4; BYTE $0xd2   // VPMOVMSKB Y10, R10                   // vpmovmskb	r10d, ymm10
	WORD $0x8545; BYTE $0xd2       // TESTL R10, R10                       // test	r10d, r10d
	JNE  LBB3_57                   // <--                                  // jne	.LBB3_57
	LEAQ 0(R14)(R15*1), R10        // <--                                  // lea	r10, [r14 + r15]
	ADDQ $0x20, R10                // <--                                  // add	r10, 32
	ADDQ $0x20, R15                // <--                                  // add	r15, 32
	CMPQ R10, R13                  // <--                                  // cmp	r10, r13
	JB   LBB3_51                   // <--                                  // jb	.LBB3_51
	ADDQ R14, R15                  // <--                                  // add	r15, r14

LBB3_54:
	CMPQ R12, $0x10              // <--                                  // cmp	r12, 16
	JL   LBB3_60                 // <--                                  // jl	.LBB3_60
	LONG $0x6f7a41c4; BYTE $0x17 // VMOVDQU 0(R15), X10                  // vmovdqu	xmm10, xmmword ptr [r15]
	LONG $0xdcfc29c5             // VPADDB X4, X10, X11                  // vpaddb	xmm11, xmm10, xmm4
	LONG $0xdd6421c5             // VPCMPGTB X5, X11, X11                // vpcmpgtb	xmm11, xmm11, xmm5
	LONG $0xdedf21c5             // VPANDN X6, X11, X11                  // vpandn	xmm11, xmm11, xmm6
	LONG $0xfc2141c4; BYTE $0xd2 // VPADDB X10, X11, X10                 // vpaddb	xmm10, xmm11, xmm10
	LONG $0xd07429c5             // VPCMPEQB X0, X10, X10                // vpcmpeqb	xmm10, xmm10, xmm0
	LONG $0xd77941c4; BYTE $0xea // VPMOVMSKB X10, R13                   // vpmovmskb	r13d, xmm10
	WORD $0x8545; BYTE $0xed     // TESTL R13, R13                       // test	r13d, r13d
	JE   LBB3_59                 // <--                                  // je	.LBB3_59
	SUBQ R14, R15                // <--                                  // sub	r15, r14
	LONG $0xbc0f45f3; BYTE $0xe5 // TZCNT R13, R12                       // rep		bsf	r12d, r13d
	JMP  LBB3_58                 // <--                                  // jmp	.LBB3_58

LBB3_57:
	LONG $0xbc0f45f3; BYTE $0xe2 // TZCNT R10, R12                       // rep		bsf	r12d, r10d

LBB3_58:
	ADDQ R15, R12 // <--                                  // add	r12, r15
	JMP  LBB3_65  // <--                                  // jmp	.LBB3_65

LBB3_59:
	ADDQ $0x10, R15  // <--                                  // add	r15, 16
	ADDQ $-0x10, R12 // <--                                  // add	r12, -16

LBB3_60:
	WORD $0x854d; BYTE $0xe4 // TESTQ R12, R12                       // test	r12, r12
	JLE  LBB3_92             // <--                                  // jle	.LBB3_92
	XORL R13, R13            // <--                                  // xor	r13d, r13d

LBB3_62:
	LONG $0x14b60f47; BYTE $0x2f // MOVZX 0(R15)(R13*1), R10             // movzx	r10d, byte ptr [r15 + r13]
	LONG $0x9f428d45             // LEAL -0x61(R10), R8                  // lea	r8d, [r10 - 97]
	LONG $0xe05a8d41             // LEAL -0x20(R10), BX                  // lea	ebx, [r10 - 32]
	CMPB R8, $0x1a               // <--                                  // cmp	r8b, 26
	LONG $0xc3b60f44             // MOVZX BL, R8                         // movzx	r8d, bl
	LONG $0xc2430f45             // CMOVAE R10, R8                       // cmovae	r8d, r10d
	CMPB R8, R9                  // <--                                  // cmp	r8b, r9b
	JE   LBB3_64                 // <--                                  // je	.LBB3_64
	INCQ R13                     // <--                                  // inc	r13
	CMPQ R12, R13                // <--                                  // cmp	r12, r13
	JNE  LBB3_62                 // <--                                  // jne	.LBB3_62
	JMP  LBB3_92                 // <--                                  // jmp	.LBB3_92

LBB3_64:
	SUBQ R14, R15 // <--                                  // sub	r15, r14
	ADDQ R13, R15 // <--                                  // add	r15, r13
	MOVQ R15, R12 // <--                                  // mov	r12, r15

LBB3_65:
	WORD $0x854d; BYTE $0xe4 // TESTQ R12, R12                       // test	r12, r12
	MOVQ 0x10(SP), R13       // <--                                  // mov	r13, qword ptr [rsp + 16]
	JS   LBB3_92             // <--                                  // js	.LBB3_92
	ADDQ R12, R11            // <--                                  // add	r11, r12
	CMPQ R11, R13            // <--                                  // cmp	r11, r13
	JG   LBB3_92             // <--                                  // jg	.LBB3_92
	ADDQ R12, R14            // <--                                  // add	r14, r12
	CMPQ CX, $0x9            // <--                                  // cmp	rcx, 9
	JAE  LBB3_73             // <--                                  // jae	.LBB3_73
	XORL R15, R15            // <--                                  // xor	r15d, r15d

LBB3_69:
	CMPQ R15, 0(SP) // <--                                  // cmp	r15, qword ptr [rsp]
	JAE  LBB3_91    // <--                                  // jae	.LBB3_91
	INCQ R15        // <--                                  // inc	r15

LBB3_71:
	LONG $0x04b60f47; BYTE $0x3e // MOVZX 0(R14)(R15*1), R8              // movzx	r8d, byte ptr [r14 + r15]
	LONG $0x9f508d45             // LEAL -0x61(R8), R10                  // lea	r10d, [r8 - 97]
	LONG $0xe0588d41             // LEAL -0x20(R8), BX                   // lea	ebx, [r8 - 32]
	CMPB R10, $0x1a              // <--                                  // cmp	r10b, 26
	LONG $0xd3b60f44             // MOVZX BL, R10                        // movzx	r10d, bl
	LONG $0xd0430f45             // CMOVAE R8, R10                       // cmovae	r10d, r8d
	LONG $0x04b60f46; BYTE $0x3a // MOVZX 0(DX)(R15*1), R8               // movzx	r8d, byte ptr [rdx + r15]
	LONG $0x9f588d41             // LEAL -0x61(R8), BX                   // lea	ebx, [r8 - 97]
	LONG $0xe0608d45             // LEAL -0x20(R8), R12                  // lea	r12d, [r8 - 32]
	WORD $0xfb80; BYTE $0x1a     // CMPL BL, $0x1a                       // cmp	bl, 26
	LONG $0xdcb60f41             // MOVZX R12, BX                        // movzx	ebx, r12b
	LONG $0xd8430f41             // CMOVAE R8, BX                        // cmovae	ebx, r8d
	CMPB R10, BL                 // <--                                  // cmp	r10b, bl
	JNE  LBB3_77                 // <--                                  // jne	.LBB3_77
	INCQ R15                     // <--                                  // inc	r15
	CMPQ CX, R15                 // <--                                  // cmp	rcx, r15
	JNE  LBB3_71                 // <--                                  // jne	.LBB3_71
	JMP  LBB3_91                 // <--                                  // jmp	.LBB3_91

LBB3_73:
	XORL R12, R12 // <--                                  // xor	r12d, r12d
	JMP  LBB3_75  // <--                                  // jmp	.LBB3_75

LBB3_74:
	LEAQ 0x8(R12), R15 // <--                                  // lea	r15, [r12 + 8]
	ADDQ $0x10, R12    // <--                                  // add	r12, 16
	CMPQ R12, 0(SP)    // <--                                  // cmp	r12, qword ptr [rsp]
	MOVQ R15, R12      // <--                                  // mov	r12, r15
	JA   LBB3_69       // <--                                  // ja	.LBB3_69

LBB3_75:
	MOVQ 0x1(R14)(R12*1), R15      // <--                                  // mov	r15, qword ptr [r14 + r12 + 1]
	MOVQ 0x1(DX)(R12*1), R10       // <--                                  // mov	r10, qword ptr [rdx + r12 + 1]
	CMPQ R15, R10                  // <--                                  // cmp	r15, r10
	JE   LBB3_74                   // <--                                  // je	.LBB3_74
	LONG $0x6ef941c4; BYTE $0xd2   // VMOVQ R10, X10                       // vmovq	xmm10, r10
	LONG $0x6ef941c4; BYTE $0xdf   // VMOVQ R15, X11                       // vmovq	xmm11, r15
	LONG $0x6c2141c4; BYTE $0xd2   // VPUNPCKLQDQ X10, X11, X10            // vpunpcklqdq	xmm10, xmm11, xmm10
	LONG $0xdfdb29c5               // VPAND X7, X10, X11                   // vpand	xmm11, xmm10, xmm7
	LONG $0xfb3941c4; BYTE $0xe3   // VPSUBQ X11, X8, X12                  // vpsubq	xmm12, xmm8, xmm11
	LONG $0xdf2941c4; BYTE $0xe4   // VPANDN X12, X10, X12                 // vpandn	xmm12, xmm10, xmm12
	LONG $0xdcd421c5               // VPADDQ X4, X11, X11                  // vpaddq	xmm11, xmm11, xmm4
	LONG $0xdb1941c4; BYTE $0xdb   // VPAND X11, X12, X11                  // vpand	xmm11, xmm12, xmm11
	LONG $0x7321c1c4; WORD $0x02d3 // VPSRLQ $0x2, X11, X11                // vpsrlq	xmm11, xmm11, 2
	LONG $0xdb2141c4; BYTE $0xd9   // VPAND X9, X11, X11                   // vpand	xmm11, xmm11, xmm9
	LONG $0xfb2941c4; BYTE $0xd3   // VPSUBQ X11, X10, X10                 // vpsubq	xmm10, xmm10, xmm11
	LONG $0x707941c4; WORD $0xeeda // VPSHUFD $-0x12, X10, X11             // vpshufd	xmm11, xmm10, 238
	LONG $0x292942c4; BYTE $0xd3   // VPCMPEQQ X11, X10, X10               // vpcmpeqq	xmm10, xmm10, xmm11
	LONG $0x7e7941c4; BYTE $0xd0   // VMOVD X10, R8                        // vmovd	r8d, xmm10
	LONG $0x01c0f641               // TESTB $0x1, R8                       // test	r8b, 1
	JNE  LBB3_74                   // <--                                  // jne	.LBB3_74

LBB3_77:
	LEAQ 0x1(R11), R8 // <--                                  // lea	r8, [r11 + 1]
	CMPQ R11, R13     // <--                                  // cmp	r11, r13
	MOVQ R8, R11      // <--                                  // mov	r11, r8
	MOVQ 0x8(SP), R8  // <--                                  // mov	r8, qword ptr [rsp + 8]
	JL   LBB3_49      // <--                                  // jl	.LBB3_49
	JMP  LBB3_92      // <--                                  // jmp	.LBB3_92

LBB3_87:
	MOVQ $-0x1, AX // <--                                  // mov	rax, -1
	JMP  LBB3_92   // <--                                  // jmp	.LBB3_92

LBB3_91:
	MOVQ R11, AX // <--                                  // mov	rax, r11
	JMP  LBB3_92 // <--                                  // jmp	.LBB3_92

LBB3_80:
	LONG $0xbc0f41f3; BYTE $0xc1 // TZCNT R9, AX                         // rep		bsf	eax, r9d
	ADDQ DX, AX                  // <--                                  // add	rax, rdx
	JMP  LBB3_92                 // <--                                  // jmp	.LBB3_92

LBB3_81:
	ADDQ $0x10, DX  // <--                                  // add	rdx, 16
	ADDQ $-0x10, SI // <--                                  // add	rsi, -16

LBB3_82:
	WORD $0x8548; BYTE $0xf6 // TESTQ SI, SI                         // test	rsi, rsi
	JLE  LBB3_92             // <--                                  // jle	.LBB3_92
	XORL R8, R8              // <--                                  // xor	r8d, r8d

LBB3_84:
	LONG $0x0cb60f46; BYTE $0x02 // MOVZX 0(DX)(R8*1), R9                // movzx	r9d, byte ptr [rdx + r8]
	LONG $0x9f518d45             // LEAL -0x61(R9), R10                  // lea	r10d, [r9 - 97]
	LONG $0xe0598d45             // LEAL -0x20(R9), R11                  // lea	r11d, [r9 - 32]
	CMPB R10, $0x1a              // <--                                  // cmp	r10b, 26
	LONG $0xd3b60f45             // MOVZX R11, R10                       // movzx	r10d, r11b
	LONG $0xd1430f45             // CMOVAE R9, R10                       // cmovae	r10d, r9d
	CMPB R10, CL                 // <--                                  // cmp	r10b, cl
	JE   LBB3_86                 // <--                                  // je	.LBB3_86
	INCQ R8                      // <--                                  // inc	r8
	CMPQ SI, R8                  // <--                                  // cmp	rsi, r8
	JNE  LBB3_84                 // <--                                  // jne	.LBB3_84
	JMP  LBB3_92                 // <--                                  // jmp	.LBB3_92

LBB3_86:
	SUBQ DI, DX  // <--                                  // sub	rdx, rdi
	ADDQ R8, DX  // <--                                  // add	rdx, r8
	MOVQ DX, AX  // <--                                  // mov	rax, rdx
	JMP  LBB3_92 // <--                                  // jmp	.LBB3_92
