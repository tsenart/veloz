//go:build !noasm && amd64
// Code generated by gocc v0.16.3-rev-6adf1e2 -- DO NOT EDIT.
//
// Source file         : ascii_avx2.c
// Clang version       : Apple clang version 17.0.0 (clang-1700.6.3.2)
// Target architecture : amd64
// Compiler options    : -mavx2 -mfma

#include "textflag.h"

TEXT Â·isAsciiAvx(SB), NOSPLIT, $0-17
	MOVQ src+0(FP), DI
	MOVQ src_len+8(FP), SI
	XORL DX, DX            // <--                                  // xor	edx, edx
	CMPQ SI, $0x20         // <--                                  // cmp	rsi, 32
	JB   LBB0_1            // <--                                  // jb	.LBB0_1

LBB0_6:
	LEAQ 0x80(DX), AX              // <--                                  // lea	rax, [rdx + 128]
	CMPQ AX, SI                    // <--                                  // cmp	rax, rsi
	JA   LBB0_8                    // <--                                  // ja	.LBB0_8
	LONG $0x446ffec5; WORD $0x2017 // VMOVDQU 0x20(DI)(DX*1), Y0           // vmovdqu	ymm0, ymmword ptr [rdi + rdx + 32]
	LONG $0x04ebfdc5; BYTE $0x17   // VPOR 0(DI)(DX*1), Y0, Y0             // vpor	ymm0, ymm0, ymmword ptr [rdi + rdx]
	LONG $0x44ebfdc5; WORD $0x4017 // VPOR 0x40(DI)(DX*1), Y0, Y0          // vpor	ymm0, ymm0, ymmword ptr [rdi + rdx + 64]
	LONG $0x44ebfdc5; WORD $0x6017 // VPOR 0x60(DI)(DX*1), Y0, Y0          // vpor	ymm0, ymm0, ymmword ptr [rdi + rdx + 96]
	LONG $0xc8d7fdc5               // VPMOVMSKB Y0, CX                     // vpmovmskb	ecx, ymm0
	MOVQ AX, DX                    // <--                                  // mov	rdx, rax
	WORD $0xc985                   // TESTL CX, CX                         // test	ecx, ecx
	JE   LBB0_6                    // <--                                  // je	.LBB0_6
	JMP  LBB0_23                   // <--                                  // jmp	.LBB0_23

LBB0_9:
	LONG $0x046ffec5; BYTE $0x17 // VMOVDQU 0(DI)(DX*1), Y0              // vmovdqu	ymm0, ymmword ptr [rdi + rdx]
	LONG $0xc8d7fdc5             // VPMOVMSKB Y0, CX                     // vpmovmskb	ecx, ymm0
	MOVQ AX, DX                  // <--                                  // mov	rdx, rax
	WORD $0xc985                 // TESTL CX, CX                         // test	ecx, ecx
	JNE  LBB0_23                 // <--                                  // jne	.LBB0_23

LBB0_8:
	LEAQ 0x20(DX), AX // <--                                  // lea	rax, [rdx + 32]
	CMPQ AX, SI       // <--                                  // cmp	rax, rsi
	JBE  LBB0_9       // <--                                  // jbe	.LBB0_9

LBB0_1:
	MOVQ SI, CX                            // <--                                  // mov	rcx, rsi
	SUBQ DX, CX                            // <--                                  // sub	rcx, rdx
	QUAD $0x808080808080b848; WORD $0x8080 // MOVQ $0x8080808080808080, AX         // movabs	rax, -9187201950435737472

LBB0_2:
	LEAQ 0x8(DX), R8 // <--                                  // lea	r8, [rdx + 8]
	CMPQ R8, SI      // <--                                  // cmp	r8, rsi
	JA   LBB0_3      // <--                                  // ja	.LBB0_3
	ADDQ $-0x8, CX   // <--                                  // add	rcx, -8
	LONG $0x17048548 // TESTQ AX, 0(DI)(DX*1)                // test	qword ptr [rdi + rdx], rax
	MOVQ R8, DX      // <--                                  // mov	rdx, r8
	JE   LBB0_2      // <--                                  // je	.LBB0_2

LBB0_23:
	XORL AX, AX // <--                                  // xor	eax, eax

LBB0_24:
	VZEROUPPER          // <--                                  // vzeroupper
	MOVB AX, ret+16(FP) // <--
	RET                 // <--                                  // ret

LBB0_3:
	MOVQ SI, R8   // <--                                  // mov	r8, rsi
	WORD $0x01b0  // MOVL $0x1, AL                        // mov	al, 1
	SUBQ DX, R8   // <--                                  // sub	r8, rdx
	JBE  LBB0_24  // <--                                  // jbe	.LBB0_24
	CMPQ R8, $0x8 // <--                                  // cmp	r8, 8
	JAE  LBB0_10  // <--                                  // jae	.LBB0_10
	XORL R9, R9   // <--                                  // xor	r9d, r9d
	MOVQ DX, CX   // <--                                  // mov	rcx, rdx
	JMP  LBB0_15  // <--                                  // jmp	.LBB0_15

LBB0_10:
	CMPQ R8, $0x80 // <--                                  // cmp	r8, 128
	JAE  LBB0_17   // <--                                  // jae	.LBB0_17
	XORL R9, R9    // <--                                  // xor	r9d, r9d
	XORL AX, AX    // <--                                  // xor	eax, eax
	JMP  LBB0_12   // <--                                  // jmp	.LBB0_12

LBB0_17:
	MOVQ R8, AX      // <--                                  // mov	rax, r8
	ANDQ $-0x80, AX  // <--                                  // and	rax, -128
	MOVQ R8, R9      // <--                                  // mov	r9, r8
	ANDQ $-0x80, R9  // <--                                  // and	r9, -128
	LONG $0xc0eff9c5 // VPXOR X0, X0, X0                     // vpxor	xmm0, xmm0, xmm0
	XORL R10, R10    // <--                                  // xor	r10d, r10d
	LONG $0xc9eff1c5 // VPXOR X1, X1, X1                     // vpxor	xmm1, xmm1, xmm1
	LONG $0xd2efe9c5 // VPXOR X2, X2, X2                     // vpxor	xmm2, xmm2, xmm2
	LONG $0xdbefe1c5 // VPXOR X3, X3, X3                     // vpxor	xmm3, xmm3, xmm3

LBB0_18:
	LEAQ 0(DI)(R10*1), R11                     // <--                                  // lea	r11, [rdi + r10]
	LONG $0xeb7da1c4; WORD $0x1a04             // VPOR 0(DX)(R11*1), Y0, Y0            // vpor	ymm0, ymm0, ymmword ptr [rdx + r11]
	LONG $0xeb75a1c4; WORD $0x1a4c; BYTE $0x20 // VPOR 0x20(DX)(R11*1), Y1, Y1         // vpor	ymm1, ymm1, ymmword ptr [rdx + r11 + 32]
	LONG $0xeb6da1c4; WORD $0x1a54; BYTE $0x40 // VPOR 0x40(DX)(R11*1), Y2, Y2         // vpor	ymm2, ymm2, ymmword ptr [rdx + r11 + 64]
	LONG $0xeb65a1c4; WORD $0x1a5c; BYTE $0x60 // VPOR 0x60(DX)(R11*1), Y3, Y3         // vpor	ymm3, ymm3, ymmword ptr [rdx + r11 + 96]
	SUBQ $-0x80, R10                           // <--                                  // sub	r10, -128
	CMPQ R9, R10                               // <--                                  // cmp	r9, r10
	JNE  LBB0_18                               // <--                                  // jne	.LBB0_18
	LONG $0xc0ebf5c5                           // VPOR Y0, Y1, Y0                      // vpor	ymm0, ymm1, ymm0
	LONG $0xcaebe5c5                           // VPOR Y2, Y3, Y1                      // vpor	ymm1, ymm3, ymm2
	LONG $0xc0ebf5c5                           // VPOR Y0, Y1, Y0                      // vpor	ymm0, ymm1, ymm0
	LONG $0x397de3c4; WORD $0x01c1             // VEXTRACTI128 $0x1, Y0, X1            // vextracti128	xmm1, ymm0, 1
	LONG $0xc1ebf9c5                           // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0xc870f9c5; BYTE $0xee               // VPSHUFD $-0x12, X0, X1               // vpshufd	xmm1, xmm0, 238
	LONG $0xc1ebf9c5                           // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0xc870f9c5; BYTE $0x55               // VPSHUFD $0x55, X0, X1                // vpshufd	xmm1, xmm0, 85
	LONG $0xc1ebf9c5                           // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0xd072f1c5; BYTE $0x10               // VPSRLD $0x10, X0, X1                 // vpsrld	xmm1, xmm0, 16
	LONG $0xc1ebf9c5                           // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0xd071f1c5; BYTE $0x08               // VPSRLW $0x8, X0, X1                  // vpsrlw	xmm1, xmm0, 8
	LONG $0xc1ebf9c5                           // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0x7e79c1c4; BYTE $0xc1               // VMOVD X0, R9                         // vmovd	r9d, xmm0
	CMPQ R8, AX                                // <--                                  // cmp	r8, rax
	JE   LBB0_16                               // <--                                  // je	.LBB0_16
	LONG $0x78c0f641                           // TESTL $0x78, R8                      // test	r8b, 120
	JE   LBB0_21                               // <--                                  // je	.LBB0_21

LBB0_12:
	NOP                          // (skipped)                            // push	rbp
	NOP                          // (skipped)                            // mov	rbp, rsp
	NOP                          // (skipped)                            // push	rbx
	NOP                          // (skipped)                            // and	rsp, -8
	MOVQ R8, R10                 // <--                                  // mov	r10, r8
	ANDQ $-0x8, R10              // <--                                  // and	r10, -8
	ANDQ $-0x8, CX               // <--                                  // and	rcx, -8
	ADDQ DX, CX                  // <--                                  // add	rcx, rdx
	LONG $0xc9b60f45             // MOVZX R9, R9                         // movzx	r9d, r9b
	LONG $0x6e79c1c4; BYTE $0xc1 // VMOVD R9, X0                         // vmovd	xmm0, r9d
	MOVQ R10, R9                 // <--                                  // mov	r9, r10
	SUBQ AX, R9                  // <--                                  // sub	r9, rax
	ADDQ DI, AX                  // <--                                  // add	rax, rdi
	XORL R11, R11                // <--                                  // xor	r11d, r11d

LBB0_13:
	LEAQ 0(AX)(R11*1), BX        // <--                                  // lea	rbx, [rax + r11]
	LONG $0x0c7efac5; BYTE $0x1a // VMOVQ 0(DX)(BX*1), X1                // vmovq	xmm1, qword ptr [rdx + rbx]
	LONG $0xc0ebf1c5             // VPOR X0, X1, X0                      // vpor	xmm0, xmm1, xmm0
	ADDQ $0x8, R11               // <--                                  // add	r11, 8
	CMPQ R9, R11                 // <--                                  // cmp	r9, r11
	JNE  LBB0_13                 // <--                                  // jne	.LBB0_13
	LONG $0xc870f9c5; BYTE $0x55 // VPSHUFD $0x55, X0, X1                // vpshufd	xmm1, xmm0, 85
	LONG $0xc1ebf9c5             // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0xd072f1c5; BYTE $0x10 // VPSRLD $0x10, X0, X1                 // vpsrld	xmm1, xmm0, 16
	LONG $0xc1ebf9c5             // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0xd071f1c5; BYTE $0x08 // VPSRLW $0x8, X0, X1                  // vpsrlw	xmm1, xmm0, 8
	LONG $0xc1ebf9c5             // VPOR X1, X0, X0                      // vpor	xmm0, xmm0, xmm1
	LONG $0x7e79c1c4; BYTE $0xc1 // VMOVD X0, R9                         // vmovd	r9d, xmm0
	CMPQ R8, R10                 // <--                                  // cmp	r8, r10
	NOP                          // (skipped)                            // lea	rsp, [rbp - 8]
	NOP                          // (skipped)                            // pop	rbx
	NOP                          // (skipped)                            // pop	rbp
	JNE  LBB0_15                 // <--                                  // jne	.LBB0_15
	JMP  LBB0_16                 // <--                                  // jmp	.LBB0_16

LBB0_21:
	ANDQ $-0x80, CX // <--                                  // and	rcx, -128
	ADDQ DX, CX     // <--                                  // add	rcx, rdx

LBB0_15:
	ORB  0(DI)(CX*1), R9 // <--                                  // or	r9b, byte ptr [rdi + rcx]
	INCQ CX              // <--                                  // inc	rcx
	CMPQ CX, SI          // <--                                  // cmp	rcx, rsi
	JB   LBB0_15         // <--                                  // jb	.LBB0_15

LBB0_16:
	WORD $0x8445; BYTE $0xc9 // TESTL R9, R9                         // test	r9b, r9b
	WORD $0x990f; BYTE $0xc0 // SETNS AL                             // setns	al
	VZEROUPPER               // <--                                  // vzeroupper
	MOVB AX, ret+16(FP)      // <--
	RET                      // <--                                  // ret
