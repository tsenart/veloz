//go:build !noasm && arm64
// Code generated by gocc devel -- DO NOT EDIT.
//
// Source file         : ascii_neon.c
// Clang version       : Homebrew clang version 21.1.8
// Target architecture : arm64
// Compiler options    : [none]

#include "textflag.h"

DATA LCPI0_0<>+0x00(SB)/8, $0x8040201008040201
DATA LCPI0_0<>+0x08(SB)/8, $0x8040201008040201
GLOBL LCPI0_0<>(SB), (RODATA|NOPTR), $16

TEXT ·indexAnyNeonBitset(SB), NOSPLIT, $0-56
	MOVD  data+0(FP), R0
	MOVD  data_len+8(FP), R1
	MOVD  bitset0+16(FP), R2
	MOVD  bitset1+24(FP), R3
	MOVD  bitset2+32(FP), R4
	MOVD  bitset3+40(FP), R5
	CBZ   R1, LBB0_14        // <--                                  // cbz	x1, .LBB0_14
	CMP   $16, R1            // <--                                  // cmp	x1, #16
	AND   $15, R1, R8        // <--                                  // and	x8, x1, #0xf
	MOVD  R0, R9             // <--                                  // mov	x9, x0
	BLT   LBB0_5             // <--                                  // b.lt	.LBB0_5
	FMOVD R2, F0             // <--                                  // fmov	d0, x2
	FMOVD R3, F2             // <--                                  // fmov	d2, x3
	MOVD  $LCPI0_0<>(SB), R9 // <--                                  // adrp	x9, .LCPI0_0
	ADD   R1, R0, R11        // <--                                  // add	x11, x0, x1
	WORD  $0x3dc00123        // FMOVQ (R9), F3                       // ldr	q3, [x9, :lo12:.LCPI0_0]
	MOVD  ZR, R10            // <--                                  // mov	x10, xzr
	SUB   R8, R11, R11       // <--                                  // sub	x11, x11, x8
	VMOV  V2.D[0], V0.D[1]   // <--                                  // mov	v0.d[1], v2.d[0]
	FMOVD R5, F2             // <--                                  // fmov	d2, x5
	FMOVD R4, F1             // <--                                  // fmov	d1, x4
	VMOV  V2.D[0], V1.D[1]   // <--                                  // mov	v1.d[1], v2.d[0]
	WORD  $0x4f00e4e2        // VMOVI $7, V2.B16                     // movi	v2.16b, #7

LBB0_3:
	WORD   $0x3cea6804                      // FMOVQ (R0)(R10), F4                  // ldr	q4, [x0, x10]
	WORD   $0x6f0d0485                      // VUSHR $3, V4.B16, V5.B16             // ushr	v5.16b, v4.16b, #3
	VAND   V2.B16, V4.B16, V4.B16           // <--                                  // and	v4.16b, v4.16b, v2.16b
	VTBL   V5.B16, [V0.B16, V1.B16], V5.B16 // <--                                  // tbl	v5.16b, { v0.16b, v1.16b }, v5.16b
	VTBL   V4.B16, [V3.B16], V4.B16         // <--                                  // tbl	v4.16b, { v3.16b }, v4.16b
	VCMTST V5.B16, V4.B16, V4.B16           // <--                                  // cmtst	v4.16b, v4.16b, v5.16b
	WORD   $0x0f0c8484                      // VSHRN $4, V4.H8, V4.B8               // shrn	v4.8b, v4.8h, #4
	FMOVD  F4, R9                           // <--                                  // fmov	x9, d4
	CBNZ   R9, LBB0_16                      // <--                                  // cbnz	x9, .LBB0_16
	ADD    $16, R10, R10                    // <--                                  // add	x10, x10, #16
	ADD    R10, R0, R9                      // <--                                  // add	x9, x0, x10
	CMP    R11, R9                          // <--                                  // cmp	x9, x11
	BCC    LBB0_3                           // <--                                  // b.lo	.LBB0_3

LBB0_5:
	CBZ R8, LBB0_14 // <--                                  // cbz	x8, .LBB0_14
	SUB R0, R9, R0  // <--                                  // sub	x0, x9, x0

LBB0_7:
	WORD $0x3840152a  // MOVBU.P 1(R9), R10                   // ldrb	w10, [x9], #1
	LSRW $6, R10, R12 // <--                                  // lsr	w12, w10, #6
	CMPW $1, R12      // <--                                  // cmp	w12, #1
	BGT  LBB0_10      // <--                                  // b.gt	.LBB0_10
	MOVD R2, R11      // <--                                  // mov	x11, x2
	CBZW R12, LBB0_12 // <--                                  // cbz	w12, .LBB0_12
	MOVD R3, R11      // <--                                  // mov	x11, x3
	JMP  LBB0_12      // <--                                  // b	.LBB0_12

LBB0_10:
	CMPW $2, R12 // <--                                  // cmp	w12, #2
	MOVD R4, R11 // <--                                  // mov	x11, x4
	BEQ  LBB0_12 // <--                                  // b.eq	.LBB0_12
	MOVD R5, R11 // <--                                  // mov	x11, x5

LBB0_12:
	LSR  R10, R11, R10    // <--                                  // lsr	x10, x11, x10
	TBNZ $0, R10, LBB0_15 // <--                                  // tbnz	w10, #0, .LBB0_15
	SUBS $1, R8, R8       // <--                                  // subs	x8, x8, #1
	ADD  $1, R0, R0       // <--                                  // add	x0, x0, #1
	BNE  LBB0_7           // <--                                  // b.ne	.LBB0_7

LBB0_14:
	MOVD $-1, R0 // <--                                  // mov	x0, #-1

LBB0_15:
	MOVD R0, ret+48(FP) // <--
	RET                 // <--                                  // ret

LBB0_16:
	RBIT R9, R8         // <--                                  // rbit	x8, x9
	CLZ  R8, R8         // <--                                  // clz	x8, x8
	ADD  R8>>2, R10, R0 // <--                                  // add	x0, x10, x8, lsr #2
	MOVD R0, ret+48(FP) // <--
	RET                 // <--                                  // ret

TEXT ·ValidString(SB), NOSPLIT, $0-17
	MOVD data+0(FP), R0
	MOVD length+8(FP), R1
	CMP  $16, R1          // <--                                  // cmp	x1, #16
	BCC  LBB1_9           // <--                                  // b.lo	.LBB1_9
	CMP  $64, R1          // <--                                  // cmp	x1, #64
	AND  $63, R1, R8      // <--                                  // and	x8, x1, #0x3f
	BLT  LBB1_5           // <--                                  // b.lt	.LBB1_5
	ADD  R1, R0, R9       // <--                                  // add	x9, x0, x1
	SUB  R8, R9, R9       // <--                                  // sub	x9, x9, x8

LBB1_3:
	VLD1  (R0), [V0.B16, V1.B16, V2.B16, V3.B16] // <--                                  // ld1	{ v0.16b, v1.16b, v2.16b, v3.16b }, [x0]
	VORR  V1.B16, V0.B16, V4.B16                 // <--                                  // orr	v4.16b, v0.16b, v1.16b
	VORR  V2.B16, V3.B16, V0.B16                 // <--                                  // orr	v0.16b, v3.16b, v2.16b
	VORR  V0.B16, V4.B16, V0.B16                 // <--                                  // orr	v0.16b, v4.16b, v0.16b
	WORD  $0x4e20a800                            // VCMLT $0, V0.B16, V0.B16             // cmlt	v0.16b, v0.16b, #0
	WORD  $0x0f0c8400                            // VSHRN $4, V0.H8, V0.B8               // shrn	v0.8b, v0.8h, #4
	FMOVD F0, R10                                // <--                                  // fmov	x10, d0
	CBNZ  R10, LBB1_14                           // <--                                  // cbnz	x10, .LBB1_14
	ADD   $64, R0, R0                            // <--                                  // add	x0, x0, #64
	CMP   R9, R0                                 // <--                                  // cmp	x0, x9
	BCC   LBB1_3                                 // <--                                  // b.lo	.LBB1_3

LBB1_5:
	TST $48, R1     // <--                                  // tst	x1, #0x30
	AND $15, R1, R1 // <--                                  // and	x1, x1, #0xf
	BEQ LBB1_9      // <--                                  // b.eq	.LBB1_9
	ADD R8, R0, R8  // <--                                  // add	x8, x0, x8
	SUB R1, R8, R8  // <--                                  // sub	x8, x8, x1

LBB1_7:
	WORD  $0x3cc10400 // FMOVQ.P 16(R0), F0                   // ldr	q0, [x0], #16
	WORD  $0x4e20a800 // VCMLT $0, V0.B16, V0.B16             // cmlt	v0.16b, v0.16b, #0
	WORD  $0x0f0c8400 // VSHRN $4, V0.H8, V0.B8               // shrn	v0.8b, v0.8h, #4
	FMOVD F0, R9      // <--                                  // fmov	x9, d0
	CBNZ  R9, LBB1_14 // <--                                  // cbnz	x9, .LBB1_14
	CMP   R8, R0      // <--                                  // cmp	x0, x8
	BCC   LBB1_7      // <--                                  // b.lo	.LBB1_7

LBB1_9:
	CMP   $8, R1         // <--                                  // cmp	x1, #8
	BCS   LBB1_13        // <--                                  // b.hs	.LBB1_13
	CMP   $4, R1         // <--                                  // cmp	x1, #4
	BCS   LBB1_15        // <--                                  // b.hs	.LBB1_15
	CBZ   R1, LBB1_16    // <--                                  // cbz	x1, .LBB1_16
	ADD   R1, R0, R8     // <--                                  // add	x8, x0, x1
	LSR   $1, R1, R9     // <--                                  // lsr	x9, x1, #1
	WORD  $0x3940000a    // MOVBU (R0), R10                      // ldrb	w10, [x0]
	WORD  $0x385ff108    // LDURBW -1(R8), R8                    // ldurb	w8, [x8, #-1]
	WORD  $0x38696809    // MOVBU (R0)(R9), R9                   // ldrb	w9, [x0, x9]
	ORRW  R8, R10, R8    // <--                                  // orr	w8, w10, w8
	ORRW  R8, R9, R8     // <--                                  // orr	w8, w9, w8
	SXTBW R8, R8         // <--                                  // sxtb	w8, w8
	CMNW  $1, R8         // <--                                  // cmn	w8, #1
	CSETW GT, R0         // <--                                  // cset	w0, gt
	MOVB  R0, ret+16(FP) // <--
	RET                  // <--                                  // ret

LBB1_13:
	ADD   R1, R0, R8                // <--                                  // add	x8, x0, x1
	WORD  $0xf9400009               // MOVD (R0), R9                        // ldr	x9, [x0]
	WORD  $0xf85f8108               // MOVD -8(R8), R8                      // ldur	x8, [x8, #-8]
	ORR   R9, R8, R8                // <--                                  // orr	x8, x8, x9
	TST   $-9187201950435737472, R8 // <--                                  // tst	x8, #0x8080808080808080
	CSETW EQ, R0                    // <--                                  // cset	w0, eq
	MOVB  R0, ret+16(FP)            // <--
	RET                             // <--                                  // ret

LBB1_14:
	MOVW ZR, R0         // <--                                  // mov	w0, wzr
	MOVB R0, ret+16(FP) // <--
	RET                 // <--                                  // ret

LBB1_15:
	ADD   R1, R0, R8      // <--                                  // add	x8, x0, x1
	WORD  $0xb9400009     // MOVWU (R0), R9                       // ldr	w9, [x0]
	WORD  $0xb85fc108     // MOVWU -4(R8), R8                     // ldur	w8, [x8, #-4]
	ORRW  R9, R8, R8      // <--                                  // orr	w8, w8, w9
	TSTW  $2155905152, R8 // <--                                  // tst	w8, #0x80808080
	CSETW EQ, R0          // <--                                  // cset	w0, eq
	MOVB  R0, ret+16(FP)  // <--
	RET                   // <--                                  // ret

LBB1_16:
	MOVW $1, R0         // <--                                  // mov	w0, #1
	MOVB R0, ret+16(FP) // <--
	RET                 // <--                                  // ret

TEXT ·IndexMask(SB), NOSPLIT, $0-32
	MOVD data+0(FP), R0
	MOVD length+8(FP), R1
	MOVB mask+16(FP), R2
	CMP  $16, R1          // <--                                  // cmp	x1, #16
	BCC  LBB2_11          // <--                                  // b.lo	.LBB2_11
	VDUP R2, V0.B16       // <--                                  // dup	v0.16b, w2
	CMP  $64, R1          // <--                                  // cmp	x1, #64
	AND  $63, R1, R10     // <--                                  // and	x10, x1, #0x3f
	MOVD R0, R8           // <--                                  // mov	x8, x0
	BLT  LBB2_15          // <--                                  // b.lt	.LBB2_15
	ADD  R1, R0, R8       // <--                                  // add	x8, x0, x1
	MOVD ZR, R9           // <--                                  // mov	x9, xzr
	MOVW $16, R11         // <--                                  // mov	w11, #16
	SUB  R10, R8, R12     // <--                                  // sub	x12, x8, x10
	JMP  LBB2_4           // <--                                  // b	.LBB2_4

LBB2_3:
	ADD $64, R9, R9 // <--                                  // add	x9, x9, #64
	ADD R9, R0, R8  // <--                                  // add	x8, x0, x9
	CMP R12, R8     // <--                                  // cmp	x8, x12
	BCS LBB2_15     // <--                                  // b.hs	.LBB2_15

LBB2_4:
	ADD    R9, R0, R8                             // <--                                  // add	x8, x0, x9
	VLD1   (R8), [V1.B16, V2.B16, V3.B16, V4.B16] // <--                                  // ld1	{ v1.16b, v2.16b, v3.16b, v4.16b }, [x8]
	VAND   V0.B16, V1.B16, V5.B16                 // <--                                  // and	v5.16b, v1.16b, v0.16b
	VAND   V0.B16, V2.B16, V6.B16                 // <--                                  // and	v6.16b, v2.16b, v0.16b
	VAND   V0.B16, V3.B16, V7.B16                 // <--                                  // and	v7.16b, v3.16b, v0.16b
	VAND   V0.B16, V4.B16, V16.B16                // <--                                  // and	v16.16b, v4.16b, v0.16b
	VORR   V5.B16, V6.B16, V5.B16                 // <--                                  // orr	v5.16b, v6.16b, v5.16b
	VORR   V16.B16, V7.B16, V7.B16                // <--                                  // orr	v7.16b, v7.16b, v16.16b
	VORR   V5.B16, V7.B16, V5.B16                 // <--                                  // orr	v5.16b, v7.16b, v5.16b
	VCMTST V5.B16, V5.B16, V5.B16                 // <--                                  // cmtst	v5.16b, v5.16b, v5.16b
	WORD   $0x0f0c84a5                            // VSHRN $4, V5.H8, V5.B8               // shrn	v5.8b, v5.8h, #4
	FMOVD  F5, R8                                 // <--                                  // fmov	x8, d5
	CBZ    R8, LBB2_3                             // <--                                  // cbz	x8, .LBB2_3
	VCMTST V0.B16, V1.B16, V5.B16                 // <--                                  // cmtst	v5.16b, v1.16b, v0.16b
	WORD   $0x0f0c84a5                            // VSHRN $4, V5.H8, V5.B8               // shrn	v5.8b, v5.8h, #4
	FMOVD  F5, R8                                 // <--                                  // fmov	x8, d5
	CBNZ   R8, LBB2_34                            // <--                                  // cbnz	x8, .LBB2_34
	VCMTST V0.B16, V2.B16, V5.B16                 // <--                                  // cmtst	v5.16b, v2.16b, v0.16b
	WORD   $0x0f0c84a5                            // VSHRN $4, V5.H8, V5.B8               // shrn	v5.8b, v5.8h, #4
	FMOVD  F5, R8                                 // <--                                  // fmov	x8, d5
	CBNZ   R8, LBB2_10                            // <--                                  // cbnz	x8, .LBB2_10
	VCMTST V0.B16, V3.B16, V5.B16                 // <--                                  // cmtst	v5.16b, v3.16b, v0.16b
	WORD   $0x0f0c84a5                            // VSHRN $4, V5.H8, V5.B8               // shrn	v5.8b, v5.8h, #4
	FMOVD  F5, R8                                 // <--                                  // fmov	x8, d5
	CBNZ   R8, LBB2_35                            // <--                                  // cbnz	x8, .LBB2_35
	VCMTST V0.B16, V4.B16, V1.B16                 // <--                                  // cmtst	v1.16b, v4.16b, v0.16b
	WORD   $0x0f0c8421                            // VSHRN $4, V1.H8, V1.B8               // shrn	v1.8b, v1.8h, #4
	FMOVD  F1, R8                                 // <--                                  // fmov	x8, d1
	CBZ    R8, LBB2_3                             // <--                                  // cbz	x8, .LBB2_3
	MOVW   $48, R11                               // <--                                  // mov	w11, #48

LBB2_10:
	RBIT R8, R8         // <--                                  // rbit	x8, x8
	CLZ  R8, R8         // <--                                  // clz	x8, x8
	ADD  R8>>2, R11, R8 // <--                                  // add	x8, x11, x8, lsr #2
	ADD  R9, R8, R0     // <--                                  // add	x0, x8, x9
	MOVD R0, ret+24(FP) // <--
	RET                 // <--                                  // ret

LBB2_11:
	MOVD R0, R8 // <--                                  // mov	x8, x0

LBB2_12:
	ANDW $255, R2, R9    // <--                                  // and	w9, w2, #0xff
	MOVW $16843009, R10  // <--                                  // mov	w10, #16843009
	MULW R10, R9, R9     // <--                                  // mul	w9, w9, w10
	SUBS $8, R1, R10     // <--                                  // subs	x10, x1, #8
	BCC  LBB2_20         // <--                                  // b.lo	.LBB2_20
	ORR  R9<<32, R9, R11 // <--                                  // orr	x11, x9, x9, lsl #32
	WORD $0xf940010c     // MOVD (R8), R12                       // ldr	x12, [x8]
	ANDS R11, R12, R11   // <--                                  // ands	x11, x12, x11
	BEQ  LBB2_19         // <--                                  // b.eq	.LBB2_19
	RBIT R11, R9         // <--                                  // rbit	x9, x11
	SUB  R0, R8, R8      // <--                                  // sub	x8, x8, x0
	CLZ  R9, R9          // <--                                  // clz	x9, x9
	ADD  R9>>3, R8, R0   // <--                                  // add	x0, x8, x9, lsr #3
	MOVD R0, ret+24(FP)  // <--
	RET                  // <--                                  // ret

LBB2_15:
	TST $48, R1     // <--                                  // tst	x1, #0x30
	AND $15, R1, R1 // <--                                  // and	x1, x1, #0xf
	BEQ LBB2_12     // <--                                  // b.eq	.LBB2_12
	ADD R10, R8, R9 // <--                                  // add	x9, x8, x10
	SUB R1, R9, R10 // <--                                  // sub	x10, x9, x1
	SUB R0, R8, R9  // <--                                  // sub	x9, x8, x0

LBB2_17:
	WORD   $0x3cc10501            // FMOVQ.P 16(R8), F1                   // ldr	q1, [x8], #16
	VCMTST V0.B16, V1.B16, V1.B16 // <--                                  // cmtst	v1.16b, v1.16b, v0.16b
	WORD   $0x0f0c8421            // VSHRN $4, V1.H8, V1.B8               // shrn	v1.8b, v1.8h, #4
	FMOVD  F1, R11                // <--                                  // fmov	x11, d1
	CBNZ   R11, LBB2_23           // <--                                  // cbnz	x11, .LBB2_23
	CMP    R10, R8                // <--                                  // cmp	x8, x10
	ADD    $16, R9, R9            // <--                                  // add	x9, x9, #16
	BCC    LBB2_17                // <--                                  // b.lo	.LBB2_17
	JMP    LBB2_12                // <--                                  // b	.LBB2_12

LBB2_19:
	ADD  $8, R8, R8 // <--                                  // add	x8, x8, #8
	MOVD R10, R1    // <--                                  // mov	x1, x10

LBB2_20:
	SUBS  $4, R1, R10    // <--                                  // subs	x10, x1, #4
	BCC   LBB2_25        // <--                                  // b.lo	.LBB2_25
	WORD  $0xb940010b    // MOVWU (R8), R11                      // ldr	w11, [x8]
	ANDSW R9, R11, R11   // <--                                  // ands	w11, w11, w9
	BEQ   LBB2_24        // <--                                  // b.eq	.LBB2_24
	RBITW R11, R9        // <--                                  // rbit	w9, w11
	CLZW  R9, R9         // <--                                  // clz	w9, w9
	SUB   R0, R8, R8     // <--                                  // sub	x8, x8, x0
	LSRW  $3, R9, R9     // <--                                  // lsr	w9, w9, #3
	ADD   R9, R8, R0     // <--                                  // add	x0, x8, x9
	MOVD  R0, ret+24(FP) // <--
	RET                  // <--                                  // ret

LBB2_23:
	RBIT R11, R8        // <--                                  // rbit	x8, x11
	CLZ  R8, R8         // <--                                  // clz	x8, x8
	ADD  R8>>2, R9, R0  // <--                                  // add	x0, x9, x8, lsr #2
	MOVD R0, ret+24(FP) // <--
	RET                 // <--                                  // ret

LBB2_24:
	ADD  $4, R8, R8 // <--                                  // add	x8, x8, #4
	MOVD R10, R1    // <--                                  // mov	x1, x10

LBB2_25:
	CMP   $1, R1            // <--                                  // cmp	x1, #1
	BEQ   LBB2_30           // <--                                  // b.eq	.LBB2_30
	CMP   $2, R1            // <--                                  // cmp	x1, #2
	BEQ   LBB2_29           // <--                                  // b.eq	.LBB2_29
	CMP   $3, R1            // <--                                  // cmp	x1, #3
	BNE   LBB2_32           // <--                                  // b.ne	.LBB2_32
	WORD  $0x7940010a       // MOVHU (R8), R10                      // ldrh	w10, [x8]
	WORD  $0x3940090b       // MOVBU 2(R8), R11                     // ldrb	w11, [x8, #2]
	ORRW  R11<<16, R10, R10 // <--                                  // orr	w10, w10, w11, lsl #16
	ANDSW R9, R10, R9       // <--                                  // ands	w9, w10, w9
	BNE   LBB2_31           // <--                                  // b.ne	.LBB2_31
	JMP   LBB2_33           // <--                                  // b	.LBB2_33

LBB2_29:
	WORD  $0x7940010a // MOVHU (R8), R10                      // ldrh	w10, [x8]
	ANDSW R9, R10, R9 // <--                                  // ands	w9, w10, w9
	BNE   LBB2_31     // <--                                  // b.ne	.LBB2_31
	JMP   LBB2_33     // <--                                  // b	.LBB2_33

LBB2_30:
	WORD  $0x3940010a // MOVBU (R8), R10                      // ldrb	w10, [x8]
	ANDSW R9, R10, R9 // <--                                  // ands	w9, w10, w9
	BEQ   LBB2_33     // <--                                  // b.eq	.LBB2_33

LBB2_31:
	RBITW R9, R9         // <--                                  // rbit	w9, w9
	CLZW  R9, R9         // <--                                  // clz	w9, w9
	SUB   R0, R8, R8     // <--                                  // sub	x8, x8, x0
	LSRW  $3, R9, R9     // <--                                  // lsr	w9, w9, #3
	ADD   R9, R8, R0     // <--                                  // add	x0, x8, x9
	MOVD  R0, ret+24(FP) // <--
	RET                  // <--                                  // ret

LBB2_32:
	ANDSW R9, ZR, R9 // <--                                  // ands	w9, wzr, w9
	BNE   LBB2_31    // <--                                  // b.ne	.LBB2_31

LBB2_33:
	MOVD $-1, R0        // <--                                  // mov	x0, #-1
	MOVD R0, ret+24(FP) // <--
	RET                 // <--                                  // ret

LBB2_34:
	RBIT R8, R8         // <--                                  // rbit	x8, x8
	CLZ  R8, R8         // <--                                  // clz	x8, x8
	ADD  R8>>2, ZR, R8  // <--                                  // add	x8, xzr, x8, lsr #2
	ADD  R9, R8, R0     // <--                                  // add	x0, x8, x9
	MOVD R0, ret+24(FP) // <--
	RET                 // <--                                  // ret

LBB2_35:
	MOVW $32, R11       // <--                                  // mov	w11, #32
	RBIT R8, R8         // <--                                  // rbit	x8, x8
	CLZ  R8, R8         // <--                                  // clz	x8, x8
	ADD  R8>>2, R11, R8 // <--                                  // add	x8, x11, x8, lsr #2
	ADD  R9, R8, R0     // <--                                  // add	x0, x8, x9
	MOVD R0, ret+24(FP) // <--
	RET                 // <--                                  // ret

TEXT ·EqualFold(SB), NOSPLIT, $0-33
	MOVD a+0(FP), R0
	MOVD a_len+8(FP), R1
	MOVD b+16(FP), R2
	MOVD b_len+24(FP), R3
	CMP  R3, R1                      // <--                                  // cmp	x1, x3
	BNE  LBB3_8                      // <--                                  // b.ne	.LBB3_8
	TBNZ $63, R1, LBB3_8             // <--                                  // tbnz	x1, #63, .LBB3_8
	MOVD $uppercasingTable<>(SB), R8 // <--                                  // adrp	x8, uppercasingTable
	NOP                              // (skipped)                            // add	x8, x8, :lo12:uppercasingTable
	CMP  $16, R1                     // <--                                  // cmp	x1, #16
	VLD1 (R8), [V0.B16, V1.B16]      // <--                                  // ld1	{ v0.16b, v1.16b }, [x8]
	AND  $15, R1, R8                 // <--                                  // and	x8, x1, #0xf
	BCC  LBB3_6                      // <--                                  // b.lo	.LBB3_6
	WORD $0x4f05e402                 // VMOVI $160, V2.B16                   // movi	v2.16b, #160
	ADD  R1, R0, R9                  // <--                                  // add	x9, x0, x1
	SUB  R8, R9, R9                  // <--                                  // sub	x9, x9, x8

LBB3_4:
	WORD  $0x3cc10403                      // FMOVQ.P 16(R0), F3                   // ldr	q3, [x0], #16
	WORD  $0x3cc10444                      // FMOVQ.P 16(R2), F4                   // ldr	q4, [x2], #16
	VADD  V2.B16, V3.B16, V3.B16           // <--                                  // add	v3.16b, v3.16b, v2.16b
	VADD  V2.B16, V4.B16, V4.B16           // <--                                  // add	v4.16b, v4.16b, v2.16b
	VTBL  V3.B16, [V0.B16, V1.B16], V5.B16 // <--                                  // tbl	v5.16b, { v0.16b, v1.16b }, v3.16b
	VTBL  V4.B16, [V0.B16, V1.B16], V6.B16 // <--                                  // tbl	v6.16b, { v0.16b, v1.16b }, v4.16b
	VSUB  V5.B16, V3.B16, V3.B16           // <--                                  // sub	v3.16b, v3.16b, v5.16b
	VSUB  V6.B16, V4.B16, V4.B16           // <--                                  // sub	v4.16b, v4.16b, v6.16b
	VCMEQ V4.B16, V3.B16, V3.B16           // <--                                  // cmeq	v3.16b, v3.16b, v4.16b
	WORD  $0x0f0c8463                      // VSHRN $4, V3.H8, V3.B8               // shrn	v3.8b, v3.8h, #4
	FMOVD F3, R10                          // <--                                  // fmov	x10, d3
	CMN   $1, R10                          // <--                                  // cmn	x10, #1
	BNE   LBB3_8                           // <--                                  // b.ne	.LBB3_8
	CMP   R9, R0                           // <--                                  // cmp	x0, x9
	BCC   LBB3_4                           // <--                                  // b.lo	.LBB3_4

LBB3_6:
	CMP   $8, R8                         // <--                                  // cmp	x8, #8
	BCC   LBB3_10                        // <--                                  // b.lo	.LBB3_10
	WORD  $0x0f05e402                    // VMOVI $160, V2.B8                    // movi	v2.8b, #160
	WORD  $0xfc408403                    // FMOVD.P 8(R0), F3                    // ldr	d3, [x0], #8
	WORD  $0xfc408444                    // FMOVD.P 8(R2), F4                    // ldr	d4, [x2], #8
	VADD  V2.B8, V3.B8, V3.B8            // <--                                  // add	v3.8b, v3.8b, v2.8b
	VADD  V2.B8, V4.B8, V2.B8            // <--                                  // add	v2.8b, v4.8b, v2.8b
	VTBL  V3.B8, [V0.B16, V1.B16], V4.B8 // <--                                  // tbl	v4.8b, { v0.16b, v1.16b }, v3.8b
	VTBL  V2.B8, [V0.B16, V1.B16], V5.B8 // <--                                  // tbl	v5.8b, { v0.16b, v1.16b }, v2.8b
	VSUB  V4.B8, V3.B8, V3.B8            // <--                                  // sub	v3.8b, v3.8b, v4.8b
	VSUB  V5.B8, V2.B8, V2.B8            // <--                                  // sub	v2.8b, v2.8b, v5.8b
	VCMEQ V2.B8, V3.B8, V2.B8            // <--                                  // cmeq	v2.8b, v3.8b, v2.8b
	FMOVD F2, R8                         // <--                                  // fmov	x8, d2
	CMN   $1, R8                         // <--                                  // cmn	x8, #1
	BEQ   LBB3_9                         // <--                                  // b.eq	.LBB3_9

LBB3_8:
	MOVW ZR, R0         // <--                                  // mov	w0, wzr
	MOVB R0, ret+32(FP) // <--
	RET                 // <--                                  // ret

LBB3_9:
	AND $7, R1, R8 // <--                                  // and	x8, x1, #0x7

LBB3_10:
	CBZ  R8, LBB3_16 // <--                                  // cbz	x8, .LBB3_16
	SUBS $4, R8, R11 // <--                                  // subs	x11, x8, #4
	BCC  LBB3_17     // <--                                  // b.lo	.LBB3_17
	WORD $0xb840440a // MOVWU.P 4(R0), R10                   // ldr	w10, [x0], #4
	MOVD R11, R8     // <--                                  // mov	x8, x11
	WORD $0xb8404449 // MOVWU.P 4(R2), R9                    // ldr	w9, [x2], #4
	CMP  $1, R11     // <--                                  // cmp	x11, #1
	BEQ  LBB3_18     // <--                                  // b.eq	.LBB3_18

LBB3_13:
	CMP  $2, R8         // <--                                  // cmp	x8, #2
	BEQ  LBB3_19        // <--                                  // b.eq	.LBB3_19
	CMP  $3, R8         // <--                                  // cmp	x8, #3
	BNE  LBB3_20        // <--                                  // b.ne	.LBB3_20
	LSL  $24, R10, R8   // <--                                  // lsl	x8, x10, #24
	WORD $0x7940000a    // MOVHU (R0), R10                      // ldrh	w10, [x0]
	LSL  $24, R9, R9    // <--                                  // lsl	x9, x9, #24
	WORD $0x7940004b    // MOVHU (R2), R11                      // ldrh	w11, [x2]
	ORR  R10<<8, R8, R8 // <--                                  // orr	x8, x8, x10, lsl #8
	WORD $0x3940080a    // MOVBU 2(R0), R10                     // ldrb	w10, [x0, #2]
	ORR  R11<<8, R9, R9 // <--                                  // orr	x9, x9, x11, lsl #8
	WORD $0x3940084b    // MOVBU 2(R2), R11                     // ldrb	w11, [x2, #2]
	ORR  R10, R8, R10   // <--                                  // orr	x10, x8, x10
	ORR  R11, R9, R9    // <--                                  // orr	x9, x9, x11
	JMP  LBB3_20        // <--                                  // b	.LBB3_20

LBB3_16:
	MOVW $1, R0         // <--                                  // mov	w0, #1
	MOVB R0, ret+32(FP) // <--
	RET                 // <--                                  // ret

LBB3_17:
	MOVD ZR, R9  // <--                                  // mov	x9, xzr
	MOVD ZR, R10 // <--                                  // mov	x10, xzr
	CMP  $1, R8  // <--                                  // cmp	x8, #1
	BNE  LBB3_13 // <--                                  // b.ne	.LBB3_13

LBB3_18:
	WORD $0x39400008     // MOVBU (R0), R8                       // ldrb	w8, [x0]
	WORD $0x3940004b     // MOVBU (R2), R11                      // ldrb	w11, [x2]
	ORR  R10<<8, R8, R10 // <--                                  // orr	x10, x8, x10, lsl #8
	ORR  R9<<8, R11, R9  // <--                                  // orr	x9, x11, x9, lsl #8
	JMP  LBB3_20         // <--                                  // b	.LBB3_20

LBB3_19:
	WORD $0x79400008      // MOVHU (R0), R8                       // ldrh	w8, [x0]
	WORD $0x7940004b      // MOVHU (R2), R11                      // ldrh	w11, [x2]
	ORR  R10<<16, R8, R10 // <--                                  // orr	x10, x8, x10, lsl #16
	ORR  R9<<16, R11, R9  // <--                                  // orr	x9, x11, x9, lsl #16

LBB3_20:
	WORD  $0x0f05e402                    // VMOVI $160, V2.B8                    // movi	v2.8b, #160
	FMOVD R10, F3                        // <--                                  // fmov	d3, x10
	FMOVD R9, F4                         // <--                                  // fmov	d4, x9
	VADD  V2.B8, V3.B8, V3.B8            // <--                                  // add	v3.8b, v3.8b, v2.8b
	VADD  V2.B8, V4.B8, V2.B8            // <--                                  // add	v2.8b, v4.8b, v2.8b
	VTBL  V3.B8, [V0.B16, V1.B16], V4.B8 // <--                                  // tbl	v4.8b, { v0.16b, v1.16b }, v3.8b
	VTBL  V2.B8, [V0.B16, V1.B16], V0.B8 // <--                                  // tbl	v0.8b, { v0.16b, v1.16b }, v2.8b
	VSUB  V4.B8, V3.B8, V1.B8            // <--                                  // sub	v1.8b, v3.8b, v4.8b
	VSUB  V0.B8, V2.B8, V0.B8            // <--                                  // sub	v0.8b, v2.8b, v0.8b
	VCMEQ V0.B8, V1.B8, V0.B8            // <--                                  // cmeq	v0.8b, v1.8b, v0.8b
	FMOVD F0, R8                         // <--                                  // fmov	x8, d0
	CMN   $1, R8                         // <--                                  // cmn	x8, #1
	CSETW EQ, R0                         // <--                                  // cset	w0, eq
	MOVB  R0, ret+32(FP)                 // <--
	RET                                  // <--                                  // ret

TEXT ·indexFoldRabinKarp(SB), NOSPLIT, $0-40
	MOVD haystack+0(FP), R0
	MOVD haystack_len+8(FP), R1
	MOVD needle+16(FP), R2
	MOVD needle_len+24(FP), R3
	CMP  $1, R3                 // <--                                  // cmp	x3, #1
	BLT  LBB4_3                 // <--                                  // b.lt	.LBB4_3
	SUBS R3, R1, R8             // <--                                  // subs	x8, x1, x3
	BGE  LBB4_4                 // <--                                  // b.ge	.LBB4_4
	MOVD $-1, R0                // <--                                  // mov	x0, #-1
	MOVD R0, ret+32(FP)         // <--
	RET                         // <--                                  // ret

LBB4_3:
	MOVD ZR, R0         // <--                                  // mov	x0, xzr
	MOVD R0, ret+32(FP) // <--
	RET                 // <--                                  // ret

LBB4_4:
	MOVD  $uppercasingTable<>(SB), R9 // <--                                  // adrp	x9, uppercasingTable
	NOP                               // (skipped)                            // add	x9, x9, :lo12:uppercasingTable
	MOVW  $403, R10                   // <--                                  // mov	w10, #403
	VLD1  (R9), [V0.B16, V1.B16]      // <--                                  // ld1	{ v0.16b, v1.16b }, [x9]
	MOVW  $403, R9                    // <--                                  // mov	w9, #403
	MOVW  $1, R12                     // <--                                  // mov	w12, #1
	MOVKW $(256<<16), R9              // <--                                  // movk	w9, #256, lsl #16
	MOVKW $(256<<16), R10             // <--                                  // movk	w10, #256, lsl #16
	MOVD  R3, R11                     // <--                                  // mov	x11, x3

LBB4_5:
	TST    $1, R11                // <--                                  // tst	x11, #0x1
	CSINCW NE, R10, ZR, R13       // <--                                  // csinc	w13, w10, wzr, ne
	MULW   R10, R10, R10          // <--                                  // mul	w10, w10, w10
	CMP    $1, R11                // <--                                  // cmp	x11, #1
	MULW   R12, R13, R12          // <--                                  // mul	w12, w13, w12
	LSR    $1, R11, R13           // <--                                  // lsr	x13, x11, #1
	MOVD   R13, R11               // <--                                  // mov	x11, x13
	BHI    LBB4_5                 // <--                                  // b.hi	.LBB4_5
	MOVD   ZR, R13                // <--                                  // mov	x13, xzr
	MOVW   ZR, R10                // <--                                  // mov	w10, wzr
	MOVD   $fold_table<>(SB), R11 // <--                                  // adrp	x11, fold_table
	NOP                           // (skipped)                            // add	x11, x11, :lo12:fold_table

LBB4_7:
	WORD  $0x386d684e       // MOVBU (R2)(R13), R14                 // ldrb	w14, [x2, x13]
	ADD   $1, R13, R13      // <--                                  // add	x13, x13, #1
	CMP   R13, R3           // <--                                  // cmp	x3, x13
	WORD  $0x386e696e       // MOVBU (R11)(R14), R14                // ldrb	w14, [x11, x14]
	MADDW R9, R14, R10, R10 // <--                                  // madd	w10, w10, w9, w14
	BNE   LBB4_7            // <--                                  // b.ne	.LBB4_7
	NOP                     // (skipped)                            // str	x19, [sp, #-16]!
	CMP   $8, R8            // <--                                  // cmp	x8, #8
	NEGW  R12, R12          // <--                                  // neg	w12, w12
	MOVD  ZR, R14           // <--                                  // mov	x14, xzr
	MOVW  ZR, R13           // <--                                  // mov	w13, wzr
	BCS   LBB4_21           // <--                                  // b.hs	.LBB4_21

LBB4_9:
	WORD  $0x386e680f       // MOVBU (R0)(R14), R15                 // ldrb	w15, [x0, x14]
	ADD   $1, R14, R14      // <--                                  // add	x14, x14, #1
	CMP   R14, R3           // <--                                  // cmp	x3, x14
	WORD  $0x386f696f       // MOVBU (R11)(R15), R15                // ldrb	w15, [x11, x15]
	MADDW R9, R15, R13, R13 // <--                                  // madd	w13, w13, w9, w15
	BNE   LBB4_9            // <--                                  // b.ne	.LBB4_9
	CMPW  R10, R13          // <--                                  // cmp	w13, w10
	BNE   LBB4_47           // <--                                  // b.ne	.LBB4_47
	CMP   $16, R3           // <--                                  // cmp	x3, #16
	AND   $15, R3, R16      // <--                                  // and	x16, x3, #0xf
	MOVD  R2, R14           // <--                                  // mov	x14, x2
	MOVD  R0, R15           // <--                                  // mov	x15, x0
	BCC   LBB4_15           // <--                                  // b.lo	.LBB4_15
	WORD  $0x4f05e402       // VMOVI $160, V2.B16                   // movi	v2.16b, #160
	ADD   R3, R0, R14       // <--                                  // add	x14, x0, x3
	MOVD  R0, R15           // <--                                  // mov	x15, x0
	SUB   R16, R14, R17     // <--                                  // sub	x17, x14, x16
	MOVD  R2, R14           // <--                                  // mov	x14, x2

LBB4_13:
	WORD  $0x3cc105e3                      // FMOVQ.P 16(R15), F3                  // ldr	q3, [x15], #16
	WORD  $0x3cc105c4                      // FMOVQ.P 16(R14), F4                  // ldr	q4, [x14], #16
	VADD  V2.B16, V3.B16, V3.B16           // <--                                  // add	v3.16b, v3.16b, v2.16b
	VADD  V2.B16, V4.B16, V4.B16           // <--                                  // add	v4.16b, v4.16b, v2.16b
	VTBL  V3.B16, [V0.B16, V1.B16], V5.B16 // <--                                  // tbl	v5.16b, { v0.16b, v1.16b }, v3.16b
	VTBL  V4.B16, [V0.B16, V1.B16], V6.B16 // <--                                  // tbl	v6.16b, { v0.16b, v1.16b }, v4.16b
	VSUB  V5.B16, V3.B16, V3.B16           // <--                                  // sub	v3.16b, v3.16b, v5.16b
	VSUB  V6.B16, V4.B16, V4.B16           // <--                                  // sub	v4.16b, v4.16b, v6.16b
	VCMEQ V4.B16, V3.B16, V3.B16           // <--                                  // cmeq	v3.16b, v3.16b, v4.16b
	WORD  $0x0f0c8463                      // VSHRN $4, V3.H8, V3.B8               // shrn	v3.8b, v3.8h, #4
	FMOVD F3, R4                           // <--                                  // fmov	x4, d3
	CMN   $1, R4                           // <--                                  // cmn	x4, #1
	BNE   LBB4_47                          // <--                                  // b.ne	.LBB4_47
	CMP   R17, R15                         // <--                                  // cmp	x15, x17
	BCC   LBB4_13                          // <--                                  // b.lo	.LBB4_13

LBB4_15:
	CMP   $8, R16                        // <--                                  // cmp	x16, #8
	BCC   LBB4_18                        // <--                                  // b.lo	.LBB4_18
	WORD  $0x0f05e402                    // VMOVI $160, V2.B8                    // movi	v2.8b, #160
	WORD  $0xfc4085e3                    // FMOVD.P 8(R15), F3                   // ldr	d3, [x15], #8
	WORD  $0xfc4085c4                    // FMOVD.P 8(R14), F4                   // ldr	d4, [x14], #8
	VADD  V2.B8, V3.B8, V3.B8            // <--                                  // add	v3.8b, v3.8b, v2.8b
	VADD  V2.B8, V4.B8, V2.B8            // <--                                  // add	v2.8b, v4.8b, v2.8b
	VTBL  V3.B8, [V0.B16, V1.B16], V4.B8 // <--                                  // tbl	v4.8b, { v0.16b, v1.16b }, v3.8b
	VTBL  V2.B8, [V0.B16, V1.B16], V5.B8 // <--                                  // tbl	v5.8b, { v0.16b, v1.16b }, v2.8b
	VSUB  V4.B8, V3.B8, V3.B8            // <--                                  // sub	v3.8b, v3.8b, v4.8b
	VSUB  V5.B8, V2.B8, V2.B8            // <--                                  // sub	v2.8b, v2.8b, v5.8b
	VCMEQ V2.B8, V3.B8, V2.B8            // <--                                  // cmeq	v2.8b, v3.8b, v2.8b
	FMOVD F2, R16                        // <--                                  // fmov	x16, d2
	CMN   $1, R16                        // <--                                  // cmn	x16, #1
	BNE   LBB4_47                        // <--                                  // b.ne	.LBB4_47
	AND   $7, R3, R16                    // <--                                  // and	x16, x3, #0x7

LBB4_18:
	CBZ  R16, LBB4_97 // <--                                  // cbz	x16, .LBB4_97
	SUBS $4, R16, R5  // <--                                  // subs	x5, x16, #4
	BCC  LBB4_33      // <--                                  // b.lo	.LBB4_33
	WORD $0xb84045e4  // MOVWU.P 4(R15), R4                   // ldr	w4, [x15], #4
	MOVD R5, R16      // <--                                  // mov	x16, x5
	WORD $0xb84045d1  // MOVWU.P 4(R14), R17                  // ldr	w17, [x14], #4
	JMP  LBB4_34      // <--                                  // b	.LBB4_34

LBB4_21:
	WORD  $0x386e680f       // MOVBU (R0)(R14), R15                 // ldrb	w15, [x0, x14]
	ADD   $1, R14, R14      // <--                                  // add	x14, x14, #1
	CMP   R14, R3           // <--                                  // cmp	x3, x14
	WORD  $0x386f696f       // MOVBU (R11)(R15), R15                // ldrb	w15, [x11, x15]
	MADDW R9, R15, R13, R13 // <--                                  // madd	w13, w13, w9, w15
	BNE   LBB4_21           // <--                                  // b.ne	.LBB4_21
	CMPW  R10, R13          // <--                                  // cmp	w13, w10
	BNE   LBB4_72           // <--                                  // b.ne	.LBB4_72
	CMP   $16, R3           // <--                                  // cmp	x3, #16
	AND   $15, R3, R16      // <--                                  // and	x16, x3, #0xf
	MOVD  R2, R14           // <--                                  // mov	x14, x2
	MOVD  R0, R15           // <--                                  // mov	x15, x0
	BCC   LBB4_27           // <--                                  // b.lo	.LBB4_27
	WORD  $0x4f05e402       // VMOVI $160, V2.B16                   // movi	v2.16b, #160
	ADD   R3, R0, R14       // <--                                  // add	x14, x0, x3
	MOVD  R0, R15           // <--                                  // mov	x15, x0
	SUB   R16, R14, R17     // <--                                  // sub	x17, x14, x16
	MOVD  R2, R14           // <--                                  // mov	x14, x2

LBB4_25:
	WORD  $0x3cc105e3                      // FMOVQ.P 16(R15), F3                  // ldr	q3, [x15], #16
	WORD  $0x3cc105c4                      // FMOVQ.P 16(R14), F4                  // ldr	q4, [x14], #16
	VADD  V2.B16, V3.B16, V3.B16           // <--                                  // add	v3.16b, v3.16b, v2.16b
	VADD  V2.B16, V4.B16, V4.B16           // <--                                  // add	v4.16b, v4.16b, v2.16b
	VTBL  V3.B16, [V0.B16, V1.B16], V5.B16 // <--                                  // tbl	v5.16b, { v0.16b, v1.16b }, v3.16b
	VTBL  V4.B16, [V0.B16, V1.B16], V6.B16 // <--                                  // tbl	v6.16b, { v0.16b, v1.16b }, v4.16b
	VSUB  V5.B16, V3.B16, V3.B16           // <--                                  // sub	v3.16b, v3.16b, v5.16b
	VSUB  V6.B16, V4.B16, V4.B16           // <--                                  // sub	v4.16b, v4.16b, v6.16b
	VCMEQ V4.B16, V3.B16, V3.B16           // <--                                  // cmeq	v3.16b, v3.16b, v4.16b
	WORD  $0x0f0c8463                      // VSHRN $4, V3.H8, V3.B8               // shrn	v3.8b, v3.8h, #4
	FMOVD F3, R1                           // <--                                  // fmov	x1, d3
	CMN   $1, R1                           // <--                                  // cmn	x1, #1
	BNE   LBB4_72                          // <--                                  // b.ne	.LBB4_72
	CMP   R17, R15                         // <--                                  // cmp	x15, x17
	BCC   LBB4_25                          // <--                                  // b.lo	.LBB4_25

LBB4_27:
	CMP   $8, R16                        // <--                                  // cmp	x16, #8
	BCC   LBB4_30                        // <--                                  // b.lo	.LBB4_30
	WORD  $0x0f05e402                    // VMOVI $160, V2.B8                    // movi	v2.8b, #160
	WORD  $0xfc4085e3                    // FMOVD.P 8(R15), F3                   // ldr	d3, [x15], #8
	WORD  $0xfc4085c4                    // FMOVD.P 8(R14), F4                   // ldr	d4, [x14], #8
	VADD  V2.B8, V3.B8, V3.B8            // <--                                  // add	v3.8b, v3.8b, v2.8b
	VADD  V2.B8, V4.B8, V2.B8            // <--                                  // add	v2.8b, v4.8b, v2.8b
	VTBL  V3.B8, [V0.B16, V1.B16], V4.B8 // <--                                  // tbl	v4.8b, { v0.16b, v1.16b }, v3.8b
	VTBL  V2.B8, [V0.B16, V1.B16], V5.B8 // <--                                  // tbl	v5.8b, { v0.16b, v1.16b }, v2.8b
	VSUB  V4.B8, V3.B8, V3.B8            // <--                                  // sub	v3.8b, v3.8b, v4.8b
	VSUB  V5.B8, V2.B8, V2.B8            // <--                                  // sub	v2.8b, v2.8b, v5.8b
	VCMEQ V2.B8, V3.B8, V2.B8            // <--                                  // cmeq	v2.8b, v3.8b, v2.8b
	FMOVD F2, R16                        // <--                                  // fmov	x16, d2
	CMN   $1, R16                        // <--                                  // cmn	x16, #1
	BNE   LBB4_72                        // <--                                  // b.ne	.LBB4_72
	AND   $7, R3, R16                    // <--                                  // and	x16, x3, #0x7

LBB4_30:
	CBZ  R16, LBB4_97 // <--                                  // cbz	x16, .LBB4_97
	SUBS $4, R16, R4  // <--                                  // subs	x4, x16, #4
	BCC  LBB4_38      // <--                                  // b.lo	.LBB4_38
	WORD $0xb84045e1  // MOVWU.P 4(R15), R1                   // ldr	w1, [x15], #4
	MOVD R4, R16      // <--                                  // mov	x16, x4
	WORD $0xb84045d1  // MOVWU.P 4(R14), R17                  // ldr	w17, [x14], #4
	JMP  LBB4_39      // <--                                  // b	.LBB4_39

LBB4_33:
	MOVD ZR, R17 // <--                                  // mov	x17, xzr
	MOVD ZR, R4  // <--                                  // mov	x4, xzr

LBB4_34:
	CMP  $1, R16         // <--                                  // cmp	x16, #1
	BEQ  LBB4_45         // <--                                  // b.eq	.LBB4_45
	CMP  $2, R16         // <--                                  // cmp	x16, #2
	BEQ  LBB4_43         // <--                                  // b.eq	.LBB4_43
	CMP  $3, R16         // <--                                  // cmp	x16, #3
	BNE  LBB4_46         // <--                                  // b.ne	.LBB4_46
	LSL  $24, R4, R16    // <--                                  // lsl	x16, x4, #24
	WORD $0x794001e4     // MOVHU (R15), R4                      // ldrh	w4, [x15]
	LSL  $24, R17, R17   // <--                                  // lsl	x17, x17, #24
	WORD $0x794001c5     // MOVHU (R14), R5                      // ldrh	w5, [x14]
	WORD $0x394009ef     // MOVBU 2(R15), R15                    // ldrb	w15, [x15, #2]
	WORD $0x394009ce     // MOVBU 2(R14), R14                    // ldrb	w14, [x14, #2]
	ORR  R4<<8, R16, R16 // <--                                  // orr	x16, x16, x4, lsl #8
	ORR  R5<<8, R17, R17 // <--                                  // orr	x17, x17, x5, lsl #8
	ORR  R15, R16, R4    // <--                                  // orr	x4, x16, x15
	ORR  R14, R17, R17   // <--                                  // orr	x17, x17, x14
	JMP  LBB4_46         // <--                                  // b	.LBB4_46

LBB4_38:
	MOVD ZR, R17 // <--                                  // mov	x17, xzr
	MOVD ZR, R1  // <--                                  // mov	x1, xzr

LBB4_39:
	CMP  $1, R16         // <--                                  // cmp	x16, #1
	BEQ  LBB4_70         // <--                                  // b.eq	.LBB4_70
	CMP  $2, R16         // <--                                  // cmp	x16, #2
	BEQ  LBB4_44         // <--                                  // b.eq	.LBB4_44
	CMP  $3, R16         // <--                                  // cmp	x16, #3
	BNE  LBB4_71         // <--                                  // b.ne	.LBB4_71
	LSL  $24, R1, R16    // <--                                  // lsl	x16, x1, #24
	WORD $0x794001e1     // MOVHU (R15), R1                      // ldrh	w1, [x15]
	LSL  $24, R17, R17   // <--                                  // lsl	x17, x17, #24
	WORD $0x794001c4     // MOVHU (R14), R4                      // ldrh	w4, [x14]
	WORD $0x394009ef     // MOVBU 2(R15), R15                    // ldrb	w15, [x15, #2]
	WORD $0x394009ce     // MOVBU 2(R14), R14                    // ldrb	w14, [x14, #2]
	ORR  R1<<8, R16, R16 // <--                                  // orr	x16, x16, x1, lsl #8
	ORR  R4<<8, R17, R17 // <--                                  // orr	x17, x17, x4, lsl #8
	ORR  R15, R16, R1    // <--                                  // orr	x1, x16, x15
	ORR  R14, R17, R17   // <--                                  // orr	x17, x17, x14
	JMP  LBB4_71         // <--                                  // b	.LBB4_71

LBB4_43:
	WORD $0x794001ef       // MOVHU (R15), R15                     // ldrh	w15, [x15]
	WORD $0x794001ce       // MOVHU (R14), R14                     // ldrh	w14, [x14]
	ORR  R4<<16, R15, R4   // <--                                  // orr	x4, x15, x4, lsl #16
	ORR  R17<<16, R14, R17 // <--                                  // orr	x17, x14, x17, lsl #16
	JMP  LBB4_46           // <--                                  // b	.LBB4_46

LBB4_44:
	WORD $0x794001ef       // MOVHU (R15), R15                     // ldrh	w15, [x15]
	WORD $0x794001ce       // MOVHU (R14), R14                     // ldrh	w14, [x14]
	ORR  R1<<16, R15, R1   // <--                                  // orr	x1, x15, x1, lsl #16
	ORR  R17<<16, R14, R17 // <--                                  // orr	x17, x14, x17, lsl #16
	JMP  LBB4_71           // <--                                  // b	.LBB4_71

LBB4_45:
	WORD $0x394001ef      // MOVBU (R15), R15                     // ldrb	w15, [x15]
	WORD $0x394001ce      // MOVBU (R14), R14                     // ldrb	w14, [x14]
	ORR  R4<<8, R15, R4   // <--                                  // orr	x4, x15, x4, lsl #8
	ORR  R17<<8, R14, R17 // <--                                  // orr	x17, x14, x17, lsl #8

LBB4_46:
	WORD  $0x0f05e402                    // VMOVI $160, V2.B8                    // movi	v2.8b, #160
	FMOVD R4, F3                         // <--                                  // fmov	d3, x4
	FMOVD R17, F4                        // <--                                  // fmov	d4, x17
	VADD  V2.B8, V3.B8, V3.B8            // <--                                  // add	v3.8b, v3.8b, v2.8b
	VADD  V2.B8, V4.B8, V2.B8            // <--                                  // add	v2.8b, v4.8b, v2.8b
	VTBL  V3.B8, [V0.B16, V1.B16], V4.B8 // <--                                  // tbl	v4.8b, { v0.16b, v1.16b }, v3.8b
	VTBL  V2.B8, [V0.B16, V1.B16], V5.B8 // <--                                  // tbl	v5.8b, { v0.16b, v1.16b }, v2.8b
	VSUB  V4.B8, V3.B8, V3.B8            // <--                                  // sub	v3.8b, v3.8b, v4.8b
	VSUB  V5.B8, V2.B8, V2.B8            // <--                                  // sub	v2.8b, v2.8b, v5.8b
	VCMEQ V2.B8, V3.B8, V2.B8            // <--                                  // cmeq	v2.8b, v3.8b, v2.8b
	FMOVD F2, R14                        // <--                                  // fmov	x14, d2
	CMN   $1, R14                        // <--                                  // cmn	x14, #1
	BEQ   LBB4_97                        // <--                                  // b.eq	.LBB4_97

LBB4_47:
	CMP   R3, R1          // <--                                  // cmp	x1, x3
	BEQ   LBB4_95         // <--                                  // b.eq	.LBB4_95
	WORD  $0x0f05e402     // VMOVI $160, V2.B8                    // movi	v2.8b, #160
	WORD  $0x4f05e403     // VMOVI $160, V3.B16                   // movi	v3.16b, #160
	AND   $15, R3, R14    // <--                                  // and	x14, x3, #0xf
	CMP   $1, R8          // <--                                  // cmp	x8, #1
	NEG   R14, R15        // <--                                  // neg	x15, x14
	AND   $7, R3, R16     // <--                                  // and	x16, x3, #0x7
	CSINC GT, R8, ZR, R17 // <--                                  // csinc	x17, x8, xzr, gt
	MOVW  $1, R8          // <--                                  // mov	w8, #1
	JMP   LBB4_52         // <--                                  // b	.LBB4_52

LBB4_49:
	WORD $0x79400021    // MOVHU (R1), R1                       // ldrh	w1, [x1]
	WORD $0x79400084    // MOVHU (R4), R4                       // ldrh	w4, [x4]
	ORR  R6<<16, R1, R6 // <--                                  // orr	x6, x1, x6, lsl #16
	ORR  R5<<16, R4, R5 // <--                                  // orr	x5, x4, x5, lsl #16

LBB4_50:
	FMOVD R6, F4                         // <--                                  // fmov	d4, x6
	FMOVD R5, F5                         // <--                                  // fmov	d5, x5
	VADD  V2.B8, V4.B8, V4.B8            // <--                                  // add	v4.8b, v4.8b, v2.8b
	VADD  V2.B8, V5.B8, V5.B8            // <--                                  // add	v5.8b, v5.8b, v2.8b
	VTBL  V4.B8, [V0.B16, V1.B16], V6.B8 // <--                                  // tbl	v6.8b, { v0.16b, v1.16b }, v4.8b
	VTBL  V5.B8, [V0.B16, V1.B16], V7.B8 // <--                                  // tbl	v7.8b, { v0.16b, v1.16b }, v5.8b
	VSUB  V6.B8, V4.B8, V4.B8            // <--                                  // sub	v4.8b, v4.8b, v6.8b
	VSUB  V7.B8, V5.B8, V5.B8            // <--                                  // sub	v5.8b, v5.8b, v7.8b
	VCMEQ V5.B8, V4.B8, V4.B8            // <--                                  // cmeq	v4.8b, v4.8b, v5.8b
	FMOVD F4, R1                         // <--                                  // fmov	x1, d4
	CMN   $1, R1                         // <--                                  // cmn	x1, #1
	BEQ   LBB4_96                        // <--                                  // b.eq	.LBB4_96

LBB4_51:
	CMP R17, R8    // <--                                  // cmp	x8, x17
	ADD $1, R8, R8 // <--                                  // add	x8, x8, #1
	BEQ LBB4_95    // <--                                  // b.eq	.LBB4_95

LBB4_52:
	ADD   R8, R0, R1        // <--                                  // add	x1, x0, x8
	ADD   R3, R1, R4        // <--                                  // add	x4, x1, x3
	WORD  $0x385ff025       // LDURBW -1(R1), R5                    // ldurb	w5, [x1, #-1]
	WORD  $0x385ff086       // LDURBW -1(R4), R6                    // ldurb	w6, [x4, #-1]
	WORD  $0x38656965       // MOVBU (R11)(R5), R5                  // ldrb	w5, [x11, x5]
	WORD  $0x38666966       // MOVBU (R11)(R6), R6                  // ldrb	w6, [x11, x6]
	MADDW R9, R6, R13, R13  // <--                                  // madd	w13, w13, w9, w6
	MADDW R12, R13, R5, R13 // <--                                  // madd	w13, w5, w12, w13
	CMPW  R10, R13          // <--                                  // cmp	w13, w10
	BNE   LBB4_51           // <--                                  // b.ne	.LBB4_51
	CMP   $16, R3           // <--                                  // cmp	x3, #16
	BCS   LBB4_55           // <--                                  // b.hs	.LBB4_55
	MOVD  R2, R4            // <--                                  // mov	x4, x2
	JMP   LBB4_58           // <--                                  // b	.LBB4_58

LBB4_55:
	ADD  R15, R4, R5 // <--                                  // add	x5, x4, x15
	MOVD R2, R4      // <--                                  // mov	x4, x2

LBB4_56:
	WORD  $0x3cc10424                      // FMOVQ.P 16(R1), F4                   // ldr	q4, [x1], #16
	WORD  $0x3cc10485                      // FMOVQ.P 16(R4), F5                   // ldr	q5, [x4], #16
	VADD  V3.B16, V4.B16, V4.B16           // <--                                  // add	v4.16b, v4.16b, v3.16b
	VADD  V3.B16, V5.B16, V5.B16           // <--                                  // add	v5.16b, v5.16b, v3.16b
	VTBL  V4.B16, [V0.B16, V1.B16], V6.B16 // <--                                  // tbl	v6.16b, { v0.16b, v1.16b }, v4.16b
	VTBL  V5.B16, [V0.B16, V1.B16], V7.B16 // <--                                  // tbl	v7.16b, { v0.16b, v1.16b }, v5.16b
	VSUB  V6.B16, V4.B16, V4.B16           // <--                                  // sub	v4.16b, v4.16b, v6.16b
	VSUB  V7.B16, V5.B16, V5.B16           // <--                                  // sub	v5.16b, v5.16b, v7.16b
	VCMEQ V5.B16, V4.B16, V4.B16           // <--                                  // cmeq	v4.16b, v4.16b, v5.16b
	WORD  $0x0f0c8484                      // VSHRN $4, V4.H8, V4.B8               // shrn	v4.8b, v4.8h, #4
	FMOVD F4, R6                           // <--                                  // fmov	x6, d4
	CMN   $1, R6                           // <--                                  // cmn	x6, #1
	BNE   LBB4_51                          // <--                                  // b.ne	.LBB4_51
	CMP   R5, R1                           // <--                                  // cmp	x1, x5
	BCC   LBB4_56                          // <--                                  // b.lo	.LBB4_56

LBB4_58:
	CMP   $8, R14                        // <--                                  // cmp	x14, #8
	BCC   LBB4_61                        // <--                                  // b.lo	.LBB4_61
	WORD  $0xfc408424                    // FMOVD.P 8(R1), F4                    // ldr	d4, [x1], #8
	WORD  $0xfc408485                    // FMOVD.P 8(R4), F5                    // ldr	d5, [x4], #8
	VADD  V2.B8, V4.B8, V4.B8            // <--                                  // add	v4.8b, v4.8b, v2.8b
	VADD  V2.B8, V5.B8, V5.B8            // <--                                  // add	v5.8b, v5.8b, v2.8b
	VTBL  V4.B8, [V0.B16, V1.B16], V6.B8 // <--                                  // tbl	v6.8b, { v0.16b, v1.16b }, v4.8b
	VTBL  V5.B8, [V0.B16, V1.B16], V7.B8 // <--                                  // tbl	v7.8b, { v0.16b, v1.16b }, v5.8b
	VSUB  V6.B8, V4.B8, V4.B8            // <--                                  // sub	v4.8b, v4.8b, v6.8b
	VSUB  V7.B8, V5.B8, V5.B8            // <--                                  // sub	v5.8b, v5.8b, v7.8b
	VCMEQ V5.B8, V4.B8, V4.B8            // <--                                  // cmeq	v4.8b, v4.8b, v5.8b
	FMOVD F4, R5                         // <--                                  // fmov	x5, d4
	CMN   $1, R5                         // <--                                  // cmn	x5, #1
	BNE   LBB4_51                        // <--                                  // b.ne	.LBB4_51
	MOVD  R16, R7                        // <--                                  // mov	x7, x16
	JMP   LBB4_62                        // <--                                  // b	.LBB4_62

LBB4_61:
	MOVD R14, R7 // <--                                  // mov	x7, x14

LBB4_62:
	CBZ  R7, LBB4_96 // <--                                  // cbz	x7, .LBB4_96
	SUBS $4, R7, R19 // <--                                  // subs	x19, x7, #4
	BCC  LBB4_68     // <--                                  // b.lo	.LBB4_68
	WORD $0xb8404426 // MOVWU.P 4(R1), R6                    // ldr	w6, [x1], #4
	MOVD R19, R7     // <--                                  // mov	x7, x19
	WORD $0xb8404485 // MOVWU.P 4(R4), R5                    // ldr	w5, [x4], #4
	CMP  $1, R19     // <--                                  // cmp	x19, #1
	BEQ  LBB4_69     // <--                                  // b.eq	.LBB4_69

LBB4_65:
	CMP  $2, R7         // <--                                  // cmp	x7, #2
	BEQ  LBB4_49        // <--                                  // b.eq	.LBB4_49
	CMP  $3, R7         // <--                                  // cmp	x7, #3
	BNE  LBB4_50        // <--                                  // b.ne	.LBB4_50
	LSL  $24, R6, R6    // <--                                  // lsl	x6, x6, #24
	WORD $0x79400027    // MOVHU (R1), R7                       // ldrh	w7, [x1]
	LSL  $24, R5, R5    // <--                                  // lsl	x5, x5, #24
	WORD $0x79400093    // MOVHU (R4), R19                      // ldrh	w19, [x4]
	WORD $0x39400821    // MOVBU 2(R1), R1                      // ldrb	w1, [x1, #2]
	WORD $0x39400884    // MOVBU 2(R4), R4                      // ldrb	w4, [x4, #2]
	ORR  R7<<8, R6, R6  // <--                                  // orr	x6, x6, x7, lsl #8
	ORR  R19<<8, R5, R5 // <--                                  // orr	x5, x5, x19, lsl #8
	ORR  R1, R6, R6     // <--                                  // orr	x6, x6, x1
	ORR  R4, R5, R5     // <--                                  // orr	x5, x5, x4
	JMP  LBB4_50        // <--                                  // b	.LBB4_50

LBB4_68:
	MOVD ZR, R5  // <--                                  // mov	x5, xzr
	MOVD ZR, R6  // <--                                  // mov	x6, xzr
	CMP  $1, R7  // <--                                  // cmp	x7, #1
	BNE  LBB4_65 // <--                                  // b.ne	.LBB4_65

LBB4_69:
	WORD $0x39400021   // MOVBU (R1), R1                       // ldrb	w1, [x1]
	WORD $0x39400084   // MOVBU (R4), R4                       // ldrb	w4, [x4]
	ORR  R6<<8, R1, R6 // <--                                  // orr	x6, x1, x6, lsl #8
	ORR  R5<<8, R4, R5 // <--                                  // orr	x5, x4, x5, lsl #8
	JMP  LBB4_50       // <--                                  // b	.LBB4_50

LBB4_70:
	WORD $0x394001ef      // MOVBU (R15), R15                     // ldrb	w15, [x15]
	WORD $0x394001ce      // MOVBU (R14), R14                     // ldrb	w14, [x14]
	ORR  R1<<8, R15, R1   // <--                                  // orr	x1, x15, x1, lsl #8
	ORR  R17<<8, R14, R17 // <--                                  // orr	x17, x14, x17, lsl #8

LBB4_71:
	WORD  $0x0f05e402                    // VMOVI $160, V2.B8                    // movi	v2.8b, #160
	FMOVD R1, F3                         // <--                                  // fmov	d3, x1
	FMOVD R17, F4                        // <--                                  // fmov	d4, x17
	VADD  V2.B8, V3.B8, V3.B8            // <--                                  // add	v3.8b, v3.8b, v2.8b
	VADD  V2.B8, V4.B8, V2.B8            // <--                                  // add	v2.8b, v4.8b, v2.8b
	VTBL  V3.B8, [V0.B16, V1.B16], V4.B8 // <--                                  // tbl	v4.8b, { v0.16b, v1.16b }, v3.8b
	VTBL  V2.B8, [V0.B16, V1.B16], V5.B8 // <--                                  // tbl	v5.8b, { v0.16b, v1.16b }, v2.8b
	VSUB  V4.B8, V3.B8, V3.B8            // <--                                  // sub	v3.8b, v3.8b, v4.8b
	VSUB  V5.B8, V2.B8, V2.B8            // <--                                  // sub	v2.8b, v2.8b, v5.8b
	VCMEQ V2.B8, V3.B8, V2.B8            // <--                                  // cmeq	v2.8b, v3.8b, v2.8b
	FMOVD F2, R14                        // <--                                  // fmov	x14, d2
	CMN   $1, R14                        // <--                                  // cmn	x14, #1
	BEQ   LBB4_97                        // <--                                  // b.eq	.LBB4_97

LBB4_72:
	CMP  $1, R8       // <--                                  // cmp	x8, #1
	BLT  LBB4_95      // <--                                  // b.lt	.LBB4_95
	WORD $0x0f05e402  // VMOVI $160, V2.B8                    // movi	v2.8b, #160
	WORD $0x4f05e403  // VMOVI $160, V3.B16                   // movi	v3.16b, #160
	AND  $15, R3, R14 // <--                                  // and	x14, x3, #0xf
	NEG  R14, R15     // <--                                  // neg	x15, x14
	AND  $7, R3, R16  // <--                                  // and	x16, x3, #0x7
	ADD  $1, R8, R17  // <--                                  // add	x17, x8, #1
	MOVW $1, R8       // <--                                  // mov	w8, #1
	JMP  LBB4_77      // <--                                  // b	.LBB4_77

LBB4_74:
	WORD $0x79400021    // MOVHU (R1), R1                       // ldrh	w1, [x1]
	WORD $0x79400084    // MOVHU (R4), R4                       // ldrh	w4, [x4]
	ORR  R6<<16, R1, R6 // <--                                  // orr	x6, x1, x6, lsl #16
	ORR  R5<<16, R4, R5 // <--                                  // orr	x5, x4, x5, lsl #16

LBB4_75:
	FMOVD R6, F4                         // <--                                  // fmov	d4, x6
	FMOVD R5, F5                         // <--                                  // fmov	d5, x5
	VADD  V2.B8, V4.B8, V4.B8            // <--                                  // add	v4.8b, v4.8b, v2.8b
	VADD  V2.B8, V5.B8, V5.B8            // <--                                  // add	v5.8b, v5.8b, v2.8b
	VTBL  V4.B8, [V0.B16, V1.B16], V6.B8 // <--                                  // tbl	v6.8b, { v0.16b, v1.16b }, v4.8b
	VTBL  V5.B8, [V0.B16, V1.B16], V7.B8 // <--                                  // tbl	v7.8b, { v0.16b, v1.16b }, v5.8b
	VSUB  V6.B8, V4.B8, V4.B8            // <--                                  // sub	v4.8b, v4.8b, v6.8b
	VSUB  V7.B8, V5.B8, V5.B8            // <--                                  // sub	v5.8b, v5.8b, v7.8b
	VCMEQ V5.B8, V4.B8, V4.B8            // <--                                  // cmeq	v4.8b, v4.8b, v5.8b
	FMOVD F4, R1                         // <--                                  // fmov	x1, d4
	CMN   $1, R1                         // <--                                  // cmn	x1, #1
	BEQ   LBB4_96                        // <--                                  // b.eq	.LBB4_96

LBB4_76:
	ADD $1, R8, R8 // <--                                  // add	x8, x8, #1
	CMP R17, R8    // <--                                  // cmp	x8, x17
	BEQ LBB4_95    // <--                                  // b.eq	.LBB4_95

LBB4_77:
	ADD   R8, R0, R1        // <--                                  // add	x1, x0, x8
	ADD   R3, R1, R4        // <--                                  // add	x4, x1, x3
	WORD  $0x385ff025       // LDURBW -1(R1), R5                    // ldurb	w5, [x1, #-1]
	WORD  $0x385ff086       // LDURBW -1(R4), R6                    // ldurb	w6, [x4, #-1]
	WORD  $0x38656965       // MOVBU (R11)(R5), R5                  // ldrb	w5, [x11, x5]
	WORD  $0x38666966       // MOVBU (R11)(R6), R6                  // ldrb	w6, [x11, x6]
	MADDW R9, R6, R13, R13  // <--                                  // madd	w13, w13, w9, w6
	MADDW R12, R13, R5, R13 // <--                                  // madd	w13, w5, w12, w13
	CMPW  R10, R13          // <--                                  // cmp	w13, w10
	BNE   LBB4_76           // <--                                  // b.ne	.LBB4_76
	CMP   $16, R3           // <--                                  // cmp	x3, #16
	BCS   LBB4_80           // <--                                  // b.hs	.LBB4_80
	MOVD  R2, R4            // <--                                  // mov	x4, x2
	JMP   LBB4_83           // <--                                  // b	.LBB4_83

LBB4_80:
	ADD  R15, R4, R5 // <--                                  // add	x5, x4, x15
	MOVD R2, R4      // <--                                  // mov	x4, x2

LBB4_81:
	WORD  $0x3cc10424                      // FMOVQ.P 16(R1), F4                   // ldr	q4, [x1], #16
	WORD  $0x3cc10485                      // FMOVQ.P 16(R4), F5                   // ldr	q5, [x4], #16
	VADD  V3.B16, V4.B16, V4.B16           // <--                                  // add	v4.16b, v4.16b, v3.16b
	VADD  V3.B16, V5.B16, V5.B16           // <--                                  // add	v5.16b, v5.16b, v3.16b
	VTBL  V4.B16, [V0.B16, V1.B16], V6.B16 // <--                                  // tbl	v6.16b, { v0.16b, v1.16b }, v4.16b
	VTBL  V5.B16, [V0.B16, V1.B16], V7.B16 // <--                                  // tbl	v7.16b, { v0.16b, v1.16b }, v5.16b
	VSUB  V6.B16, V4.B16, V4.B16           // <--                                  // sub	v4.16b, v4.16b, v6.16b
	VSUB  V7.B16, V5.B16, V5.B16           // <--                                  // sub	v5.16b, v5.16b, v7.16b
	VCMEQ V5.B16, V4.B16, V4.B16           // <--                                  // cmeq	v4.16b, v4.16b, v5.16b
	WORD  $0x0f0c8484                      // VSHRN $4, V4.H8, V4.B8               // shrn	v4.8b, v4.8h, #4
	FMOVD F4, R6                           // <--                                  // fmov	x6, d4
	CMN   $1, R6                           // <--                                  // cmn	x6, #1
	BNE   LBB4_76                          // <--                                  // b.ne	.LBB4_76
	CMP   R5, R1                           // <--                                  // cmp	x1, x5
	BCC   LBB4_81                          // <--                                  // b.lo	.LBB4_81

LBB4_83:
	CMP   $8, R14                        // <--                                  // cmp	x14, #8
	BCC   LBB4_86                        // <--                                  // b.lo	.LBB4_86
	WORD  $0xfc408424                    // FMOVD.P 8(R1), F4                    // ldr	d4, [x1], #8
	WORD  $0xfc408485                    // FMOVD.P 8(R4), F5                    // ldr	d5, [x4], #8
	VADD  V2.B8, V4.B8, V4.B8            // <--                                  // add	v4.8b, v4.8b, v2.8b
	VADD  V2.B8, V5.B8, V5.B8            // <--                                  // add	v5.8b, v5.8b, v2.8b
	VTBL  V4.B8, [V0.B16, V1.B16], V6.B8 // <--                                  // tbl	v6.8b, { v0.16b, v1.16b }, v4.8b
	VTBL  V5.B8, [V0.B16, V1.B16], V7.B8 // <--                                  // tbl	v7.8b, { v0.16b, v1.16b }, v5.8b
	VSUB  V6.B8, V4.B8, V4.B8            // <--                                  // sub	v4.8b, v4.8b, v6.8b
	VSUB  V7.B8, V5.B8, V5.B8            // <--                                  // sub	v5.8b, v5.8b, v7.8b
	VCMEQ V5.B8, V4.B8, V4.B8            // <--                                  // cmeq	v4.8b, v4.8b, v5.8b
	FMOVD F4, R5                         // <--                                  // fmov	x5, d4
	CMN   $1, R5                         // <--                                  // cmn	x5, #1
	BNE   LBB4_76                        // <--                                  // b.ne	.LBB4_76
	MOVD  R16, R7                        // <--                                  // mov	x7, x16
	JMP   LBB4_87                        // <--                                  // b	.LBB4_87

LBB4_86:
	MOVD R14, R7 // <--                                  // mov	x7, x14

LBB4_87:
	CBZ  R7, LBB4_96 // <--                                  // cbz	x7, .LBB4_96
	SUBS $4, R7, R19 // <--                                  // subs	x19, x7, #4
	BCC  LBB4_93     // <--                                  // b.lo	.LBB4_93
	WORD $0xb8404426 // MOVWU.P 4(R1), R6                    // ldr	w6, [x1], #4
	MOVD R19, R7     // <--                                  // mov	x7, x19
	WORD $0xb8404485 // MOVWU.P 4(R4), R5                    // ldr	w5, [x4], #4
	CMP  $1, R19     // <--                                  // cmp	x19, #1
	BEQ  LBB4_94     // <--                                  // b.eq	.LBB4_94

LBB4_90:
	CMP  $2, R7         // <--                                  // cmp	x7, #2
	BEQ  LBB4_74        // <--                                  // b.eq	.LBB4_74
	CMP  $3, R7         // <--                                  // cmp	x7, #3
	BNE  LBB4_75        // <--                                  // b.ne	.LBB4_75
	LSL  $24, R6, R6    // <--                                  // lsl	x6, x6, #24
	WORD $0x79400027    // MOVHU (R1), R7                       // ldrh	w7, [x1]
	LSL  $24, R5, R5    // <--                                  // lsl	x5, x5, #24
	WORD $0x79400093    // MOVHU (R4), R19                      // ldrh	w19, [x4]
	WORD $0x39400821    // MOVBU 2(R1), R1                      // ldrb	w1, [x1, #2]
	WORD $0x39400884    // MOVBU 2(R4), R4                      // ldrb	w4, [x4, #2]
	ORR  R7<<8, R6, R6  // <--                                  // orr	x6, x6, x7, lsl #8
	ORR  R19<<8, R5, R5 // <--                                  // orr	x5, x5, x19, lsl #8
	ORR  R1, R6, R6     // <--                                  // orr	x6, x6, x1
	ORR  R4, R5, R5     // <--                                  // orr	x5, x5, x4
	JMP  LBB4_75        // <--                                  // b	.LBB4_75

LBB4_93:
	MOVD ZR, R5  // <--                                  // mov	x5, xzr
	MOVD ZR, R6  // <--                                  // mov	x6, xzr
	CMP  $1, R7  // <--                                  // cmp	x7, #1
	BNE  LBB4_90 // <--                                  // b.ne	.LBB4_90

LBB4_94:
	WORD $0x39400021   // MOVBU (R1), R1                       // ldrb	w1, [x1]
	WORD $0x39400084   // MOVBU (R4), R4                       // ldrb	w4, [x4]
	ORR  R6<<8, R1, R6 // <--                                  // orr	x6, x1, x6, lsl #8
	ORR  R5<<8, R4, R5 // <--                                  // orr	x5, x4, x5, lsl #8
	JMP  LBB4_75       // <--                                  // b	.LBB4_75

LBB4_95:
	MOVD $-1, R8 // <--                                  // mov	x8, #-1

LBB4_96:
	NOP                 // (skipped)                            // ldr	x19, [sp], #16
	MOVD R8, R0         // <--                                  // mov	x0, x8
	MOVD R0, ret+32(FP) // <--
	RET                 // <--                                  // ret

LBB4_97:
	MOVD ZR, R8         // <--                                  // mov	x8, xzr
	NOP                 // (skipped)                            // ldr	x19, [sp], #16
	MOVD R8, R0         // <--                                  // mov	x0, x8
	MOVD R0, ret+32(FP) // <--
	RET                 // <--                                  // ret

TEXT ·IndexNEON(SB), NOSPLIT, $0-72
	MOVD haystack+0(FP), R0
	MOVD haystack_len+8(FP), R1
	MOVB rare1+16(FP), R2
	MOVD off1+24(FP), R3
	MOVB rare2+32(FP), R4
	MOVD off2+40(FP), R5
	MOVD needle+48(FP), R6
	MOVD needle_len+56(FP), R7
	JMP  l_exact                // <--                                  // b	impl_exact

TEXT ·indexFoldNEONC(SB), NOSPLIT, $0-72
	MOVD haystack+0(FP), R0
	MOVD haystack_len+8(FP), R1
	MOVB rare1+16(FP), R2
	MOVD off1+24(FP), R3
	MOVB rare2+32(FP), R4
	MOVD off2+40(FP), R5
	MOVD needle+48(FP), R6
	MOVD needle_len+56(FP), R7
	JMP  l_fold_both            // <--                                  // b	impl_fold_both

DATA uppercasingTable<>+0x00(SB)/8, $0x2020202020202000
DATA uppercasingTable<>+0x08(SB)/8, $0x2020202020202020
DATA uppercasingTable<>+0x10(SB)/8, $0x2020202020202020
DATA uppercasingTable<>+0x18(SB)/8, $0x0000000000202020
GLOBL uppercasingTable<>(SB), (RODATA|NOPTR), $32

DATA fold_table<>+0x00(SB)/8, $0x0706050403020100
DATA fold_table<>+0x08(SB)/8, $0x0f0e0d0c0b0a0908
DATA fold_table<>+0x10(SB)/8, $0x1716151413121110
DATA fold_table<>+0x18(SB)/8, $0x1f1e1d1c1b1a1918
DATA fold_table<>+0x20(SB)/8, $0x2726252423222120
DATA fold_table<>+0x28(SB)/8, $0x2f2e2d2c2b2a2928
DATA fold_table<>+0x30(SB)/8, $0x3736353433323130
DATA fold_table<>+0x38(SB)/8, $0x3f3e3d3c3b3a3938
DATA fold_table<>+0x40(SB)/8, $0x4746454443424140
DATA fold_table<>+0x48(SB)/8, $0x4f4e4d4c4b4a4948
DATA fold_table<>+0x50(SB)/8, $0x5756555453525150
DATA fold_table<>+0x58(SB)/8, $0x5f5e5d5c5b5a5958
DATA fold_table<>+0x60(SB)/8, $0x4746454443424160
DATA fold_table<>+0x68(SB)/8, $0x4f4e4d4c4b4a4948
DATA fold_table<>+0x70(SB)/8, $0x5756555453525150
DATA fold_table<>+0x78(SB)/8, $0x7f7e7d7c7b5a5958
DATA fold_table<>+0x80(SB)/8, $0x8786858483828180
DATA fold_table<>+0x88(SB)/8, $0x8f8e8d8c8b8a8988
DATA fold_table<>+0x90(SB)/8, $0x9796959493929190
DATA fold_table<>+0x98(SB)/8, $0x9f9e9d9c9b9a9998
DATA fold_table<>+0xa0(SB)/8, $0xa7a6a5a4a3a2a1a0
DATA fold_table<>+0xa8(SB)/8, $0xafaeadacabaaa9a8
DATA fold_table<>+0xb0(SB)/8, $0xb7b6b5b4b3b2b1b0
DATA fold_table<>+0xb8(SB)/8, $0xbfbebdbcbbbab9b8
DATA fold_table<>+0xc0(SB)/8, $0xc7c6c5c4c3c2c1c0
DATA fold_table<>+0xc8(SB)/8, $0xcfcecdcccbcac9c8
DATA fold_table<>+0xd0(SB)/8, $0xd7d6d5d4d3d2d1d0
DATA fold_table<>+0xd8(SB)/8, $0xdfdedddcdbdad9d8
DATA fold_table<>+0xe0(SB)/8, $0xe7e6e5e4e3e2e1e0
DATA fold_table<>+0xe8(SB)/8, $0xefeeedecebeae9e8
DATA fold_table<>+0xf0(SB)/8, $0xf7f6f5f4f3f2f1f0
DATA fold_table<>+0xf8(SB)/8, $0xfffefdfcfbfaf9f8
GLOBL fold_table<>(SB), (RODATA|NOPTR), $256

DATA tail_mask_table<>+0x00(SB)/8, $0x0000000000000000
DATA tail_mask_table<>+0x08(SB)/8, $0x0000000000000000
DATA tail_mask_table<>+0x10(SB)/1, $0xff
DATA tail_mask_table<>+0x11(SB)/8, $0x0000000000000000
DATA tail_mask_table<>+0x19(SB)/4, $0x00000000
DATA tail_mask_table<>+0x1d(SB)/2, $0x0000
DATA tail_mask_table<>+0x1f(SB)/1, $0x00
DATA tail_mask_table<>+0x20(SB)/1, $0xff
DATA tail_mask_table<>+0x21(SB)/1, $0xff
DATA tail_mask_table<>+0x22(SB)/8, $0x0000000000000000
DATA tail_mask_table<>+0x2a(SB)/4, $0x00000000
DATA tail_mask_table<>+0x2e(SB)/2, $0x0000
DATA tail_mask_table<>+0x30(SB)/1, $0xff
DATA tail_mask_table<>+0x31(SB)/1, $0xff
DATA tail_mask_table<>+0x32(SB)/1, $0xff
DATA tail_mask_table<>+0x33(SB)/8, $0x0000000000000000
DATA tail_mask_table<>+0x3b(SB)/4, $0x00000000
DATA tail_mask_table<>+0x3f(SB)/1, $0x00
DATA tail_mask_table<>+0x40(SB)/1, $0xff
DATA tail_mask_table<>+0x41(SB)/1, $0xff
DATA tail_mask_table<>+0x42(SB)/1, $0xff
DATA tail_mask_table<>+0x43(SB)/1, $0xff
DATA tail_mask_table<>+0x44(SB)/8, $0x0000000000000000
DATA tail_mask_table<>+0x4c(SB)/4, $0x00000000
DATA tail_mask_table<>+0x50(SB)/1, $0xff
DATA tail_mask_table<>+0x51(SB)/1, $0xff
DATA tail_mask_table<>+0x52(SB)/1, $0xff
DATA tail_mask_table<>+0x53(SB)/1, $0xff
DATA tail_mask_table<>+0x54(SB)/1, $0xff
DATA tail_mask_table<>+0x55(SB)/8, $0x0000000000000000
DATA tail_mask_table<>+0x5d(SB)/2, $0x0000
DATA tail_mask_table<>+0x5f(SB)/1, $0x00
DATA tail_mask_table<>+0x60(SB)/1, $0xff
DATA tail_mask_table<>+0x61(SB)/1, $0xff
DATA tail_mask_table<>+0x62(SB)/1, $0xff
DATA tail_mask_table<>+0x63(SB)/1, $0xff
DATA tail_mask_table<>+0x64(SB)/1, $0xff
DATA tail_mask_table<>+0x65(SB)/1, $0xff
DATA tail_mask_table<>+0x66(SB)/8, $0x0000000000000000
DATA tail_mask_table<>+0x6e(SB)/2, $0x0000
DATA tail_mask_table<>+0x70(SB)/1, $0xff
DATA tail_mask_table<>+0x71(SB)/1, $0xff
DATA tail_mask_table<>+0x72(SB)/1, $0xff
DATA tail_mask_table<>+0x73(SB)/1, $0xff
DATA tail_mask_table<>+0x74(SB)/1, $0xff
DATA tail_mask_table<>+0x75(SB)/1, $0xff
DATA tail_mask_table<>+0x76(SB)/1, $0xff
DATA tail_mask_table<>+0x77(SB)/8, $0x0000000000000000
DATA tail_mask_table<>+0x7f(SB)/1, $0x00
DATA tail_mask_table<>+0x80(SB)/8, $0xffffffffffffffff
DATA tail_mask_table<>+0x88(SB)/8, $0x0000000000000000
DATA tail_mask_table<>+0x90(SB)/8, $0xffffffffffffffff
DATA tail_mask_table<>+0x98(SB)/8, $0x00000000000000ff
DATA tail_mask_table<>+0xa0(SB)/8, $0xffffffffffffffff
DATA tail_mask_table<>+0xa8(SB)/8, $0x000000000000ffff
DATA tail_mask_table<>+0xb0(SB)/8, $0xffffffffffffffff
DATA tail_mask_table<>+0xb8(SB)/8, $0x0000000000ffffff
DATA tail_mask_table<>+0xc0(SB)/8, $0xffffffffffffffff
DATA tail_mask_table<>+0xc8(SB)/8, $0x00000000ffffffff
DATA tail_mask_table<>+0xd0(SB)/8, $0xffffffffffffffff
DATA tail_mask_table<>+0xd8(SB)/8, $0x000000ffffffffff
DATA tail_mask_table<>+0xe0(SB)/8, $0xffffffffffffffff
DATA tail_mask_table<>+0xe8(SB)/8, $0x0000ffffffffffff
DATA tail_mask_table<>+0xf0(SB)/8, $0xffffffffffffffff
DATA tail_mask_table<>+0xf8(SB)/8, $0x00ffffffffffffff
GLOBL tail_mask_table<>(SB), (RODATA|NOPTR), $256

TEXT ·SearchNeedleFold(SB), NOSPLIT, $0-72
	MOVD haystack+0(FP), R0
	MOVD haystack_len+8(FP), R1
	MOVB rare1+16(FP), R2
	MOVD off1+24(FP), R3
	MOVB rare2+32(FP), R4
	MOVD off2+40(FP), R5
	MOVD needle+48(FP), R6
	MOVD needle_len+56(FP), R7
	JMP  l_fold_norm            // <--                                  // b	impl_fold_norm
